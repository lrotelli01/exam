\chapter{Data Analysis and Conclusions}

This chapter presents a statistical analysis of the simulation results, including warm-up period determination, factorial design analysis, normality testing, and residual analysis to validate the model assumptions.

\section{Warm-Up Period Analysis}

Before collecting steady-state statistics, it is essential to identify and discard the \textbf{transient phase} (warm-up period) during which the system has not yet reached equilibrium.

\subsection{Welch's Graphical Procedure}

We applied \textbf{Welch's graphical method} to determine the warm-up period. This technique involves:

\begin{enumerate}
    \item Running $R$ independent replications with different random seeds
    \item Recording the time series of the metric of interest (utilization)
    \item Computing the ensemble average across replications at each time point
    \item Applying a moving average filter to smooth fluctuations
    \item Identifying the time $T_w$ at which the smoothed series stabilizes
\end{enumerate}

\subsubsection{Mathematical Formulation}

Let $Y_{r,i}$ denote the observation at time step $i$ in replication $r$. The ensemble average is:
\begin{equation}
\bar{Y}_i = \frac{1}{R} \sum_{r=1}^{R} Y_{r,i}
\end{equation}

The moving average with window size $w$ is:
\begin{equation}
\bar{Y}_i(w) = \begin{cases}
\frac{1}{2i+1} \sum_{s=-i}^{i} \bar{Y}_{i+s+1} & \text{if } i < w \\
\frac{1}{2w+1} \sum_{s=-w}^{w} \bar{Y}_{i+s+1} & \text{if } i \geq w
\end{cases}
\end{equation}

The warm-up period $T_w$ is identified as the point where:
\begin{equation}
\left| \frac{d\bar{Y}_i(w)}{dt} \right| < \epsilon
\end{equation}

\subsection{Results from Simulation Data}

The analysis was performed using data extracted from all \textbf{360 simulation runs} covering \textbf{72 unique configurations}:

\begin{itemize}
    \item Number of users $N$: 100, 500, 1000, 1200, 1500, 1600, 2000, 2500, 3000, 3500, 4000, 5000
    \item Read probability $p$: 0.3, 0.5, 0.8
    \item Distribution: Uniform, Lognormal
    \item Tables $M = 20$, $\lambda = 0.05$ req/s, $S = 0.1$s
    \item 5 replications per configuration
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{images/warmup_analysis.pdf}
\caption{Warm-up analysis across all configurations. Top-left: warm-up period vs system load for different $p$ values and distributions. Top-right: theoretical vs empirical utilization comparison. Bottom-left: warm-up period by distribution type. Bottom-right: heatmap of warm-up periods across $N$ and $p$.}
\label{fig:warmup_analysis}
\end{figure}

\subsubsection{Key Findings}

The analysis [Figure~\ref{fig:warmup_analysis}] reveals important patterns:

\begin{itemize}
    \item \textbf{Effect of N}: Higher user counts lead to longer characteristic times $\tau$, especially near saturation. At $N=5000$ with Uniform distribution, $\tau \approx 33$s.
    
    \item \textbf{Effect of p}: Higher read probability reduces warm-up time because reads can proceed in parallel, reducing queueing delays.
    
    \item \textbf{Effect of Distribution}: 
    \begin{itemize}
        \item \textbf{Uniform}: Higher actual utilization (closer to theoretical), longer warm-up at high loads
        \item \textbf{Lognormal}: Creates hotspots, causing some tables to saturate while others remain idle, resulting in lower overall utilization but uneven convergence
    \end{itemize}
\end{itemize}

\subsubsection{Sample Warm-Up Results}

\begin{table}[H]
\centering
\small
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{N} & \textbf{p} & \textbf{Dist} & \textbf{$U_{theo}$} & \textbf{$U_{emp}$} & \textbf{$\tau$ (s)} \\
\hline
100 & 0.5 & Uniform & 2.5\% & 2.49\% & 0.9 \\
1000 & 0.5 & Uniform & 25.0\% & 24.14\% & 1.8 \\
2000 & 0.5 & Uniform & 50.0\% & 46.38\% & 2.8 \\
3000 & 0.5 & Uniform & 75.0\% & 66.25\% & 4.6 \\
4000 & 0.5 & Uniform & 100.0\% & 83.11\% & 9.5 \\
5000 & 0.5 & Uniform & 125.0\% & 96.39\% & 33.1 \\
\hline
1000 & 0.5 & Lognormal & 25.0\% & 23.41\% & 1.8 \\
3000 & 0.5 & Lognormal & 75.0\% & 53.24\% & 3.3 \\
5000 & 0.5 & Lognormal & 125.0\% & 66.83\% & 5.0 \\
\hline
\end{tabular}
\caption{Characteristic time $\tau$ for selected configurations}
\label{tab:warmup_tau}
\end{table}

\textbf{Note}: The Lognormal distribution shows lower empirical utilization than Uniform because hotspots cause some tables to reach saturation (blocking new requests) while others remain underutilized.

\begin{tcolorbox}[title=Warm-Up Configuration]
Based on the analysis of all 72 configurations:
\begin{itemize}
    \item \textbf{Recommended warm-up}: 500 seconds (covers 90th percentile of $5\tau$)
    \item \textbf{For high-load scenarios} ($N > 4000$): Consider 1000s warm-up
\end{itemize}
The OMNeT++ configuration includes:
\begin{verbatim}
warmup-period = 500s
\end{verbatim}
\end{tcolorbox}

\section{Experimental Design}

The simulation study follows a \textbf{factorial design} with the following factors:

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Factor} & \textbf{Symbol} & \textbf{Levels} \\
\hline
Number of users & $N$ & 100, 500, 1000, 1200, 1500, 1600, 2000, 2500, 3000, 3500, 4000, 5000 \\
Read probability & $p$ & 0.3, 0.5, 0.8 \\
Number of tables & $M$ & 20 \\
Distribution type & - & Uniform, Lognormal \\
\hline
\end{tabular}
\caption{Experimental factors and their levels}
\label{tab:factors}
\end{table}

Each configuration was replicated 5 times with different random seeds, resulting in a total of \textbf{360 simulation runs}.

\section{Factor Impact Analysis}

Using the $2^k$ factorial design methodology, we computed the effect of each factor on the system throughput. The pie chart [Figure~\ref{fig:factor_pie}] illustrates the relative contribution of each factor to the total variation in throughput.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{images/factor_effects_pie.pdf}
\caption{The pie chart illustrates the impact of each factor on the throughput of the system.}
\label{fig:factor_pie}
\end{figure}

\subsection{Key Findings}

The analysis reveals that:

\begin{itemize}
    \item \textbf{Number of Users ($N$)}: The dominant factor affecting throughput, as expected from queueing theory. More users generate more requests, directly increasing throughput until saturation.
    
    \item \textbf{Read Probability ($p$)}: Has a moderate effect. Higher read probabilities reduce contention since reads can be served concurrently, improving overall throughput.
    
    \item \textbf{Interaction Effects}: The $N \times M$ interaction shows that the effect of adding users depends on the number of available tables (service capacity).
\end{itemize}


\begin{table}[H]
\centering
\begin{tabular}{|l|r|r|r|r|r|}
\hline
\textbf{Source} & \textbf{SS} & \textbf{df} & \textbf{MS} & \textbf{F} & \textbf{p-value} \\
\hline
Between groups & $1.36 \times 10^{14}$ & 71 & $1.91 \times 10^{12}$ & 204.02 & $< 0.001$ \\
Within groups & $6.16 \times 10^{12}$ & 288 & $2.14 \times 10^{10}$ & - & - \\
\hline
Total & $1.42 \times 10^{14}$ & 359 & - & - & - \\
\hline
\end{tabular}
\caption{ANOVA table for throughput analysis}
\label{tab:anova}
\end{table}

The F-statistic of 204.02 with p-value $< 0.001$ indicates that the factor effects are \textbf{highly significant}. The between-groups variation accounts for \textbf{95.7\%} of the total variation.

\section{Model Validation}

\subsection{Testing Normality Hypothesis}

The QQ-Plot [Figure~\ref{fig:qqplot}] compares the distribution of residuals against a theoretical normal distribution.

\begin{figure}[H]
\centering
\includegraphics[width=0.75\textwidth]{images/qq_plot_residuals.pdf}
\caption{QQ-Plot: On Y-Axis the sample quantiles and X-Axis the theoretical quantiles of a normal distribution.}
\label{fig:qqplot}
\end{figure}

The QQ-Plot shows a \textbf{non-linear behavior}, indicating that the residuals deviate from normality, particularly in the tails. This is expected given:

\begin{itemize}
    \item The wide range of configurations (from light load to saturation)
    \item The presence of two different distributions (Uniform vs Lognormal)
    \item The non-linear behavior near system saturation
\end{itemize}

The Shapiro-Wilk test confirms this departure from normality (p-value $< 0.05$).

\subsection{Homoskedasticity}

The scatter plot of residuals vs predicted response [Figure~\ref{fig:residuals_pred}] shows the relationship between model predictions and errors.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/residuals_vs_predicted.pdf}
\caption{The residuals are plotted along the Y-axis, while the predicted responses are represented on the X-axis.}
\label{fig:residuals_pred}
\end{figure}

A visible trend is present, indicating \textbf{heteroskedasticity}: the variance of residuals increases with the predicted response. This is typical in simulation studies where higher throughput configurations have larger absolute variations.

\subsection{Residual Magnitude Analysis}

Essentially, we can ignore trends if the errors are one or more orders of magnitude below the predicted response. Figure~\ref{fig:residual_mag} shows this analysis:

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{images/residual_magnitude.pdf}
\caption{Each residual varies by an order of magnitude or more below the predicted response. On Y-Axis the ratio $|$residual$|$ / $|$predicted$|$ and X-Axis the observation number.}
\label{fig:residual_mag}
\end{figure}

The analysis shows that most residuals are \textbf{well below 10\%} of the predicted values, indicating that despite the heteroskedasticity, the model provides accurate predictions.

\section{Performance Summary}

Table~\ref{tab:perf_summary} summarizes the key performance metrics across different configurations:

\begin{table}[H]
\centering
\small
\begin{tabular}{|c|c|c|r|r|r|}
\hline
\textbf{N} & \textbf{p} & \textbf{Distribution} & \textbf{Throughput} & \textbf{Util. (\%)} & \textbf{Wait (ms)} \\
\hline
100 & 0.5 & Uniform & 49,865 & 2.49 & 0.97 \\
500 & 0.5 & Uniform & 249,790 & 12.29 & 5.19 \\
1000 & 0.5 & Uniform & 499,104 & 24.14 & 11.70 \\
2000 & 0.5 & Uniform & 998,117 & 46.38 & 31.30 \\
3000 & 0.5 & Uniform & 1,497,917 & 66.25 & 69.03 \\
4000 & 0.5 & Uniform & 1,998,085 & 83.11 & 166.39 \\
5000 & 0.5 & Uniform & 2,498,596 & 96.39 & 860.97 \\
\hline
1000 & 0.5 & Lognormal & 500,083 & 23.41 & 15.70 \\
3000 & 0.5 & Lognormal & 1,283,611 & 53.24 & 264,303 \\
5000 & 0.5 & Lognormal & 1,656,913 & 66.83 & 734,533 \\
\hline
\end{tabular}
\caption{Performance summary for selected configurations}
\label{tab:perf_summary}
\end{table}

\subsection{Observations}

\begin{enumerate}
    \item \textbf{Linear Scaling}: For low to moderate loads ($N \leq 2000$), throughput scales linearly with the number of users.
    
    \item \textbf{Saturation Effects}: As utilization approaches 100\%, waiting times increase dramatically due to queueing effects.
    
    \item \textbf{Distribution Impact}: The Lognormal distribution (modeling hotspots) causes significantly higher waiting times compared to Uniform distribution at high loads, due to load imbalance among tables.
    
    \item \textbf{Read Probability}: Higher read probabilities ($p = 0.8$) reduce waiting times since reads have less contention than writes.
\end{enumerate}

\section{Conclusions}

This simulation study has successfully analyzed the performance of a distributed database system under various configurations. The main conclusions are:

\subsection{System Capacity Analysis}

Based on the simulation results, we analyze system capacity using \textbf{average waiting time} as the primary metric for detecting stall conditions:
\begin{itemize}
    \item \textbf{OK}: Waiting time $< 100$ms (acceptable response time)
    \item \textbf{DEGRADED}: Waiting time $100$--$1000$ms (noticeable delays)
    \item \textbf{STALLED}: Waiting time $> 1000$ms (system overloaded)
\end{itemize}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|r|r|c|}
\hline
\textbf{p} & \textbf{Distribution} & \textbf{Max N (W$<$100ms)} & \textbf{Max N (W$<$1s)} & \textbf{Status at N=5000} \\
\hline
0.3 & Lognormal & 1,200 & 1,200 & \textcolor{red}{STALLED (944s wait)} \\
0.3 & Uniform & 2,500 & 4,000 & \textcolor{red}{STALLED (599s wait)} \\
\hline
0.5 & Lognormal & 1,600 & 1,600 & \textcolor{red}{STALLED (735s wait)} \\
0.5 & Uniform & 3,000 & 5,000 & DEGRADED (861ms wait) \\
\hline
0.8 & Lognormal & 3,000 & 3,500 & \textcolor{red}{STALLED (127s wait)} \\
0.8 & Uniform & 5,000+ & 5,000+ & OK (54ms wait) \\
\hline
\end{tabular}
\caption{Maximum concurrent users based on waiting time thresholds ($M=20$, $\lambda=0.05$, $S=0.1$s)}
\label{tab:max_users}
\end{table}

\subsubsection{Detailed Throughput Analysis}

Table~\ref{tab:throughput_detail} shows the throughput per user, which decreases when the system becomes saturated:

\begin{table}[H]
\centering
\small
\begin{tabular}{|c|c|c|r|r|r|c|}
\hline
\textbf{p} & \textbf{Dist} & \textbf{N} & \textbf{Throughput} & \textbf{Wait (ms)} & \textbf{TP/User} & \textbf{Status} \\
\hline
0.5 & Uniform & 1,000 & 499,104 & 11.70 & 499.1 & OK \\
0.5 & Uniform & 2,000 & 998,117 & 31.30 & 499.1 & OK \\
0.5 & Uniform & 3,000 & 1,497,917 & 69.03 & 499.3 & OK \\
0.5 & Uniform & 4,000 & 1,998,085 & 166.39 & 499.5 & DEGRADED \\
0.5 & Uniform & 5,000 & 2,498,596 & 860.98 & 499.7 & DEGRADED \\
\hline
0.5 & Lognormal & 1,000 & 500,083 & 15.70 & 500.1 & OK \\
0.5 & Lognormal & 1,600 & 799,534 & 60.91 & 499.7 & OK \\
0.5 & Lognormal & 2,000 & 976,335 & 39,359 & 488.2 & \textcolor{red}{STALLED} \\
0.5 & Lognormal & 3,000 & 1,283,611 & 264,306 & 427.9 & \textcolor{red}{STALLED} \\
\hline
\end{tabular}
\caption{Throughput degradation under increasing load}
\label{tab:throughput_detail}
\end{table}

\subsubsection{Capacity Guidelines}

\begin{itemize}
    \item \textbf{Uniform Distribution}:
    \begin{itemize}
        \item $p=0.3$: Max \textbf{2,500 users} (W$<$100ms), stalls at N$>$4,000
        \item $p=0.5$: Max \textbf{3,000 users} (W$<$100ms), degrades but stable up to 5,000
        \item $p=0.8$: Max \textbf{5,000+ users} (W=54ms at N=5,000) -- \textbf{best configuration}
    \end{itemize}
    
    \item \textbf{Lognormal Distribution (hotspots)}:
    \begin{itemize}
        \item $p=0.3$: Max \textbf{1,200 users} only -- hotspots cause early saturation
        \item $p=0.5$: Max \textbf{1,600 users} -- throughput/user drops at higher loads
        \item $p=0.8$: Max \textbf{3,000 users} -- read parallelism mitigates hotspot effects
    \end{itemize}
\end{itemize}

\begin{tcolorbox}[colback=yellow!10, title=Critical Finding: Hotspot Impact]
The \textbf{Lognormal distribution} (simulating hotspot access patterns) reduces system capacity by \textbf{50--75\%} compared to Uniform distribution:
\begin{itemize}
    \item At $p=0.3$: 1,200 vs 2,500 users (52\% reduction)
    \item At $p=0.5$: 1,600 vs 3,000 users (47\% reduction)  
    \item At $p=0.8$: 3,000 vs 5,000+ users (40\% reduction)
\end{itemize}
This highlights the critical importance of \textbf{load balancing} in production systems.
\end{tcolorbox}

\begin{tcolorbox}[title=Key Conclusions]
\begin{enumerate}
    \item \textbf{Model Validity}: The simulation model produces statistically significant results with factor effects explaining 95.7\% of the total variation.
    
    \item \textbf{Capacity Limits} (for $M=20$, $\lambda=0.05$, $S=0.1$s):
    \begin{itemize}
        \item \textbf{Best case} (Uniform, $p=0.8$): 5,000+ concurrent users
        \item \textbf{Typical} (Uniform, $p=0.5$): 3,000 concurrent users
        \item \textbf{Worst case} (Lognormal, $p=0.3$): 1,200 concurrent users
    \end{itemize}
    
    \item \textbf{Stall Detection}: System enters stall when:
    \begin{itemize}
        \item Average waiting time exceeds 1 second
        \item Throughput per user decreases (queue buildup)
    \end{itemize}
    
    \item \textbf{Read/Write Impact}: Each 10\% increase in read probability increases capacity by approximately \textbf{25--50\%} due to read parallelism.
    
    \item \textbf{Scaling Formula}: Maximum users for target waiting time $W_{max}$:
    \begin{equation}
    N_{max} \approx \frac{M \cdot (1 - p \cdot \alpha)}{\lambda \cdot S} \cdot f(W_{max})
    \end{equation}
    where $\alpha$ is the read parallelism factor and $f(W_{max})$ depends on acceptable waiting time.
\end{enumerate}
\end{tcolorbox}

\subsection{Recommendations}

Based on the analysis, we recommend:

\begin{itemize}
    \item Keep system utilization below 70\% to maintain predictable response times
    \item Implement load balancing when hotspot access patterns are expected
    \item Scale the number of tables proportionally with expected user growth
    \item Monitor the read/write ratio as it affects overall system capacity
\end{itemize}