\chapter{Data Analysis and Conclusions}

This chapter presents a statistical analysis of the simulation results, including factorial design analysis, normality testing, and residual analysis to validate the model assumptions.

\section{Experimental Design}

The simulation study follows a \textbf{factorial design} with the following factors:

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Factor} & \textbf{Symbol} & \textbf{Levels} \\
\hline
Number of users & $N$ & 100, 500, 1000, 1200, 1500, 1600, 2000, 2500, 3000, 3500, 4000, 5000 \\
Read probability & $p$ & 0.3, 0.5, 0.8 \\
Number of tables & $M$ & 20 \\
Distribution type & - & Uniform, Lognormal \\
\hline
\end{tabular}
\caption{Experimental factors and their levels}
\label{tab:factors}
\end{table}

Each configuration was replicated 5 times with different random seeds, resulting in a total of \textbf{360 simulation runs}.

\section{Factor Impact Analysis}

Using the $2^k$ factorial design methodology, we computed the effect of each factor on the system throughput. The pie chart [Figure~\ref{fig:factor_pie}] illustrates the relative contribution of each factor to the total variation in throughput.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{images/factor_effects_pie.pdf}
\caption{The pie chart illustrates the impact of each factor on the throughput of the system.}
\label{fig:factor_pie}
\end{figure}

\subsection{Key Findings}

The analysis reveals that:

\begin{itemize}
    \item \textbf{Number of Users ($N$)}: The dominant factor affecting throughput, as expected from queueing theory. More users generate more requests, directly increasing throughput until saturation.
    
    \item \textbf{Read Probability ($p$)}: Has a moderate effect. Higher read probabilities reduce contention since reads can be served concurrently, improving overall throughput.
    
    \item \textbf{Interaction Effects}: The $N \times M$ interaction shows that the effect of adding users depends on the number of available tables (service capacity).
\end{itemize}

\section{ANOVA Results}

The Analysis of Variance (ANOVA) was performed to test whether the factor effects are statistically significant.

\begin{table}[H]
\centering
\begin{tabular}{|l|r|r|r|r|r|}
\hline
\textbf{Source} & \textbf{SS} & \textbf{df} & \textbf{MS} & \textbf{F} & \textbf{p-value} \\
\hline
Between groups & $1.36 \times 10^{14}$ & 71 & $1.91 \times 10^{12}$ & 204.02 & $< 0.001$ \\
Within groups & $6.16 \times 10^{12}$ & 288 & $2.14 \times 10^{10}$ & - & - \\
\hline
Total & $1.42 \times 10^{14}$ & 359 & - & - & - \\
\hline
\end{tabular}
\caption{ANOVA table for throughput analysis}
\label{tab:anova}
\end{table}

The F-statistic of 204.02 with p-value $< 0.001$ indicates that the factor effects are \textbf{highly significant}. The between-groups variation accounts for \textbf{95.7\%} of the total variation.

\section{Model Validation}

\subsection{Testing Normality Hypothesis}

The QQ-Plot [Figure~\ref{fig:qqplot}] compares the distribution of residuals against a theoretical normal distribution.

\begin{figure}[H]
\centering
\includegraphics[width=0.75\textwidth]{images/qq_plot_residuals.pdf}
\caption{QQ-Plot: On Y-Axis the sample quantiles and X-Axis the theoretical quantiles of a normal distribution.}
\label{fig:qqplot}
\end{figure}

The QQ-Plot shows a \textbf{non-linear behavior}, indicating that the residuals deviate from normality, particularly in the tails. This is expected given:

\begin{itemize}
    \item The wide range of configurations (from light load to saturation)
    \item The presence of two different distributions (Uniform vs Lognormal)
    \item The non-linear behavior near system saturation
\end{itemize}

The Shapiro-Wilk test confirms this departure from normality (p-value $< 0.05$).

\subsection{Homoskedasticity}

The scatter plot of residuals vs predicted response [Figure~\ref{fig:residuals_pred}] shows the relationship between model predictions and errors.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/residuals_vs_predicted.pdf}
\caption{The residuals are plotted along the Y-axis, while the predicted responses are represented on the X-axis.}
\label{fig:residuals_pred}
\end{figure}

A visible trend is present, indicating \textbf{heteroskedasticity}: the variance of residuals increases with the predicted response. This is typical in simulation studies where higher throughput configurations have larger absolute variations.

\subsection{Residual Magnitude Analysis}

Essentially, we can ignore trends if the errors are one or more orders of magnitude below the predicted response. Figure~\ref{fig:residual_mag} shows this analysis:

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{images/residual_magnitude.pdf}
\caption{Each residual varies by an order of magnitude or more below the predicted response. On Y-Axis the ratio $|$residual$|$ / $|$predicted$|$ and X-Axis the observation number.}
\label{fig:residual_mag}
\end{figure}

The analysis shows that most residuals are \textbf{well below 10\%} of the predicted values, indicating that despite the heteroskedasticity, the model provides accurate predictions.

\section{Performance Summary}

Table~\ref{tab:perf_summary} summarizes the key performance metrics across different configurations:

\begin{table}[H]
\centering
\small
\begin{tabular}{|c|c|c|r|r|r|}
\hline
\textbf{N} & \textbf{p} & \textbf{Distribution} & \textbf{Throughput} & \textbf{Util. (\%)} & \textbf{Wait (ms)} \\
\hline
100 & 0.5 & Uniform & 49,865 & 2.49 & 0.97 \\
500 & 0.5 & Uniform & 249,790 & 12.29 & 5.19 \\
1000 & 0.5 & Uniform & 499,104 & 24.14 & 11.70 \\
2000 & 0.5 & Uniform & 998,117 & 46.38 & 31.30 \\
3000 & 0.5 & Uniform & 1,497,917 & 66.25 & 69.03 \\
4000 & 0.5 & Uniform & 1,998,085 & 83.11 & 166.39 \\
5000 & 0.5 & Uniform & 2,498,596 & 96.39 & 860.97 \\
\hline
1000 & 0.5 & Lognormal & 500,083 & 23.41 & 15.70 \\
3000 & 0.5 & Lognormal & 1,283,611 & 53.24 & 264,303 \\
5000 & 0.5 & Lognormal & 1,656,913 & 66.83 & 734,533 \\
\hline
\end{tabular}
\caption{Performance summary for selected configurations}
\label{tab:perf_summary}
\end{table}

\subsection{Observations}

\begin{enumerate}
    \item \textbf{Linear Scaling}: For low to moderate loads ($N \leq 2000$), throughput scales linearly with the number of users.
    
    \item \textbf{Saturation Effects}: As utilization approaches 100\%, waiting times increase dramatically due to queueing effects.
    
    \item \textbf{Distribution Impact}: The Lognormal distribution (modeling hotspots) causes significantly higher waiting times compared to Uniform distribution at high loads, due to load imbalance among tables.
    
    \item \textbf{Read Probability}: Higher read probabilities ($p = 0.8$) reduce waiting times since reads have less contention than writes.
\end{enumerate}

\section{Conclusions}

This simulation study has successfully analyzed the performance of a distributed database system under various configurations. The main conclusions are:

\begin{tcolorbox}[title=Key Conclusions]
\begin{enumerate}
    \item \textbf{Model Validity}: The simulation model produces statistically significant results with factor effects explaining 95.7\% of the total variation.
    
    \item \textbf{Dominant Factor}: The number of users ($N$) is the primary driver of system performance, followed by the service capacity (number of tables $M$).
    
    \item \textbf{Practical Limits}: The system maintains acceptable response times (under 100ms) for utilization below 70\%. Beyond this threshold, waiting times increase non-linearly.
    
    \item \textbf{Hotspot Sensitivity}: The Lognormal access pattern (hotspots) significantly degrades performance at high loads, suggesting the importance of load balancing strategies.
    
    \item \textbf{Model Accuracy}: Despite departures from normality and presence of heteroskedasticity, the relative errors remain small (typically $< 10\%$), validating the model's predictive capability.
\end{enumerate}
\end{tcolorbox}

\subsection{Recommendations}

Based on the analysis, we recommend:

\begin{itemize}
    \item Keep system utilization below 70\% to maintain predictable response times
    \item Implement load balancing when hotspot access patterns are expected
    \item Scale the number of tables proportionally with expected user growth
    \item Monitor the read/write ratio as it affects overall system capacity
\end{itemize}