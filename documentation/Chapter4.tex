\chapter{Data Analysis and Conclusions}

This chapter presents a statistical analysis of the simulation results, including warm-up period determination, factorial design analysis, normality testing, and residual analysis to validate the model assumptions.

\section{Warm-Up Period Analysis}

Before collecting steady-state statistics, it is essential to identify and discard the \textbf{transient phase} (warm-up period) during which the system has not yet reached equilibrium.

In this project, the warm-up period was estimated by \textbf{visual inspection} of the simulation trend.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{images/warmup_analysis.png}
\caption{Warm-up behavior observed in the simulation output.}
\label{fig:warmup_analysis}
\end{figure}

From Figure~\ref{fig:warmup_analysis}, it is clear that after the initial transient the curve stabilizes, so a \textbf{500 s warm-up} is considered sufficient.

\begin{tcolorbox}[title=Warm-Up Configuration]
The OMNeT++ configuration includes:
\begin{verbatim}
warmup-period = 500s
\end{verbatim}
\end{tcolorbox}

\section{Experimental Design}

The simulation study follows a \textbf{factorial design} with the following factors:

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Factor} & \textbf{Symbol} & \textbf{Levels} \\
\hline
Number of users & $N$ & 100, 500, 1000, 1200, 1500, 1600, 2000, 2500, 3000, 3500, 4000, 5000 \\
Read probability & $p$ & 0.3, 0.5, 0.8 \\
Number of tables & $M$ & 20 \\
Distribution type & - & Uniform, Lognormal \\
\hline
\end{tabular}
\caption{Experimental factors and their levels}
\label{tab:factors}
\end{table}

Each configuration was replicated 5 times with different random seeds, resulting in a total of \textbf{360 simulation runs}.

\section{Factor Impact Analysis}

The pie chart [Figure~\ref{fig:factor_pie}] is computed directly from the \texttt{.sca} runs and shows how much each factor contributes to \textbf{throughput} variability.
The dominant slice is \textbf{Number of Users ($N$)} (numerically almost all the variance), so system load is the main driver of throughput.
This is coherent with the capacity results: distribution has little impact on aggregate throughput, but a strong impact on waiting-time tails and stall threshold.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{images/factor_effects_pie.pdf}
\caption{The pie chart illustrates the impact of each factor on the throughput of the system.}
\label{fig:factor_pie}
\end{figure}

\subsection{Key Findings}

The analysis reveals that:

\begin{itemize}
    \item \textbf{Number of Users ($N$)}: This is the most significant factor by far. In practice, throughput behavior is mostly determined by how many users are active.
    
    \item \textbf{Read Probability ($p$)}: Secondary effect on throughput.
    
    \item \textbf{Distribution effect}: Small impact on global throughput, but strong impact on delay and stability. Lognormal hotspots can trigger queue explosion and early stall under high load.
\end{itemize}


\section{Model Validation}

\subsection{Testing Normality Hypothesis}

Residual analysis is built only from real simulation replications (no synthetic data): for each $(N,p,\text{distribution})$ configuration, the predicted waiting time is the mean over the 5 runs, and residuals are measured as percentage deviations from that configuration mean.

The QQ-Plot [Figure~\ref{fig:qqplot}] compares the distribution of residuals against a theoretical normal distribution.

\begin{figure}[H]
\centering
\includegraphics[width=0.75\textwidth]{images/qq_plot_residuals.pdf}
\caption{QQ-Plot of standardized residual percentages: sample quantiles (Y-axis) vs normal theoretical quantiles (X-axis).}
\label{fig:qqplot}
\end{figure}

The QQ-Plot shows a \textbf{non-linear behavior}, indicating that the residuals deviate from normality, particularly in the tails. This is expected given:

\begin{itemize}
    \item The wide range of configurations (from light load to saturation)
    \item The presence of two different distributions (Uniform vs Lognormal)
    \item The non-linear behavior near system saturation
\end{itemize}

The Shapiro-Wilk test confirms this departure from normality (p-value $\ll 0.05$).

\subsection{Homoskedasticity}

The residuals-vs-predicted plot [Figure~\ref{fig:residuals_pred}] checks whether residual variance is stable across operating conditions.
With perfect homoskedasticity, residual percentages should form a horizontal band around zero with similar vertical spread.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{images/residuals_vs_predicted.pdf}
\caption{Residual percentage (Y-axis) versus predicted waiting time per configuration in ms (X-axis, log scale).}
\label{fig:residuals_pred}
\end{figure}

In our case, a clear funnel shape is not evident. Residuals stay centered around zero, with limited widening only in the most stressed hotspot regimes. The trend between residual magnitude and predicted wait is weak (Spearman $\rho \approx 0.18$), so behavior is \textbf{approximately homoskedastic} with mild heteroskedasticity at the extremes.

Implications:
\begin{itemize}
    \item Point predictions are still useful (mean residual remains near zero).
    \item Uncertainty may grow only in the most stressed configurations.
    \item Main qualitative conclusions are unchanged.
\end{itemize}

\subsection{Residual Magnitude Analysis}

To quantify this effect, we examine the absolute residual percentage $|e|$ across all runs and by groups [Figure~\ref{fig:residual_mag}].

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{images/residual_magnitude.pdf}
\caption{Residual magnitude analysis from \texttt{.sca} data: histogram of $|$residual$|$ (\%) and boxplots grouped by distribution and $p$.}
\label{fig:residual_mag}
\end{figure}

Most replications are very stable (median $|e| = 0.068\%$, 90th percentile $= 0.715\%$), while the largest deviations are concentrated in hotspot cases (up to about $19\%$).
Therefore, variability is mostly localized in stressed scenarios and does not change the core conclusions: the number of users is the dominant driver, while distribution mainly affects tails and stall risk.

\section{Conclusions}

This simulation study has successfully analyzed the performance of a distributed database system under various configurations. The main conclusions are:

\subsection{System Capacity Analysis}

Based on the simulation results, we analyze system capacity using \textbf{average waiting time} as the primary metric for detecting stall conditions:
\begin{itemize}
    \item \textbf{OK}: Waiting time $< 200$ms (acceptable response time)
    \item \textbf{DEGRADED}: Waiting time $200$--$1000$ms (noticeable delays)
    \item \textbf{STALLED}: Waiting time $> 1000$ms (system overloaded)
\end{itemize}

\subsubsection{Detailed Throughput Analysis}

Figure~\ref{fig:capacity_heatmap} summarizes all 72 configurations as a waiting-time heatmap. The overall throughput grows with load, while waiting time increases sharply under hotspot conditions. The full detailed table is reported in Appendix~\ref{chap:appendix_table}.

\begin{figure}[H]
\centering
\includegraphics[width=0.98\textwidth]{images/capacity_heatmap_waittime.pdf}
\caption{Capacity heatmap for Uniform and Lognormal traffic. Colors represent mean waiting time (log scale). Numbers inside cells are mean waiting time in ms (compact format, e.g., 15k = 15,000ms).}
\label{fig:capacity_heatmap}
\end{figure}

\subsubsection{Capacity Guidelines}

\begin{itemize}
    \item \textbf{Uniform Distribution}:
    \begin{itemize}
        \item $p=0.3$: Max \textbf{2,500 users} (W$<$200ms), stalls at N$>$4,000
        \item $p=0.5$: Max \textbf{3,000 users} (W$<$200ms), degraded but stable up to 5,000
        \item $p=0.8$: Max \textbf{5,000+ users} (W=154ms at N=5,000) -- \textbf{best configuration}
    \end{itemize}
    
    \item \textbf{Lognormal Distribution (hotspots)}:
    \begin{itemize}
        \item $p=0.3$: Max \textbf{1,200 users} only -- hotspots cause early saturation
        \item $p=0.5$: Max \textbf{1,200 users} for W$<$200ms (up to 1,600 for W$<$1s)
        \item $p=0.8$: Max \textbf{2,500 users} for W$<$200ms (up to 3,500 for W$<$1s)
    \end{itemize}
\end{itemize}

\begin{tcolorbox}[colback=yellow!10, title=Critical Finding: Hotspot Impact]
The \textbf{Lognormal distribution} (simulating hotspot access patterns) reduces system capacity by about \textbf{50--60\%} compared to Uniform distribution:
\begin{itemize}
    \item At $p=0.3$: 1,200 vs 2,500 users (52\% reduction)
    \item At $p=0.5$: 1,200 vs 3,000 users (60\% reduction)
    \item At $p=0.8$: 2,500 vs 5,000+ users (50\% reduction)
\end{itemize}
This highlights the critical importance of \textbf{load balancing} in production systems.
\end{tcolorbox}

\begin{tcolorbox}[title=Key Conclusions]
\begin{enumerate}
    \item \textbf{Model Behavior}: Across all runs, throughput scales almost linearly with offered load, while waiting time captures saturation and hotspot effects.
    
    \item \textbf{Capacity Limits} (for $M=20$, $\lambda=0.05$, $S=0.1$s):
    \begin{itemize}
        \item \textbf{Best case} (Uniform, $p=0.8$): 5,000+ concurrent users
        \item \textbf{Typical} (Uniform, $p=0.5$): 3,000 concurrent users
        \item \textbf{Worst case} (Lognormal, $p=0.3$): 1,200 concurrent users
    \end{itemize}
    
    \item \textbf{Stall Detection}: System enters stall when:
    \begin{itemize}
        \item Average waiting time exceeds 1 second
        \item Queueing delay grows explosively in hotspot configurations
    \end{itemize}
    
    \item \textbf{Read/Write Impact}: Higher read probability increases usable capacity, with the strongest gains under hotspot traffic.
\end{enumerate}
\end{tcolorbox}
