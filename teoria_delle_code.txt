1 Notes on Queueing Theory New version, 2019 Student version Last saved: 04/08/2022 09:52 2 Index 1 General Information.......................................................................................................5 2 Introduction to Queueing Theory...................................................................................6 3 Analysis of queueing nodes in isolation ........................................................................9 3.1 Characterizing the state of a queueing node............................................................9 3.1.1 Birth-only process..........................................................................................12 3.1.2 Two-state birth-death process........................................................................13 3.2 Steady-state analysis of birth-death systems.........................................................14 3.3 M/M/1 systems......................................................................................................17 3.3.1 Mean performance indexes............................................................................20 3.3.2 An alternative way to compute mean performance indexes..........................22 3.3.3 Arrival-time and random-observer probabilities............................................24 3.3.4 Distribution of response and waiting times....................................................25 3.3.5 Exercise..........................................................................................................28 3.4 M/M/C systems .....................................................................................................29 3.4.1 Exercise: comparison of the response time for queueing systems.................34 3.4.2 Delay centers: M/M/? systems.....................................................................34 3.4.3 Models, CTMCs and performance indexes....................................................35 3.5 Discouraged arrivals..............................................................................................36 3.6 Systems with finite memory: M/M/1/K ................................................................37 3.6.1 Adding queueing space does increase the utilization.....................................39 3.7 Systems with finite populations: M/M/1/*/U........................................................40 3.8 Systems with bulk arrivals ....................................................................................43 3.9 Systems with non-exponential service time distributions.....................................46 3.9.1 M/G/? systems and insensitivity...................................................................49 3.9.2 Exercise: M/En/1 system................................................................................49 4 Queueing Networks......................................................................................................51 4.1 Characterizing the output of a service center........................................................53 4.2 From Burke’s theorem to queueing networks.......................................................54 4.2.1 Queueing networks with feedback loops.......................................................56 4.3 General results for open queueing networks.........................................................57 4.4 Closed Queueing Networks...................................................................................60 4.4.1 Buzen’s convolution algorithm......................................................................63 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 3 4.4.2 Performance indexes in Closed Queueing Networks.....................................64 4.5 Classed queueing networks...................................................................................68 4.5.1 Classed queueing systems in isolation...........................................................69 4.5.2 Open classed queueing networks...................................................................70 4.5.3 Exercise – response times in a routed network ..............................................71 4.6 Closing remarks on FCFS queueing networks......................................................72 5 Processor-sharing queueing systems............................................................................73 6 Exercises ......................................................................................................................77 6.1 Single-queue systems............................................................................................77 6.1.1 Problem..........................................................................................................77 6.1.2 Problem..........................................................................................................78 6.1.3 Problem..........................................................................................................80 6.2 Queueing networks................................................................................................84 6.2.1 Problem (open queueing network).................................................................84 6.2.2 Problem (open queueing network).................................................................85 6.2.3 Problem (closed queueing network) ..............................................................87 6.2.4 Problem (classed open queueing network) ....................................................89 6.2.5 Problem (classed open QN of PS systems)....................................................91 7 Appendix......................................................................................................................93 7.1 Stochastic processes..............................................................................................93 7.1.1 Markov processes...........................................................................................96 7.1.2 Example: Bernoulli process...........................................................................97 7.1.3 Example: Poisson process..............................................................................98 7.1.4 Properties of Poisson processes ...................................................................100 7.2 Formal derivation of Chapman-Kolmogorov equations .....................................101 7.2.1 M/M/1 system ..............................................................................................101 7.2.2 M/M/2 system ..............................................................................................104 7.3 Useful mathematical series..................................................................................107 7.3.1 Sums of powers............................................................................................107 7.3.2 Power series .................................................................................................107 7.3.3 Exponential functions ..................................................................................107 7.3.4 Binomial coefficients...................................................................................107 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 4 placeholder 5 1 General Information Prof. Ing. Giovanni Stea Dipartimento di Ingegneria dell'Informazione, University of Pisa Largo L. Lazzarino 1, 56122 Pisa - Italy Ph. : (+39) 050-2217.653 (direct) .599 (switch) Fax : (+39) 050-2217.600 E-mail: giovanni.stea@unipi.it Useful references: Most of the material found in these notes can be found on the following book: Leonard Kleinrock, “QUEUEING SYSTEMS” John Wiley & Sons 1975 Another helpful book is: Mor Harchol-Balter, “Performance Modeling and Design of Computer Systems: Queueing Theory in Action”, Cambridge University Press, 18 Feb. 2013 Pre-requisites: Strong background in probability theory, algebra and mathematical analysis (derivatives, integrals, infinite sums). Some notions of linear algebra and differential equations. Module length: 18 hours theory, 4-5 hours exercises. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 6 2 Introduction to Queueing Theory Queueing theory is an analytical technique to model systems and get performance measures out of them. It is based on the observation that most of the work in computer systems/networks (and in many other, non-computer-related contexts) is performed by entities (e.g., a CPU, a disk, a peripheral) that handle one job at a time. Thus, if there are many jobs requiring service, they will queue up in a waiting queue, and will eventually get served when those ahead of them have been served. Why should one employ a queue at all? Because queues increase system utilization. In fact, if there is no queue, then the system will just reject jobs when it is busy, and then will have to wait for the next job arrival when it is idle. Instead, if we allow jobs to queue up, then the next (queued) job will seize the server as soon as it finishes processing the current job. This comes at the price of adding delay. Queued jobs spend time doing nothing, waiting for their turn. A typical example is the output interface of a router, with a line whose speed is ?? bits/s. If packets arrive fast enough (e.g., from the other input interfaces) they queue up, and they are transmitted sequentially in FCFS order (or, possibly, according to other scheduling disciplines). According to the figure, there are five packets in the system: one is being transmitted (packet 0), i.e., is in the server; four are queued (packets 1 to 4). Let us assume that packet 0 has just started transmission at time ??. Then we know that it will leave at time ?? + ??0???, ??0??? being its service time. On the other hand, packet 4 will: - Start being served at ??4 ?? = ?? + ? ???? 3 ??=0 ?? , i.e. it will stop waiting in the queue at that time instant; - Leave at time ??4 ?? = ??4 ?? + ??4 ?? = ?? + ? ???? 4 ??=0 ?? . Assuming that packet 4 has arrived at time ??4 ?? < ??4 ?? < ??4 ?? , then ??4 ?? ? ??4 ?? will be its waiting time (or queueing time), and ??4 ?? ? ??4 ?? will be its response time. We will always assume that our servers are work conserving, i.e., they always serve queued jobs if the queue is non-empty. In a system like this we would like to answer the following questions: - What is the distribution of the number of packets in the queue (or in the system)? You would need to know this, for instance, to size the buffer, to bound the probability of dropping a packet due to a buffer overflow; - What is the distribution of the response times? - What happens if you change the link speed to 2??? C L 1 L 2 L 3 queue server L 0 L 4 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 7 - How much do you need to increase the speed of the line if you want the 90th percentile of the response time to be less than ??? (capacity planning) In a system like this, most of the above questions can be answered once we define what the workload is. In this case, a workload is given by: a) The interarrival time of the packets, which will be some random variable; b) The service demand, i.e., the time for which they keep the server busy. In this case, it is given by the packet lengths (divided by a constant link speed). Another example: a till at the supermarket. In this case the service demand may be inferred from the number of items in the shopping cart (assuming that the cashier keeps a constant speed). The model is the same, i.e. a queue plus a server, with interarrivals (new customers joining the queue) and departures (customers checking out). Yet another example: consider a web server, that accepts HTTP requests, performs some computations, may or may not need to access a database, and then returns the response. In this case it would probably be inappropriate to model this using a simple queue and server. In fact, it is still true that requests are served in sequence, but they may interest several components, and visit the same component more than once. In fact, some requests will only require computations at the CPU (and will not interest the disk), others will access the CPU first, then the disk and the CPU again, possibly several times. A more appropriate model for this example would then be the following: This is a queueing network, where each service center can be modeled as a queue+server. There is probabilistic routing, i.e., jobs (or requests, or transactions, etc.) that leave the CPU may leave the system altogether (with probability ??) or may be routed to the disk (with probability 1 ? ??). Obviously, the service demand for the same transaction at the two service centers may be different (it may differ by orders of magnitude, given the relative speeds of the devices), and if the same request traverses twice the same service center it will place a different service demand at that center. For such a system, we can answer questions like the ones that we formulated previously both separately, i.e., per service center, and globally, for the system as a whole. In this case, we can also perform a bottleneck analysis, i.e., find out which of the two components limits the performance of the system. This is interesting, because the bottleneck is the component that we need to upgrade first if we want our system to scale up (i.e., be able to handle a higher workload). If the CPU is the CPU workload disk p 1-p Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 8 bottleneck, then upgrading the disk will not yield a faster response or allow this system to handle more transactions per unit of time. Upgrading to a faster CPU will instead provide tangible benefits. The bottleneck is the service center with the highest utilization. Utilization is defined as the percentage of time for which a server is busy, i.e. is dequeuing and serving jobs. The device with the highest utilization is the one to upgrade first. If you upgrade another – non-bottleneck - device, you will simply reduce its utilization (i.e., you will have it idle for a higher percentage of time), but the overall performance of the system will not improve. The power of QT is that you can (almost always) obtain at least average performance metrics (e.g., mean response times, mean number of jobs in the queue), and very often in a closed form, just by solving few simple equations. In the simplest cases, you can often obtain more detailed performance metrics (e.g., a CDF of the response time), and not just average values. Having closed-form solutions is important if you want to predict what happens when the parameters change, e.g., to identify possible bottlenecks. At the very least, you can use QT to model systems as queuing networks, and then simulate their behavior and get numerical results instead. This is less insightful, but you can always do it. Thus, QT is also a modeling paradigm. Its power derives from the fact that it is quite abstract: you need to describe your fragment of reality at a very high level, without going into too many details. If you can model a physical system in terms of service centers, queues, interarrivals and service demands, then you can quickly get some insight into the performance of that system. Compare this modeling style, and the (weak) insight it requires, to the level of detail that you may want to attain in an in-depth simulation modeling (e.g., simulating the fetch and execution phases of a CPU with real instructions, etc.). The two are clearly different, and they will require different time and money. On the other hand, QT has its limitations. It is quite apt an instrument if you want to do a quick and dirty evaluation, but QT modeling may incur the risk of oversimplification. Neglecting crucial aspects just because they complicate your QT model too much happens all too often. What can you expect from QT? Those in the know assert that, if your model is correct, then normally you obtain fairly accurate throughput predictions (say, within 10% of the actual throughput). On the other hand, response times tend to be less accurate, and the error that you get will be load dependent (the higher the load, i.e., the nearer your system is to saturation, the larger your errors are going to be). Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 9 3 Analysis of queueing nodes in isolation 3.1 Characterizing the state of a queueing node Let us start with an example: a single queue + server (something that we will study a lot in the future), often called a service center or node. This may model anything (e.g., a network interface queue just as well as a post office’s). We need to characterize the state of this system at a given time ??. The way we characterize its state depends on what we want to observe. For instance, we may be interested in the number of jobs in the system at time ?? (also called the backlog at that time) Job 1 arrives Job 2 arrives Job 3 arrives Job 4 arrives Job 1 leaves Job 2 leaves j1 response time j2 response time j1 service time j2 q-ing time j2 service time N(t) t ??(??) is a discrete quantity (it is an integer), which is a function of a continuous parameter (time). The above is a trajectory (or realization, or sample path), which depends on the (possibly random) interarrival times of the customers at the queue, as well as on the (possibly random) service times (or service demands). Given different interarrival and service times, the trajectory is going to be different. We call such random trajectories random (or stochastic) processes. Let us start from one where: - The interarrival times between jobs are IID exponentials, with a rate ?? (or a mean interarrival time 1???). - The service demands are IID exponentials with a mean 1???. - Interarrivals and service demands are independent. - The queue is infinite and FCFS. queue server Jobs, Customers, Transactions, Packets, Users, Etc. Service center, node l m Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 10 In such a system (which is often called a birth-death system), jobs will get in, they will queue up, and whenever the system is non-empty the server will pick the head-of-line job in the queue, work on it for an exponential time, etc. etc. We are interested in computing the distribution of the number of jobs in the system, from which (as we will see) we will be able to derive the one of the response time, etc. The trajectories of this system can go up and down. We first observe that, if both interarrivals and service times are exponentially distributed, then ??(??) describes the state of this process completely. There is no need, in fact, to know the last time of arrival/departure in the past, since this does not yield any more insight: exponentials are memoryless. This means that the future evolutions of this system can be predicted (in a stochastic sense) only by knowing ??(??). As a counterexample, consider a system where: - Arrivals are exponential; - Service times are constant. For the above system, ??(??) alone would not be a complete state characterization. The time at which the next departure event will occur is univocally determined by the time of the last departure, hence the future does depend on the past. This means that we can setup a state diagram, describing the evolution of such a system in time, as follows: 0 l l 1 l l 2 …. n l m m m m m The circles are the system states at time t, and the arcs are the transitions from one state to another. The above is sometimes called a transition-rate diagram, since ?? and ?? are in fact transition rates between adjacent states, and – more often – continuous-time Markov chain (CTMC). We will always assume that ?? and ?? are time-independent, i.e. they do not change over time. They might, instead, be state-dependent, i.e. they may depend on the state of the system. There are many practical cases in which they do: - In some CPUs, the clock frequency is varied depending on the number of tasks to be executed: more tasks mean higher frequency, hence higher service rates depending on the state of the system. - Most people will be less likely to join a queue (e.g., to enter a museum) if the queue is long. In this case, the arrival rates would clearly depend on the system state. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 11 Therefore, it may be worthwhile to use ???? instead of ??, to denote the arrival rate when the system holds ?? jobs, and ???? in place of ??. The resulting CTMC would be the following. Note that the earlier CTMC was a special case of this one, when ????=?? and ???? =?? for all the values of ??. 0 l0 l1 1 ln-1 ln 2 …. n l2 m1 m2 m3 mn mn+1 The probability of two simultaneous events (i.e., one arrival and one departure, or two arrivals, or two departures) is negligible. For this reason, there are only arcs reaching out to the nearest (left or right) neighbors in the graph. Systems that admit only nearest-neighbor transitions are quite easy to analyze. Focus now on one state ?? > 0, and fix a time ??. Call ???? (??) the probability that there are ?? jobs at time ??, i.e. ???? (??) = ??{??(??) = ??}. If you circle that state, you can quickly write a probability flow-balance equation involving that state, just by looking at the CTMC: n mn mn+1 0 m1 { ?? ???? ???? (??) = ?(???? + ???? ) ? ???? (??) + ????+1 ? ????+1 (??) + ?????1 ? ?????1 (??) ?? > 0 ?? ???? ??0 (??) = ???0 ? ??0 (??) + ??1 ? ??1 (??) ?? = 0 The intuitive explanation for the above set of equations is the following: the term on the left is the variation in the flow of probability. That variation stems from the balance of: - An outgoing flow, with a minus sign - An incoming flow, with a plus sign. Both of which are at the right-hand side of the equations. This way, ???? can be interpreted as the transition rate from state ?? to state ?? + 1, and ???? as the transition rate from state ?? to ?? ? 1. ???? ? ???? (??) is the flow of probability which is poured from state ?? to state ?? + 1, etc. n n n n n n n n ( ) ( ) ( ) 1 1 1 1 ( ) ( ) d p t p t p t p t dt = ? + ? + ? + ? l m m l + + ? ? Variation of flow Outgoing flow Incoming flow Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 12 The above equations are called Chapman-Kolmogorov’s equations1 . The one for ?? = 0 is slightly different, since the incoming and outgoing arcs from state 0 are different. The evolution of such a system over time (i.e., for each ??) is thus completely specified once we solve the CK system of (an infinite number of) differential equations. Systems of differential equations can be solved once initial conditions are given in the form of a PMF for the state at time 0, i.e. ???? (0) ???, such that ? ???? (0) +? ??=0 = 1. A typical initial condition is ??0 (0) = 1, ???? (0) = 0 for ?? > 0, i.e. the system is initially empty. This is tough, in general, and – as we will show – not necessary for our purposes. However, we now solve the CK system in two very simple cases (we will not need to solve it in general, but it pays to do it a couple of times to figure out how things are). 3.1.1 Birth-only process This can be seen as an instance of the above, obtained by setting ???? = 0 ???. In the simplest case ???? = ??, ???, the CK equations become: { ?? ???? ???? (??) = ??? ? ???? (??) + ?? ? ?????1 (??) ?? > 0 ?? ???? ??0 (??) = ??? ? ??0 (??) ?? = 0 Assuming as initial conditions the usual ones, i.e., ??0 (0) = 1, ???? (0) = 0 for ?? > 0, we can easily solve the equations. In fact: - ?? = 0: ?? ???? ??0 (??) = ??? ? ??0 (??) admits as a solution ??0 (??) = ?? ? ?? ?????. The constant ?? can be set using the initial condition ??0 (0) = 1, hence ?? = 1. Thus, ??0 (??) = ?? ????? . - ?? = 1: ?? ???? ??1 (??) = ??? ? ??1 (??) + ?? ? ??0 (??) = ??? ? ??1 (??) + ?? ? ?? ?????. The solution to this one is ??1 (??) = ???? ? ?? ????? . - ?? > 1: by generalizing the same computations, one easily gets ???? (??) = (????) ?? ??! ? ?? ????? . Therefore, the general expression is ???? (??) = (????) ?? ??! ? ?? ????? , ???. The above one is a Poisson distribution, with a mean ????. This is why we normally call “Poisson processes” those whose interarrival times are IID exponentials2 . Moreover, we get that, as time increases, lim ???? ???? (??) = 0, ???. Again, this should not surprise us, since in a birth-only process the 1 A more formal derivation of CK equations can be found in the Appendix 2 A more formal definition of a Poisson process can be found in the Appendix Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 13 trajectory grows indefinitely with time, so the probability that ?? jobs have arrived in an infinite time must go to zero for each finite ??. 3.1.2 Two-state birth-death process This is a model for a single-slot buffer. If a job arrives when the system is in state 1, then that job is discarded. Thus, it is ??0 = ??, ??1 = 0, and ??1 = ?? (the fact that ??0 = 0 is pretty obvious). The CK equations for this system are the following: { ?? ???? ??1 (??) = ??? ? ??1 (??) + ?? ? ??0 (??) ?? ???? ??0 (??) = ??? ? ??0 (??) + ?? ? ??1 (??) Summing both equations, we get ?? ???? ??1 (??) + ?? ???? ??0 (??) = 0, which means that ??0 (??) + ??1 (??) = ??????????, which is obviously true, with ?????????? = 1 ???. We can solve this system using standard techniques (therein including using the LST), and get the following result: { ??0 (??) = ?? ?? + ?? + [??0 (0) ? ?? ?? + ?? ]?? ?(??+??)?? ??1 (??) = ?? ?? + ?? + [??1 (0) ? ?? ?? + ?? ]?? ?(??+??)?? Now, these expressions describe the probability of being in either state as time progresses. They do depend on the initial state, i.e., on ???? (0). It is always ??0 (??) + ??1 (??) = 1 If we let ?? ? +?, we observe the following: { ??0 ? lim ???+? ??0 (??) = ?? ?? + ?? ??1 ? lim ???+? ??1 (??) = ?? ?? + ?? And, again, ??0 + ??1 = 1. We call ??0 , ??1 the steady-state probabilities. At the steady state, in fact, they do not depend on the time anymore. On the other hand, ???? (??) is called the transient probability. Note that, while the transient probability does depend on the initial conditions (see the above formulas), the steady-state probability does not. It is independent of the initial conditions. Depending on the initial conditions, the steady-state probability will be approached from below (e.g., if ??0 (0) < ???(?? + ??)), or from above (if the opposite inequality holds). If, instead, ??0 (0) = ???(?? + ??), then the system will be in the steady state ???. However, the fact that a steady state is reached and the value of the SS probabilities will not change. 0 1 m1 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 14 Note that, if we are only interested in SS probabilities, there is a much quicker way to obtain them – notably, one that does not involve differential equations. In fact, by the very definition of steady state, we have that: ???, ?? ???? ???? (??) = 0 Hence, under this hypothesis, we can compute the SS probabilities by solving the following system: { 0 = ??? ? ??1 + ?? ? ??0 0 = ??? ? ??0 + ?? ? ??1 Which is only algebraic. In this case, the two equations are clearly not independent, so we can discard one and use the normalization condition in its stead: ??0 + ??1 = 1. The system is thus: { 0 = ??? ? ??1 + ?? ? ??0 ??0 + ??1 = 1 And its solution is the one that we have just found – yet computed considerably faster. 3.2 Steady-state analysis of birth-death systems The above example reveals something that is indeed general. If we want to compute the steady-state probabilities in a birth-death system (whatever its number of states), there are two ways: a) The complex one, which consists in formulating the CK (differential) equations, solving the system – thus obtaining a solution in the form ???? (??), and getting ???? = lim ???+? ???? (??). b) The simple one, which consists in equating ?? ???? ???? (??) = 0 ??? in the CK equations, solving an algebraic system, and getting ????, ???. The complex one has the (slight) advantage of providing us with the transient probabilities as well, but these are normally uninteresting for our purposes, hence we will use the simple method from now on. Note that the system of the first example – the birth-only process – does not admit a steady state. In fact, it is ???? = lim ???? ???? (??) = 0, ???. It is an unpleasant fact that systems may or may not admit a steady state, and – when they do – they might reach it only under specific conditions (e.g., a constraint on the arrival rates, or something similar). The simple method can only be used if the system does reach a steady state (this is what allows us to set the derivatives to zero in the first place), and this hypothesis must always be tested a posteriori. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 15 Both methods can be applied to systems with an arbitrary number of states, as long as they do admit a steady state. The physical interpretation of “reaching a steady state” is the following: 0 m1 n mn mn+1 The flow of probability through the dashed surface, which is the derivative at the left-hand side of the CK equation, is null. Thus, the outgoing and incoming flows must balance each other, i.e. { (???? + ???? ) ? ???? = ?????1 ? ?????1 + ????+1 ? ????+1 ?? > 0 ??0 ? ??0 = ??1 ? ??1 This said, computing the SS probabilities in a birth-death system is straightforward: a) You draw the CTMC, according to the modeling of your system; b) You formulate the above steady-state equilibrium equations; c) You add the normalization condition, i.e. ? ???? +? ??=0 = 1 This way you get a non-homogeneous algebraic system (non-homogeneity been assured by the constant “1” in the normalization condition), which – as such – admits only one solution. That solution can be computed quite easily, starting from ?? = 0 and working your way up for increasing values of ??. - ?? = 0: from the equation we get ??1 = ??0 ??1 ? ??0 - ?? = 1: we instantiate (???? + ???? ) ? ???? = ?????1 ? ?????1 + ????+1 ? ????+1 and substitute ??1 = ??0 ??1 ? ??0, thus obtaining: (??1 + ??1 ) ? ??1 = ??0 ? ??0 + ??2 ? ??2 (??1 + ??1 ) ? ??0 ??1 ? ??0 = ??0 ? ??0 + ??2 ? ??2 ??2 = 1 ??2 [(??1 + ??1 ) ? ??0 ??1 ? ??0] ? ??0 = ??0 ? ??1 ??1 ? ??2 ??0 - ?? > 1 : after few algebraic manipulations, it is clear that we always obtain ???? = ??0???1?...??????1 ??1???2?...????? ??0 = ? ???? ????+1 ??0 ???1 ??=0 . Note that this expression holds also when ?? = 1. Thus, in the end, we get the following: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 16 { ???? = ? ???? ????+1 ??0 ???1 ??=0 , ?? ? 1 ? ???? = 1 +? ??=0 And the normalization condition can be rewritten as follows: ??0 [1 + ? (? ???? ????+1 ???1 ??=0 ) +? ??=1 ] = 1 A necessary and sufficient condition for the system to admit a steady state (i.e., to be stable) is that the above sum be finite. If that sum if finite, call S the term between square brackets, and we get: { ??0 = 1 ?? ???? = 1 ?? ?? ???? ????+1 ???1 ??=0 , ?? ? 1 Otherwise, we get ???? = 0 ???. Note that the problem of stability only exists with systems with an infinite number of states. In fact, in system with finite states (such as the single-slot buffer) the above sum would only include a finite number of terms, hence would always be finite. Therefore, only systems with infinite states may not reach a steady state. Systems with finite states always do. The above method for computing the SS probabilities is entirely general and can be applied to any birth-death system. The above way of computing probabilities, i.e. “circling” each single state and balancing its outgoing and incoming flow, leads to the so-called global equilibrium equations, and it is not the only one. In fact, at the equilibrium, the outgoing and incoming flow through every surface, circling any number of states, must balance each other out (otherwise some derivative would be non-null). Therefore, one may choose arbitrary perimeters across which to enforce the flow balance, and this sometimes leads to simpler computations. For instance, local equilibrium equations are those written balancing the flows through perimeters including all the states from 0 to n included, and they are the following: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 17 ??0 ? ??0 = ??1 ? ??1 ??1 ? ??1 = ??2 ? ??2 . . . ???? ? ???? = ????+1 ? ????+1 0 1 2 …. n m1 m2 m3 mn mn+1 From which we get ???? = ? ???? ????+1 ??0 ???1 ??=0 , even more quickly than before. As will be apparent later on, global equations are always easy to write. Local equations are easy to write (possibly easier than global ones) when the CTMC is simple, but they quickly get overly complicated if the CTMC is messy: if there are too many arcs around, you run the risk of forgetting something. 3.3 M/M/1 systems Let us now discuss in some detail the simplest birth-death system, which is called an M/M/1 system. The latter is known as Kendall’s notation, and consists of (at least) three indications: - The distribution of interarrival times: M for memoryless (D for deterministic, E for Erlang, G for Generic, etc.) - The distribution of service times: the same letters can appear - The number of servers, one in this case. There can be other indications following these three, such as the system capacity (the max. number of jobs allowed in the system), or the population from which arrivals are drawn. These are both assumed to be infinite in our case, and – when they are – they need not be stated explicitly. We will discuss systems with finite queues and finite populations later on. 0 l l 1 l l 2 …. n l m m m m m Assume ???? = ??, ???? = ??, i.e. arrival and departure rates are constant (or state-independent, or loadindependent), and the queue is infinite. In this case, the relationship derived for generic birth-death processes becomes: ???? = ? ???? ????+1 ??0 ???1 ??=0 = ( ?? ?? ) ?? ??0 ?? ? 0 l m Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 18 We call ?? = ????? the utilization of this system (the reason why it is called like that will be given in a minute). Then the normalization condition is the following: ??0 [1 + ? (? ???? ????+1 ???1 ??=0 ) +? ??=1 ] = 1 ? ??0 [? ?? ?? +? ??=0 ] = 1 Which means that the stability condition is ?? < 1. Under that condition, the above infinite sum converges to 1 1??? , hence ??0 = (1 ? ??) and ???? = (1 ? ??) ? ?? ?? . The fact that ??0 = (1 ? ??) justifies the name of utilization given to ??: in fact, it is ?? = 1 ? ??0 = 0 ? ??0 + 1 ? (1 ? ??0 ), hence ?? is the mean number of jobs in the server – or the fraction of time for which it is busy, hence its utilization. It also helps us to get a physical explanation of the stability condition: if ?? is a utilization, it cannot grow beyond one: as it approaches one, the system becomes unstable, and queues grow to infinity. In fact, ?? < 1 means ?? < ??, i.e. the mean interarrival time 1??? is larger than the mean service time 1???. We call a system where ?? < 1 positive recurrent. When the opposite occurs, ?? > ??, then the system accumulates more and more jobs in the queue as time progresses, hence lim ???? ???? (??) = 0 for all finite values of ??. A system where ?? > 1 is called transient. The case ?? = 1, i.e. ?? = ??, is somewhat tricky to understand. In this case the system is not stable, and the reason why it is not is that it may happen that a very large service time occurs at least once (recall that exponentials have a tail extending to infinity), during which the queue gets so large that it is never able to empty again. We call a system where ?? = 1 null recurrent. For a positive recurrent system, the distribution of the number of jobs in the system at the steady state is geometric: ???? = (1 ? ??) ? ?? ?? , with a success probability ?? = 1 ? ??. Therefore, it is straightforward to compute its mean and its variance, i.e. the main indexes of the number of jobs in the system. It is: ??[??] = ? ?? ? ???? +? ??=0 = ?? 1??? , ??????(??) = ?? (1???)2 It is particularly interesting to observe the behavior of ??[??] as a function of ??. This function is called the Kleinrock function (also called the “hockey-stick”), and its shape is the one in the figure: it is practically flat until ?? = 0.5 (when it reaches 1), and then exhibits a knee and has a vertical asymptote for ?? ? 1. This is the typical behavior of systems under a varying workload: - In low-load conditions, the mean number of jobs in the system is below one (i.e., the system is either empty or serving the one and only job present, most of the time). Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 19 - As ?? grows beyond 0.5, queueing starts to occur frequently. As ?? ? 1, the system saturates, hence a marginal increase in ?? translates to a huge increase in the number of jobs. When you provision a system, the region to the right of the knee point is the one which you will want to avoid. Exercise You have to dimension a network interface for your system. Its workload consists in packets whose length is exponentially distributed with a mean 1???. Packet interarrival times at the interface with are exponential with a mean 1???. Compute the line speed ?? so that: 1) the mean backlog is ?? packets 2) the 95th percentile of the backlog is ? packets We observe that this is an M/M/1 system, with an arrival rate ??. As for the service rate, we get that ??[???? ] = ??[???????????] ?? = 1 ?? , hence we get ?? = ?? ? ??. The first question can be readily answered by observing that the mean backlog is ?? = ??[??] = ?? 1??? = ???(?????) 1????(?????) . We solve the latter for ?? and we get ?? = ???(1+??) ????? . Note that this only holds if the system does admit a steady state, hence if ?? = ???(?? ? ??) < 1. The second question can be answered by solving the following equation: ??{?? ? ?} = 0.95. However, we quickly get ??{?? ? ??} = ? ???? ?? ??=0 = ? (1 ? ??) ? ?? ?? ?? ??=0 = (1 ? ??) ? 1??? ??+1 1??? = 1 ? ?? ??+1 . Therefore, the equation that we need to solve is 1 ? ?? ?+1 = 0.95, i.e.?? ?+1 = 20 ? (?????) ?+1 , i.e. ?? = ?20 (?+1) ? ?? ?? ? 0 5 10 15 20 25 30 35 0 0.2 0.4 0.6 0.8 1 1.2 E[N] knee Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 20 3.3.1 Mean performance indexes The important mean performance indexes in queueing systems are the following: - The mean number of jobs in the system ??[??]. We have already computed it. - The mean number of jobs in the queue (i.e., not counting the one being served), called ??[????] - The mean response time ??[??], i.e. the mean time between the arrival and the departure of the same job. - The mean waiting time ??[??] (or queueing time), i.e. the mean time between the arrival and the start of the service of the same job. This is what people care about, normally. The optimum would be to be able to compute the distributions of all the above quantities. From these, in fact, we can compute everything: mean value, variance, percentiles, etc. However, this is only possible if the system is simple enough. If the system is too complex, we will have to settle for the mean values which are always easy to compute. We have already discussed how to compute ??[??]. Number of jobs in the queue We move to analyzing RV ????.The latter takes on the following values: - 0, with probability ??0 + ??1 (in fact, our queueing systems are work-conserving). - 1, with probability ??2 - ?? ? 1, with probability ????+1. From the above, computing the mean value is quite straightforward: ??[????] = ? ?? ? ????+1 +? ??=1 = ?(?? ? 1) ? ???? +? ??=2 = ?(?? ? 1) ? ???? +? ??=1 = ??? ? ???? +? ??=1 ? ?? ???? +? ??=1 = ??[??] ? (1 ? ??0 ) = ??[??] ? ?? This result (which is common to all the systems with one server) could have been obtained much more easily by observing that mean values are additive, and that ?? is the server’s utilization, i.e., the mean number of jobs in the server. Therefore, it must be ??[????] + ?? = ??[??]. Response time The mean response time can be computed using a general result, which is very useful in many cases. This is called Little’s Law (or Little’s Theorem), and it states the following: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 21 Consider a system in a steady state, such that no jobs are created/destroyed within the system and let ?? be its mean arrival rate: then the mean response time is ??[??] = ??[??]???. Little’s law can be applied to every system at the steady state, under very loose hypotheses: the system may not be FCFS, it may have non-exponential arrivals/departures, whatever. The only requirement is that no jobs are created/destroyed within the system, so that the average arrival rate ?? is also the average departure rate. An intuitive rationale behind Little’s law is the following: if the system is in a steady state, when a job arrives, the number of jobs that it sees ahead of itself is statistically equal to the number of jobs it will leave behind on its departure. The latter is equal to ??[??], and has arrived at a rate ?? during the response time of that job ??[??]. Hence, it makes sense that ??[??] = ??[??]???. Note that Little’s law only applies to mean values, not to distributions. We can use Little’s law to compute ??[??]. In an M/M/1 system it is ?? = ? ???? ? ???? +? ??=0 = ?? ? ? ???? +? ??=0 = ??, so it is fairly easy to see that ??[??] = 1 ?? ? ?? 1??? = 1??? 1??? = 1 ????? . When the load is small ?? ? 1,the response time tends to 1???, which is in fact the mean service time ??[???? ]. This makes perfect sense, since the system will always be empty, and any arriving job will only spend time in the server. As ?? increases, queueing starts to occur frequently, until the system saturates and the response time grows to infinity. Waiting time 0 5 10 15 20 25 30 0 0.2 0.4 0.6 0.8 1 E[R] l E R E N ? ? = ? ? l l l m Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 22 The mean waiting time can be computed by applying Little’s law to the queue at the equilibrium. Note that Little’s law can be applied anywhere, under very broad conditions. Since the system “queue” is in equilibrium, then its arrival and departure rates are equal to ??, hence ??[??] = ??[????] ?? = ??[??]??? ?? = ??[??] ? 1 ?? . The last expression is obvious, since mean values are additive and the mean service time is ??[???? ] = 1 ?? Throughput In queueing systems, it is often required to compute the throughput, i.e., the number of jobs served per unit of time. The throughput is often denoted with ??. We start with an intuitive reasoning: - If ?? > ??, then it means that there are jobs that get out without having been injected in the system. In other words, the system should create jobs internally for this to be possible. This is not the case, of course. - If, on the other hand, ?? < ??, there would be jobs that stay in the queue indefinitely (since they do get in, but they never get out). This is impossible, since the system is FCFS and stable. Therefore, the only possibility is that ?? = ??. This is a given in systems without losses. The only case when ?? < ?? is possible is when systems have finite memory: in this case, due to the interplay of the random arrival and service times, there might be cases when some jobs are rejected. In any case, the formal definition of throughput is the following: ?? ? ? ???? ? ???? +? ??=1 , which in this case is ?? = ?? ????? +? ??=1 = ?? ? (1 ? ??0 ) = ?? ? ?? = ?? 3.3.2 An alternative way to compute mean performance indexes Sometimes computing the steady-state probabilities using the direct method is challenging, because the computations involved are non-trivial. In many cases, we can still compute the mean performance indexes without computing the SS probabilities. The method is quite general (i.e., it can be applied to any birth-death system) and will be exemplified on the M/M/1 for simplicity. Consider the global steady-state equations: { ?? ? ??0 = ?? ? ??1 (?? + ??) ? ???? = ?? ? ?????1 + ?? ? ????+1 ?? ? 1 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 23 The technique is as follows: you multiply each equation by ?? ??, ?? ? ?, |??| < 1, and then sum everything up. We obtain: { ?? ? ?? 0 ? ??0 = ?? ? ?? 0 ? ??1 (?? + ??) ? ?? ?? ? ???? = ?? ? ?? ?? ? ?????1 + ?? ? ?? ?? ? ????+1 ?? ? 1 ?? ? ?? 0 ? ??0 + ?(?? + ??) ? ?? ?? ? ???? +? ??=1 = ?? ? ?? 0 ? ??1 + ??? ? ?? ?? ? ?????1 +? ??=1 + ??? ? ?? ?? ? ????+1 +? ??=1 Then we recall the definition of PGF of a discrete non-negative RV: ??(??) ? ??[?? ??] = ? ?? ?? ? ???? +? ??=0 . In this case, the state of the system ?? is a discrete and non-negative RV. We manipulate the above expression to obtain ??(??): ?? ? ?? 0 ? ??0 + ?(?? + ??) ? ?? ?? ? ???? +? ??=1 = ?? ? ?? 0 ? ??1 + ? ?? ? ?? ?? ? ?????1 +? ??=1 + ? ?? ? ?? ?? ? ????+1 +? ??=1 ??? ? ??0 + (?? + ??) ? ? ?? ?? ? ???? +? ??=0 = ?? ? ?? ? ? ?? ???1 ? ?????1 +? ??=1 + ?? ? ? ?? ?? ? ????+1 +? ??=0 ??? ? ??0 + (?? + ??) ? ? ?? ?? ? ???? +? ??=0 = ?? ? ?? ? ? ?? ?? ? ???? +? ??=0 + ?? ?? ? ? ?? ??+1 ? ????+1 +? ??=0 (?? + ??) ? ??(??) ? ?? ? ??0 = ?? ? ?? ? ??(??) + ?? ?? ? [??(??) ? ??0 ] (?? + ??) ? ?? ? ??(??) ? ?? ? ?? ? ??0 = ?? ? ?? 2 ? ??(??) + ?? ? [??(??) ? ??0 ] We rearrange the terms and obtain: ??(??) = ?? ? ??0 ? (?? ? 1) (?? + ??) ? ?? ? ?? ? ?? 2 ? ?? = ?? ? ??0 ? (?? ? 1) ?? ? (?? ? 1) ? ?? ? ?? ? (?? ? 1) = ?? ? ??0 ?? ? ?? ? ?? = ??0 1 ? ?? ? ?? The latter depends on ??0 , which is unknown and can be set by imposing the normalization condition. From ??(??) ? ??[?? ??] = ? ?? ?? ? ???? +? ??=0 we obtain that ??(1) ? ??[1 ??] = ? 1 ?? ? ???? +? ??=0 = 1, which yields ??0 = 1 ? ??, hence: ??(??) = 1 ? ?? 1 ? ?? ? ?? Note that the above expression can be anti-transformed (this is because this case is particularly simple). In fact, from ??(??) ? ??[?? ??] = ? ?? ?? ? ???? +? ??=0 = 1??? 1?????? = (1 ? ??) ? ? (?? ? ??) +? ?? ??=0 we immediately obtain that ???? = (1 ? ??) ? ?? ?? , which we already knew. However, once you have ??(??), you can compute average performance indexes without anti-transforming it, by only using the well-known properties of the PGF: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 24 - Mean number of jobs: ??[??] = ?? ???? ??(??)|??=1 . In this case, we get: ??[??] = ?? ???? ??(??)|??=1 = ???(1???) (1??????)2 | ??=1 = ?? 1??? . From the latter using simple algebra, one can compute the missing mean performance indexes ??[????], ??[??], ??[??]. - Mean squared number of jobs: ??[?? 2 ] = [ ?? 2 ???? 2 ??(??) + ?? ???? ??(??)] ??=1 . If needed, one can also compute some SS probabilities by deriving the PGF. In fact, it is: - ??0 = lim???0 ??(??) - ???? = ?? (??) (0) ??! = 1 ??! ? ?? ?? ???? ?? ??(??)| ??=0 Therefore, at least the first few SS probabilities (often the most relevant) can be easily computed. 3.3.3 Arrival-time and random-observer probabilities The SS probabilities that we have computed so far are those that a random observer would observe. In other words, if anyone looks at the system at a random time (in the steady state), ???? is the probability that she will observe ?? jobs in the system. There is another important probability, which is the one seen by an arriving job. We call it arrivaltime or tagged-job SS probability, to distinguish it from the random observer’s one, and denote it with ????. In general, the two SS probabilities are different. We show this via a simple yet illuminating example. Consider a queueing system with constant interarrival times, equal to 2s, and constant service times equal to 1s (a D/D/1 system). Such a system is always in a steady state, being deterministic. A trajectory of this system is the following: t N(t) A random observer will observe: - One job in the system, half of the time - Zero jobs in the system, half of the time. Hence it is ??0 = ??1 = 1?2. However, an arriving job always finds the system empty, hence it is ??0 = 1, and ???? = 0, ?? > 0. Therefore, it is in general ???? ? ???? . ? In a (generic) birth-death system with exponential interarrival times, arrival-time probabilities can be found using Bayes’ theorem, as follows. Define: ???? (??) = lim ????0 ??{??(??) = ??|??(??,?? + ???)} Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 25 Where ??(??,?? + ???) means that there is an arrival in [??,?? + ???)3. We develop the computations as: ???? (??) = lim ????0 ??{??(??) = ??|??(??,?? + ???)} = lim ????0 ??{??(??) = ??, ??(??,?? + ???)} ??{??(??,?? + ???)} = lim ????0 ??{??(??,?? + ???)|??(??) = ??} ? ??{??(??) = ??} ? ??{??(??,?? + ???)|??(??) = ??} ? ??{??(??) = ??} +? ??=0 = lim ????0 ??{??(??,?? + ???)|??(??) = ??} ? ??{??(??) = ??} ? ??{??(??,?? + ???)|??(??) = ??} ? ??{??(??) = ??} +? ??=0 = lim ????0 [???? + ??(???) ??? ] ? ???? (??) ? [???? + ??(???) ??? ] ? ???? (??) +? ??=0 = ???? ? ???? (??) ? ???? ? ???? (??) +? ??=0 The above equalities hold ???, hence it holds also at the steady state. At the steady state, we get: ???? = lim ???+? ???? (??) = ???? ? ???? ? ???? ? ???? +? ??=0 = ???? ?? ? ???? where ?? ? is the mean arrival rate. Note that, when ???? = ?? ???, and only under that condition, it is ???? = ???? . Systems where ???? = ???? are said to possess the PASTA property (Poisson Arrivals See Time Average). Nevertheless, there is still a conceptual difference between the two distributions, even when they have the same values, hence we will take some care to use the correct symbol whenever possible. Tagged-job probabilities are useful to compute the distribution of the response and waiting times. In fact, the response time of a job within a system does not start at a random time instant: it starts when that job arrives, hence its distribution must be related to probabilities ????. 3.3.4 Distribution of response and waiting times We have already computed the mean response and waiting time, ??[??], ??[??], through Little’s Law. We now show how to compute the distribution of the response and waiting times, i.e. ????(??), ????(??). We start with the former. 3 Recall that, with continuous RVs (such as arrival times), we cannot posit that anything occurs “at” time ?? with non-null probability. However, we can have it occur within an interval [??,?? + ???), and then let ??? ? 0. The probability that the next arrival occurs by ?? + ??? when the system is in state ?? is: ??{??(??,?? + ???)|??(??) = ??} = 1 ? ?? ????????? However, since we are letting ??? ? 0, we substitute the expansion of the exponential: ?? ????????? = ? (????? ? ???) ?? ??! +? ??=0 = 1 ? ???? ? ??? + ??(???) Hence: 1 ? ?? ????????? = 1 ? (1 ? ???? ? ??? + ??(???)) = ???? ? ??? + ??(???) Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 26 Suppose a job arrives in the system at time ??. Let ?? be the number of jobs already in the system at time ?? ?. We know that – at the steady state – the probability to have ?? jobs in the system at the time of an arrival is ???? (which may or may not be equal to ???? in general – it is in this case). Now, the time that the tagged job will have to spend in the system (i.e., its response time) is composed of: - The residual service time of the one job being served at time ??. - The sum of the service times of all the other ?? jobs, including the tagged one. m tagged job residual transmitted n jobs 1 (partial) job However, since service times are exponential (hence memoryless), the residual service time has the same distribution as the service time: ??{???? > ?? + ??|???? > ??} = ??{???? > ??}. Therefore, the response time is the sum of the service times of ?? + ?? jobs, if there are ?? jobs in the system at the time of arrival. This distribution of the sum of IID exponential is very common, and it is called Erlang distribution. The CDF of an ??-stage Erlang is: ????(??) = 1 ? ??? ????? (????) ?? ??! ???1 ??=0 The PDF is ???? (??) = ?? ????? ? ?? ? (????) ???1 (???1)! Let us take a look at what an Erlang PDF looks like: When ?? = 1 it is an exponential. This is clear both intuitively and from the formulas. When ?? > 1 it starts peaking and then goes down. When ?? gets large, due to the CLT, it looks like a Normal. We can compute ??[???? ] and ??????(???? ) leveraging additivity of mean values and independence (recall that the Erlang is the sum of ?? independent exponentials). Therefore, we get ??[???? ] = ?? ?? , ??????(???? ) = ?? ??2 . From these we obtain ??????(???? ) = ???????(????) ??[????] = 1 ??? . In other words, the CoV of an ??-stage Erlang is smaller than one (and, specifically, it is smaller than an exponential’s), and it gets smaller with ?? (which is again a consequence of the CLT). Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 27 We now know that the sum of ?? + 1 IID exponentials with a rate ?? is an (?? + 1)-stage Erlang distribution, i.e., ????+1 (??) = ?? ? ?? ?????? ? (?????) ?? ??! . This is the PDF of RV ??, given that there are ?? jobs in the system. Therefore, we can compute ???? (??) using Total Probability as follows: ???? (??) = ? ????+1 (??) ? ???? +? ??=0 = ? ?? ? ?? ?????? ? (?? ? ??) ?? ??! ? (1 ? ??) ? ?? ?? +? ??=0 = ?? ? (1 ? ??) ? ?? ?????? ? ? (?? ? ?? ? ??) ?? ??! +? ??=0 = ?? ? (1 ? ??) ? ?? ?????? ? ?? ?????? = ?? ? (1 ? ??) ? ?? ???(1???)??? = (?? ? ??) ? ?? ?(?????)??? = 1 ??[??] ? ?? ??????[??] This is an exponential distribution, hence ????(??) = 1 ? ?? ??????[??] = 1 ? ?? ?(?????)??? . As far as the distribution of the waiting time ?? is concerned, things are only slightly different. We can repeat the same reasoning as for the response time; however, we need a little care: in fact, there is a possibility that the system may be empty at the time of arrival, hence the waiting time will be zero in that case. There is a non-null probability that the waiting time be null, equal to the probability of finding the system empty, i.e., ??0 = 1 ? ??. Therefore, the PDF of the waiting time will be: - Zero, with a non-null probability ??0 = 1 ? ??. - Equal to an ??-stage Erlang distribution (mind the difference: it was ?? + 1 for the response time) with a probability ????, ?? ? 1. Note that the fact that ????(0) = ??{?? = 0} = ??0 > 0 implies that there is a discontinuity at ????(0). The PDF will have a Dirac’s delta in zero. This said, we can use Total Probability again and compute ???? (??): Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 28 ???? (??) = (1 ? ??) ? ??(??) + ? ???? (??) ? ???? +? ??=1 = (1 ? ??) ? ??(??) + ? ?? ? ?? ?????? ? (?? ? ??) ???1 (?? ? 1)! ? (1 ? ??) ? ?? ?? +? ??=1 = (1 ? ??) ? ??(??) + ?? ? ?? ?????? ? (1 ? ??) ? ?? ? ? (?? ? ??) ???1 (?? ? 1)! ? ?? ???1 +? ??=1 = (1 ? ??) ? ??(??) + ?? ? ?? ? (1 ? ??) ? ?? ???(1???)??? = (1 ? ??) ? ??(??) + ?? ? 1 ??[??] ? ?? ??????[??] Area=1?r Area = r fW(x) x 1?r FW(x) x From the above we can easily obtain the distribution ????(??), which is such that: ????(??) = { 1 ? ?? ?? = 0 (1 ? ??) + ?? ? (1 ? ?? ??????[??] ) ?? > 0 , Which boils down to: ????(??) = 1 ? ?? ? ?? ??????[??] ?? ? 0 Now that we have distributions, we can solve problems with percentile constraints: select the server speed so that the 95th percentile of the response (waiting) time is below ??, etc. You just need to solve ????(??) = 0.95 and obtain x as a solution. 3.3.5 Exercise Your boss says that the rate of contacts to your company’s website is going to double next month. She wants you to add more capacity to your website, so that: a) The mean response time will remain the same; b) The 99th percentile of the response time will remain the same. Assuming your web server can be modeled via an M/M/1 system, this boils down to increasing its service rate to match the requirements. Call ??, ?? the current arrival rate and service rate of your website, and let ??? = 2??, ??? be the new arrival and service rates. The equations are: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 29 For case a), i.e. how to keep the mean response time constant: ??[???] = ??[??] 1 ??? ? 2?? = 1 ?? ? ?? ??? = ?? + ?? For case b) we have to consider that ????(??) = 1 ? ?? ??????[??] = 1 ? ?? ?(?????)??? , and that the 99th percentile of the current response time is the solution ??.01 to ????(??.01) = 1 ? ?? ?(?????)???.01 = 0.99, i.e. 1 100 = ?? ?(?????)???.01 ??.01 = log100 ?? ? ?? In the new configuration, the 99th percentile of the response time will be ??.01? = log100 ????2?? , which again means that ??? = ?? + ??. Those who instinctively thought ??? = 2?? can check for themselves that doubling both the arrival and the service rate leads to halving the (mean or 99th percentile) response time. As an aside, case b) shows that setting ??? = ?? + ?? allows you to obtain exactly the same distribution of the response times: in fact, you can match any percentile through the same trick – you will just get a different argument for the logarithm in the above expressions. 3.4 M/M/C systems So far, we have discussed systems with only one server. A frequent case is that of a queue which is drained by more than one server: - Airport check-in, where the single queue is served by several desks; - One queue of transactions waiting to be processed by several redundant disks; - A server farm, with requests being routed to the first idle server; - Networks with ?? parallel links bundled together to increase the capacity. If the ?? servers are equivalent (meaning that they have the same rate ??) and everything else stays the same (i.e., exponential arrivals, exponential service times, infinite memory), then the system is called an M/M/C one. In an M/M/C system, an arriving job is sent to an idle server at random, if one such server exists, otherwise it queues up. We want to derive the SS probabilities for an M/M/C system. We start with ?? = 2, and then we generalize to an arbitrary value of ??. It is quite easy to derive the transition rates in this system4 . In fact: 4 A formal derivation of CK equations for an M/M/2 system can be found in the Appendix. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 30 - Arcs going to the right are the same (with a rate ???? = ??); - Arcs going to the left will have to consider that (at least when ?? ? 2) both servers are busy. Assume you are at time ??, in a trajectory whose value is ??(??) = ??, and ?? ? 2. Both servers are busy, and a job may depart in the future from either of them (but not from both: as for the previous cases, we neglect the occurrence of simultaneous events, since it has a negligible probability). N(t) t residual service time @ server 1 residual service time @ server 2 When will the next downward step in the trajectory occur? When the smallest of the two residual service times (i.e., those of server 1 and of server 2) expires. However, we know that the service times at both servers are IID exponentials with the same rate ??, therefore: - “residual” service times are themselves IID exponentials with a rate ??, since exponentials are memoryless. The adjective “residual” is thus immaterial. - The minimum of two IID exponentials is an exponential with double their rate. Therefore, arcs going to the left, out of states ?? ? 2, will have a transition rate equal to 2??. What about the arc related to the service rate in state 1? In that case the transition rate to the left is still ??, since only one server is busy. The CTMC will then look as follows: 0 l l 1 l l 2 …. n l m 2m 2m 2m 2m We stress again that the fact that the rate of departure is 2?? does not mean that two jobs may leave simultaneously: transitions are still of the nearest-neighbor type, and non-nearest-neighbor transitions have negligible probability. Hence, we get a CTMC with ???? = ??, and ???? = { ?? ?? = 1 2?? ?? > 1 . In this case, service rates are load-dependent. Given the above diagram, we can easily write down both global and local equilibrium equations at the steady state, through visual inspection: 31 Global equilibrium equations ?? ? ??0 = ?? ? ??1 (?? + ??) ? ??1 = ?? ? ??0 + 2?? ? ??2 (?? + 2??) ? ???? = ?? ? ?????1 + 2?? ? ????+1 , ?? ? 2 Local equilibrium equations ?? ? ??0 = ?? ? ??1 ?? ? ???? = 2?? ? ????+1, ?? ? 2 Before solving the above system, we generalize the above reasoning to an arbitrary number of servers ??. We can write down the CTMC keeping in mind that: - Arrival rates are constant; - The service rates will be ???? = { ?? ? ?? ?? ? ?? ?? ? ?? ?? ? ?? = min(??, ??) ? ?? 0 l l 1 l l 2 …. C-1 l m 2m 3m (C-1)m Cm l l n Cm Cm l C Cm ... In order to compute the SS probabilities and the stability condition, we can specialize the general formulas that hold for any birth-death system with nearest-neighbor transitions, i.e.: { ???? = ? ???? ????+1 ??0 ???1 ??=0 , ?? ? 1 ? ???? = 1 +? ??=0 Define ?? = ?????. Note that, with this system, ????? is not the utilization. Symbol ?? denotes the utilization, hence we need a different symbol to avoid confusion. To write the above formulas, we distinguish the two cases: ?? ? ??, ?? ? ??. - When ?? ? ??, we have ???? = ?? ?? ?? ? 2?? ? 3?? ?. . .? ?? ? ?? ? ??0 = ( ?? ?? ) ?? ? 1 ??! ? ??0 = ?? ?? ??! ? ??0 - When ?? ? ??, we have ???? = ?? ?? (?? ? 2?? ? 3?? ?. . .? ?? ? ??) ? (?? ? ?? ?. . .? ?? ? ??) ? ??0 = ( ?? ?? ) ?? ? 1 ??! ? ( ?? ?? ? ?? ) ????? ? ??0 = ( ?? ?? ) ?? ? 1 ??! ? 1 ?? ????? ? ??0 = ?? ?? ?? ????? ? ??! ? ??0 This said, the normalization condition becomes (recall that both expressions are correct when ?? = ??, but we should not count equality twice): Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 32 ??0 ? [? ?? ?? ??! ???1 ??=0 + ? ?? ?? ?? ????? ? ??! +? ??=?? ] = 1 The first summation includes a finite number of terms, hence it is always finite. Thus, the stability condition is the one under which the second summation is finite, i.e.: ? ?? ?? ?? ????? ? ??! +? ??=?? = ?? ?? ??! ? ? ?? ????? ?? ????? +? ??=?? = ?? ?? ??! ??( ?? ?? ) ?? +? ??=0 The condition is clearly ?? < ??, i.e. ?? < ?? ? ??. This could be expected, since ?? is the arrival rate, and ?? ? ?? is the service rate at high loads. If the services cannot keep up with the arrivals when the load is high, then the state is bound to diverge. In fact, in this case it is ?? = ?? ????? (we will see why later on), hence the stability condition is still ?? < 1. This gives us an interesting insight on stability: what actually matters for stability is the balance of the CTMC rates “to the right”, i.e. the fact that ???? < ???? ??? ? ??0. What happens “close to state 0” does not affect stability, although it still influences performance indexes. Under the above condition, the infinite sum converges to 1?(1 ? ??), hence: ??0 = 1 ? ???? ??! ???1 ??=0 + ???? ??! ? 1 1 ? ?? and ???? = { ??0 ? ?? ?? ??! ?? ? ?? ??0 ? ?? ?? ?? ????? ? ??! ?? ? ?? Now that we have the SS probabilities, we can compute all the performance indexes. We start with ??[????], which is easier. ??[????] = ? (?? ? ??) ? ???? +? ??=??+1 = ? (?? ? ??) ? ?? ?? ??! ?? ????? +? ??=??+1 ? ??0 = = ?? ?? ??! ? ??0 ? ? (?? ? ??) ? ?? ????? ?? ????? +? ??=??+1 = ?? ?? ??! ? ??0 ? ? ?? ? ?? ?? +? ??=1 = ?? ?? ??! ? ??0 ? ?? (1 ? ??) 2 From the above, using Little’s Law, we get: ??[??] = ??[????] ?? = ?? ?? ??! ? ??0 ? 1?(?? ? ??) (1 ? ??) 2 In order to compute ??[??], we only need to sum up a mean service time to ??[??], i.e. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 33 ??[??] = ??[??] + ??[???? ] = ?? ?? ??! ? ??0 ? 1?(?? ? ??) (1 ? ??) 2 + 1 ?? And from the latter, applying Little’s Law backwards, we can get ??[??]: ??[??] = ?? ?? ??! ? ??0 ? ?? (1 ? ??) 2 + ?? ?? = ??[????] + ?? ? ?? Again, it is ??[??] = ??[????] + ??[???? ], i.e. the mean number in the queue plus the mean number being served, which is ?? ? ??. The M/M/C system has the PASTA property, so it is ???? = ???? . As far as the throughput is concerned, we get: ?? = ????? ? ???? +? ??=1 = ??? ? ?? ? ???? ?? ??=1 + ? ?? ? ?? ? ???? +? ??=??+1 The computations are not straightforward. However, for pretty obvious physical considerations, the only possibility is that ?? = ??, since the system is in a steady state, and what gets in must get out. Finally, it is interesting to compute the mean number of busy servers. Call ?? the RV “number of busy servers”. The expression is the following: ??[??] = ?min(??, ??) ? ???? +? ??=1 = ??? ? ???? ?? ??=1 + ? ?? ? ???? +? ??=??+1 Again, the computations are not straightforward, and – again – we can find a quicker workaround, which relies on Little’s Law. Apply Little’s Law to the sub-system consisting of the ?? servers, and get the following: - The average response time of the system is ??[???? ] = 1 ?? ; - The input-output rate at the steady state is ?? = ??. Thus, ??[??] = ?? ? ??[???? ] = ?? ?? = ??. This justifies the fact that ?? = ?? ????? = ??[??] ?? . ?? represents the utilization, hence it is the average fraction of busy servers. As this fraction approaches one, the system becomes unstable. Note that the above definition also holds for an M/M/1 system. SS probabilities can be rewritten using ?? instead of ?? via a few algebraic computations: ???? = { ??0 ? (?? ? ??) ?? ??! ?? ? ?? ??0 ? ?? ?? ? ?? ?? ??! ?? ? ?? Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 34 3.4.1 Exercise: comparison of the response time for queueing systems Suppose that you have to build up a computer system that processes transactions. Transactions arrive at a rate ??. You can buy a total computing power equal to ?? ? ??. You are requested to choose among three alternative designs: 1) A system where the incoming traffic is split into ?? Poisson processes5 , each of which is sent to an M/M/1 system whose service rate is ?? (load balancing). 2) An M/M/C system, i.e., where a single queue exists and each of the identical ?? servers have a service rate equal to ??. 3) An M/M/1 system with a more powerful server, whose service rate is ?? ? ??. Which of the three will yield the smallest ??[??]? What is the rationale behind the answer? 3.4.2 Delay centers: M/M/? systems If we take the limit ?? ? +?, we observe a peculiar behavior: since the number of severs is infinite, every job that arrives will find an available server, hence there will be no queueing. The CTMC is the following: 0 l l 1 l l 2 …. n-1 l m 2m 3m (n-1)m nm l n (n+1)m ... The local equilibrium equations are: ????+1 = ?? (??+1)?? ? ???? . The SS probabilities can be written quite easily by specializing the general formula: { ???? = ? ???? ????+1 ??0 ???1 ??=0 , ?? ? 1 ? ???? = 1 +? ??=0 , with ???? = ??, ???? = ?? ? ??. We readily obtain ???? = ( ?? ?? ) ?? ? 1 ??! ? ??0 , ?? ? 0. The stability condition is ??0 ? ? ( ?? ?? ) ?? ? 1 ??! +? ??=0 = 1. However, since ? ( ?? ?? ) ?? ? 1 ??! +? ??=0 = ?? ????? , then this system is always stable, regardless of the values of ??, ??. This means that ???? = ?? ?????? ? (?????) ?? ??! , ?? ? 0. The SS probabilities have a Poisson distribution. M/M/? systems are called delay centers. They model cases when arriving jobs are delayed by a random exponential time before being forwarded (e.g., a user think time between two successive page requests). 5 If a Poisson process with a rate ?? is split probabilistically, i.e. jobs are routed to server ?? with probability ???? , the arrivals at each server will themselves be independent Poisson processes, with rates ???? = ?? ? ???? . Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 35 For an M/M/? system we can easily compute the only relevant performance metric, i.e. ??[??] = ??[??]. By recalling the properties of Poisson distributions, we easily get ??[??] = ??[??] = ?? ?? . 3.4.3 Models, CTMCs and performance indexes It is now time to observe that very different models may admit the same SS probabilities. It is important to understand that these similarities may not extend to all the performance indexes, hence some care must be taken when doing the computations. Here is an example. Example Consider the following two systems: a) An M/M/C system; b) An M/M/1 system with load-dependent service-rate. It is ???? = min(??, ??) ? ??, i.e. the service rate increases with the load, but caps to a maximum of ?? ? ??. It is quite clear that both systems have the same CTMC, hence they will have the same SS probabilities. Since they do, it will be ??[?? (??) ] = ??[?? (??) ]. By Little, since ?? (??) = ? (??) , it will also be ??[?? (??) ] = ??[?? (??) ]. Does this imply that all the performance indexes are equal? 0 l l 1 l l 2 …. C-1 l m 2m 3m (C-1)m Cm l l n Cm Cm l C Cm ... No, it does not. In fact, we have: ??[???? (??) ] = ? (?? ? ??) ? ???? +? ??=??+1 whereas it is: ??[???? (??) ] = ?(?? ? 1) ? ???? +? ??=2 Hence, in general ??[???? (??) ] ? ??[???? (??) ]. The mean waiting time will thus be different as well. ? This is to remind to ourselves that one is never too careful around these systems, and that not everything that you need to know can be found in the CTMC. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 36 3.5 Discouraged arrivals Consider the (likely) case of a system where the more jobs are in the queue, the fewer will join. This happens, for instance, in museums or supermarket tills, where the fact that the queue is long discourages other users from joining it. A common model is one where ???? = ???(?? + 1), and the service rate is constant, ???? = ??. The CTMC is the following: 0 l l/2 1 l/(n?1) l/n 2 …. n-1 l/3 m m m m m l/(n+1) n m ... And the local equilibrium equations are ????+1 = ?? (??+1)?? ? ???? , which are the same as a delay center’s. Therefore, we quickly get the following: a) The system is always stable, whatever the values of ??, ??; b) It is ???? = ?? ?????? ? (?????) ?? ??! , ?? ? 0. The SS probabilities have a Poisson distribution; c) ??[??] = ?? ?? . However, the similarities between a discouraged-arrivals system and a delay center end here. In fact: - Queueing occurs in this system, but not in a delay center. In fact, we have ??[????] = ??[??] ? (1 ? ??0 ) = ?? ?? ? (1 ? ?? ?????? ). - The average arrival rate is different in the two systems, hence everything that is computed through Little (notably, ??[??]) will be different. - This system is non-PASTA, since the arrival rates are not constant, whereas the other is. Therefore, here we have ???? ? ????. This means that we have to compute the average arrival rate, which is defined as ?? ? = ? ???? ? ???? +? ??=0 . However, we know that it must also be ?? ? = ?? ? ? ???? ? ???? +? ??=1 . Since ???? = ??, we obtain that ?? ? = ?? ? (1 ? ??0 ) = ?? ? (1 ? ?? ?????? ) with considerably fewer computations. Therefore, we get: ??[??] = ??[??] ??? = ?? ?? 2 ? (1 ? ?? ??????) ??[??] = ??[????] ??? = [ ?? ?? ? (1 ? ?? ?????? )] ? 1 ??(1 ? ?? ??????) = ?? ?? 2(1 ? ?? ??????) ? 1 ?? = ??[??] ? ??[???? ] ???? = ???? ?? ? ? ???? = ?? (?? + 1) ? ?? ? (1 ? ?? ??????) ? ?? ?????? ? (?????) ?? ??! = ????+1 1 ? ?? ?????? = ????+1 1 ? ??0 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 37 3.6 Systems with finite memory: M/M/1/K Infinite queues are often a useful abstraction. Real systems, however, have finite queues, hence they have losses due to overflow. This means that, in general, the case that ?? < ?? may be given, since some of the jobs will not enter the system. Call ?? the system memory, i.e., the maximum number of jobs that are allowed in the system at any time. When the system is in state ??, the queue is full. Any arrival occurring when the system is in that state will be dropped. If the arrival and service rates are constant, the CTMC will be this: 0 l l 1 l l 2 …. K-1 l m m m m m K From the latter, we can easily infer the local equilibrium equations ?? ? ???? = ?? ? ????+1, 0 ? ?? < ??, hence we will have ???? = ( ?? ?? ) ?? ? ??0 , 0 ? ?? ? ??. The normalization condition now involves a finite sum, hence the system is always positive recurrent (all systems with finite states are), whether ?? < ?? or not. Call ?? = ?????. We obtain: { ???? = ?? ?? ? ??0 , ?? ? 0 ??0 ? ? ?? ?? ?? ??=0 = 1 . However, ? ?? ?? ?? ??=0 = { 1??? ??+1 1??? ?? ? 1 ?? + 1 ?? = 1 , thus: ??0 = 1 ? ?? ???? ??=0 = { 1??? 1?????+1 ?? ? 1 1 ??+1 ?? = 1 , ???? = { 1??? 1?????+1 ? ?? ?? ?? ? 1 1 ??+1 ?? = 1 . The case ?? = 1, i.e. ?? = ??, is quite peculiar: in this case, in fact, the rates of left- and right-bound transitions are the same, hence all the states are equally likely. If ?? < 1 we would expect “low” states to be observed with a larger probability than “high” ones: this is the case, in fact, since ???? is a decreasing sequence. If ?? > 1, instead, ???? is an increasing sequence, which is again expectable for the same reason. We can compute performance indexes (assuming ?? ? 1 from now on, otherwise they are trivial): Please do not forget to consider this case when solving classworks Full? l m K Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 38 ??[??] = ? ?? ? ???? ?? ??=0 = 1 ? ?? 1 ? ????+1 ? ? ?? ? ?? ?? ?? ??=0 = 1 ? ?? 1 ? ????+1 ? ?? ? ?? ???? ? ?? ?? ?? ??=0 = 1 ? ?? 1 ? ????+1 ? ?? ? ?? ???? ( 1 ? ?? ??+1 1 ? ?? ) = 1 ? ?? 1 ? ????+1 ? ?? ? ?(?? + 1)?? ?? ? (1 ? ??) + 1 ? ?? ??+1 (1 ? ??) 2 = ?? 1 ? ?? ? ?(?? + 1)?? ?? ? (1 ? ??) + 1 ? ?? ??+1 1 ? ????+1 = ?? 1 ? ?? ? (1 ? (?? + 1)?? ?? ? (1 ? ??) 1 ? ????+1 ) = ?? 1 ? ?? ? (?? + 1)?? ??+1 1 ? ????+1 Assume ?? < 1: the above formula is similar to the M/M/1 system’s, but it has a negative offset to compensate for the missing states. In this case lim ???+? ??[??] = ?? 1??? , which is in fact what should happen in a stable M/M/1 system. On the other hand, if ?? > 1, as ?? increases, we get the following: ??[??] = ?? 1 ? ?? ? (?? + 1)?? ??+1 1 ? ?? ??+1 = (?? + 1) 1 ? 1 ?? ??+1 ? ?? ?? ? 1 ? ?? ? 1 ?? ? 1 Hence, the number of jobs will be close to ?? in any case, since the transitions to the right occur more often than those to the left. The mean number of jobs in the queue is: ??[????] = ??[??] ? (1 ? ??0 ) = ?? 1 ? ?? ? (?? + 1)?? ??+1 1 ? ????+1 ? (1 ? 1 ? ?? 1 ? ????+1 ) = ?? 1 ? ?? ? ?? ? ?? ??+1 + ?? 1 ? ????+1 An important performance metric of a finite-queue system is the blocking probability or loss probability, i.e. the probability that an arriving job is dropped because the system is full. This is the probability that an arriving job finds the system in state ??. However, to the left of the divide this system is a PASTA system, since the arrival rates are independent of the state of the system (they are constant and equal to ??). Therefore, we have ???? = ???? = ????? ???????+?? ? ?? ?? . Knowing the relationship between ???? and ??, ??, allows one to dimension the queue size ?? based on the expected loss probability given the arrival and service rates. This should be done by solving the above equation numerically, possibly with the help of a spreadsheet. Full? M/M/1/K l ln PASTA Non PASTA 39 Some care must instead be taken when computing response/waiting times through Little’s Law, since response times are computed only for those jobs that pass the above vertical divide. For these ???? is not constant. In fact, it is: ???? = { ?? 0 ? ?? < ?? 0 ?? = ?? Hence, right of the divide, this is a non-PASTA system, with ?? ? = ? ???? ? ???? ?? ??=0 = ?? ? (1 ? ???? ) < ??. This said, we can compute ??[??], ??[??] using ?? ? as a mean arrival rate: ??[??] = ??[??] ??? , ??[??] = ??[????] ??? . Moreover, it is: ???? = ???? ?? ? ? ???? = { ???? 1 ? ???? ?? < ?? 0 ?? = ?? This has an intuitive explanation, since ???? must be equal to zero (no job can enter the system when the queue is full). Therefore, all the other probabilities ??0, . . . ?????1 must sum to one and be proportional to the related random-observer ones (the arrival rates are constant up to state ?? ? 1), hence they can only be ???? (1 ? ???? ? ). Last, but not least, we should compute the throughput. Due to physical reasons, the only possibility is ?? = ???= ??(1 ? ???? ). 3.6.1 Adding queueing space does increase the utilization We have discussed at the beginning that queues are there to increase the utilization of a system. We can now corroborate the above observation with numbers. Let us compute the utilization of an M/M/1/K as a function of ??. We have: ??(??) = 1 ? ??0 (??) = 1 ? 1 ? ?? 1 ? ?? ??+1 = ?? ? 1 ? ?? ?? 1 ? ?? ??+1 When ?? < 1 (i.e., ?? < ?? ), the above expression increases with ?? and ??(?) = lim ???+? ??(??) = ?? ?? . Hence, adding queueing increases the system utilization, up to a maximum achieved when the queue is infinite. For instance, an M/M/1/1 system having ?? ?? = 0.8 can only achieve a utilization of ??(1) ? 0.44 just because jobs are not allowed to queue up when the system is busy. Moreover, increasing the queue also increases the throughput, since it is: ??(??) = ?? ? (1 ? ??0 (??)) = ?? ? ??(??) Again, ??(??) is an increasing sequence and ??(?) = lim ???+? ??(??) = ??. It is also ??(1) ? 0.56 ? ??. However, queueing increases the response time. Let us compute ??[??] as a function of ??. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 40 ??[??] = ??[??] ?? = ?? 1 ? ?? ? (?? + 1)?? ??+1 1 ? ????+1 ?? ? 1 ? ???? 1 ? ????+1 = ?? + ?? ? ?? ??+2 ? (?? + 1)?? ??+1 ?? ? (1 ? ????) ? (1 ? ??) = ?? ?? ? (1 ? ??) ? ?? ? ?? ??+1 ?? ? (1 ? ????) One can clearly see that: lim ???+? ??[??] = ?? ?? ? (1 ? ??) = 1 ?? ? ?? If you plot both ??[??] and ??(??), you get the following (in the example, it is ?? = 1, ?? = 1.2): 1 1.5 2 2.5 3 3.5 4 4.5 5 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 0 10 20 30 40 50 E[R] gamma E[R] gamma K This is typical of queueing systems: when you add buffer space, the achieved utilization (or the throughput) increases faster than the response time. Both eventually reach their maximum value (i.e., the corresponding M/M/1’s), but the utilization increases sooner. This means that adding buffer space has a diminishing performance return: the more you add buffer space, the smaller the return in utilization, and the higher the cost in response time. Of course, this discussion assumes that occasionally losing some input is not a problem. If this is not the case, one should add buffer space until the probability of losing a job is small enough, as shown before. 3.7 Systems with finite populations: M/M/1/*/U It is often the case that a queueing system models a service center providing service to a finite population of users. Typical examples are: - A repair center for broken machines. Once fixed, machines are put back in operation, and broken ones are queued for repair. The overall population of machines is a constant ??. - An I/O device being accessed by a finite number of processes. m U users Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 41 - A network switch having ?? input lines that block when they are being served. Now, assume that users are independent, and that the time a user spends outside the system is exponentially distributed with a rate ??. Then, it follows that, if ?? users are the population and ?? users are inside the system at time ??, then ?? ? ?? are outside the system and may be entering the system in the future. Therefore, the next arrival will occur when the smallest (residual) “outside” time will have elapsed. However, given that outside times are IID exponentials, a) Residual outside times are distributed as outside times (memoryless property). b) The minimum of ?? ? ?? IID exponentials is an exponential with a rate (?? ? ??) ? ??. Therefore, the arrival rates are ???? = (?? ? ??) ? ??. On the other hand, the service rates are constant, ???? = ?? (this is the case if we have only a constant-rate server), and the system will have ?? + 1 states - hence, as long as its memory is at least equal to ??, it does not really matter how large it is. Having said this, it is quite straightforward to draw the CTMC: 0 Ul (U-1)l 1 2l l 2 …. U-1 (U-2)l m m m m m U The system is always stable (it has a finite number of states), and the equilibrium equations are: Global ?? ? ?? ? ??0 = ?? ? ??1 [(?? ? ??) ? ?? + ??] ? ???? = ?? ? ????+1 + (?? ? (?? ? 1)) ? ?? ? ?????1 , 1 ? ?? < ?? ?? ? ???? = ?? ? ?????1 Local (?? ? ??) ? ?? ? ???? = ?? ? ????+1 From the local equilibrium equations, it is quite easy to obtain ???? = ( ?? ?? ) ?? ? ??! (?????)! ? ??0 , 0 ? ?? ? ??. The system is always stable, and we get ??0 from the normalization condition: ??0 ? ? ( ?? ?? ) ?? ? ??! (?? ? ??)! ?? ??=0 = 1, hence ??0 = 1 ? ( ?? ?? ) ?? ? ??! (?? ? ??)! ?? ??=0 We can compute the performance indexes as an exercise: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 42 ??[??] = ? ?? ? ???? ?? ??=0 = ?(?? ? (?? ? ??)) ? ???? ?? ??=0 = ?? ? ?(?? ? ??) ? ( ?? ?? ) ?? ? ??! (?? ? ??)! ? ??0 ???1 ??=0 = ?? ? ? ( ?? ?? ) ?? ? ??! (?? ? (?? + 1))! ? ??0 ???1 ??=0 = ?? ? ?? ?? ? ? ( ?? ?? ) ?? ? ??! (?? ? ??)! ? ??0 ?? ??=1 = ?? ? ?? ?? ? (1 ? ??0 ) From this we get ??[????] = ??[??] ? (1 ? ??0 ) = ?? ? ??+?? ?? (1 ? ??0 ). In order to apply Little’s Law we need to compute: ?? ? = ? ???? ? ???? ?? ??=0 = ?(?? ? ??) ? ?? ? ???? ?? ??=0 = ?? ? [?? ? ??[??]] = ?? ? (1 ? ??0 ) Hence, we get: ??[??] = ??[??] ??? = ?? ?? ? (1 ? ??0 ) ? 1 ?? , ??[??] = ??[????] ??? = ?? ?? ? (1 ? ??0 ) ? 1 ?? ? 1 ?? The last expression confirms that ??[??] = ??[??] + ??[???? ]. Finally, we have: ???? = ???? ?? ? ? ???? = (?? ? ??) ? ?? ?? ? (1 ? ??0 ) ? ( ?? ?? ) ?? ? ??! (?? ? ??)! ? ??0 = ????+1 1 ? ??0 , ?? < ?? As usual, we can devise more complex systems with finite populations and ?? servers, etc. These only bring algebraic complications, and there is nothing interesting from a conceptual standpoint. One might wonder how finite-population systems relate to infinite-population systems (i.e., all the others that we had discussed thus far), and why we normally assume a constant arrival rate in the latter. It is because, when ?? grows to infinity, all numbers ?? ? ?? are not dissimilar to ??, hence the arrival rate is approximately constant. This is the same approximation through which we obtained a Poisson distribution from a binomial, when the number of trials (i.e., individuals in the population) is very large and the probability of success (i.e., that each single individual arrives in the system) is very small. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 43 3.8 Systems with bulk arrivals So far, we have only analyzed systems with nearest-neighbor transitions. However, there are practical cases when non-nearest-neighbor transitions may occur. Consider in fact the following examples: - A processing plant where trucks arrive with exponential interarrival times, carrying a random number of items that must be processed individually. Thus, if we describe the system state using the number of items in the processing plant, one arrival implies a state jump of as many items as the truck contains. - A network protocol sending messages to the underlying protocol. Messages may be arbitrarily long, and they may be fragmented and transmitted separately. In all these cases, if we assume that arrivals are exponential, we retain the property that the only relevant parameter to describe the system state is the number of jobs in the system. However, one arrival will increase the number of queued jobs by more than one unit, so we will have non-nearestneighbor transitions to the right in the CTMC. How do we write the CTMC in this case? Call ?? the RV of the number of jobs per arrival, and let ???? be its PMF, i.e. ???? = ??{?? = ??}. It is ??0 = 0, and (obviously) ? ???? +? ??=1 = 1. This does not necessarily mean that the support of ?? must be infinite: if it is finite, we will have ???? starting from some index ?? ? . Assume that ???? is independent of the interarrival time and service time distribution. Then the rate of the arc going from state ?? to state ?? is ?? ? ??????? . This said, the CTMC can be drawn, though not too easily: 0 lg1 lg1 1 lg1 2 …. lg1 m m m m n lg1 m lg3 lg2 lg2 lgk ... lg2 lg3 ... lgn lg2 ... lg3 lgk The above diagram is quite hard to follow, since: - All states will have as many outgoing arcs to the right as the support of RV ?? allows, each one with a label ?? ? ???? , ?? ? 1. If the maximum number of jobs in a bulk arrival is infinite, there will be infinitely many outgoing arcs to the right from each state. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 44 - Each state ?? will have exactly ?? incoming arcs from the left, labelled ?? ? ??????? , 0 ? ?? < ?? and coming from state ??. - Finally, we still have the service transition going from ?? to ?? ? 1 at a rate ??. This may be quite difficult to do with pen and paper (you may want to write some code, lest you forget something). In any case, you can still write global equilibrium equations (if you try local ones, you will surely end up forgetting some arc). These are simpler than one may think: - With ?? = 0, ? ?? ? ???? +? ??=1 ? ??0 = ?? ? ??1, hence ?? ? ??0 = ?? ? ??1 as usual. - With ?? ? 1, [??? ? ???? +? ??=1 + ??] ? ???? = ?? ? ????+1 + ??? ? ??????? ???1 ??=0 ? ???? i.e. (?? + ??) ? ???? = ?? ? ????+1 + ?? ? ???????? ???1 ??=0 ? ???? Computing the SS probabilities using the direct method (i.e., writing ???? = ????(??0) and enforcing normalization) is probably too difficult in this case. When this is the case, the usual technique to get at least some performance metrics is to switch to the PGFs. We multiply each equation by ?? ?? and sum everything up. { ?? ? ?? 0 ? ??0 = ?? ? ?? 0 ? ??1 (?? + ??) ? ?? ?? ? ???? = ?? ? ?? ?? ? ????+1 + ?? ? ?? ?? ? ? ??????? ???1 ??=0 ? ???? ?? ? 1 (?? + ??) ? ??(??) ? ?? ? ??0 = ?? ? ??1 + ?? ? ? ?? ?? ? ????+1 +? ??=1 + ?? ? ? ? ?? ?? ? ??????? ???1 ??=0 ? ???? +? ??=1 (?? + ??) ? ??(??) ? ?? ? ??0 = ?? ? ??1 + ?? ?? ? [??(??) ? ??0 ? ?? ? ??1 ] + ?? ?? ? ?? ?? ? ??????? +? ??=??+1 ? ???? +? ??=0 (?? + ??) ? ??(??) ? ?? ? ??0 = ?? ?? ? [??(??) ? ??0 ] + ?? ? ??? ?? ? ???? ? ? ?? ????? ? ??????? +? ??=??+1 +? ??=0 (?? + ??) ? ??(??) ? ?? ? ??0 = ?? ?? ? [??(??) ? ??0 ] + ?? ? ??(??) ? ??(??) where ??(??) is the PGF of ??. Thus, we end up with: ??(??) = ?? ? ??0 ? (1 ? ??) ?? ? (1 ? ??) ? ?? ? ?? ? [1 ? ??(??)] n i outgoing incoming Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 45 The normalization condition is ??(1) = 1. Unfortunately, this leads to an undetermined expression, hence we must use De L’Hopital’s rule to get to the bottom of it. We get: lim???1 ???(??) = ??? ? ??0 ??? ? ?? ? [1 ? ??(??)] + ?? ? ?? ? ???(??) | ??=1 = ??? ? ??0 ??? + ?? ? ???(1) = ??0 1 ? ?? ?? ? ??[??] This is because a property of the PGF is that ???(1) = ??[??]. From the latter we get: ??0 = 1 ? ?? ?? ? ??[??] ??0 is a probability, so it must be non-negative. This means that ?? ?? ? ??[??] < 1, which is our stability condition. In fact, it is quite clear that ?? = (1 ? ??0 ) = ?? ?? ? ??[??], since ?? ? ??[??] is the actual average rate of job arrivals. This yields the following expression for ??(??): ??(??) = ?? ? (1 ? ??) ? (1 ? ??) ?? ? (1 ? ??) ? ?? ? ?? ? [1 ? ??(??)] As an exercise, let us instantiate the above in some simple cases: Single arrivals: ???? = { 1 ?? = 1 0 ?? ? 1 Thus, we get ??(??) = 1 ? ?? 1 = ??. Under the condition that ??0 = 1 ? ?? ?? ? ??[??] > 0, i.e. ?? = ?? ?? ? ??[??] = ?? ?? < 1, we get: ??(??) = ?? ? (1 ? ??) ? (1 ? ??) ?? ? (1 ? ??) ? ?? ? ?? ? [1 ? ??] = 1 ? ?? 1 ? ?? ? ?? We know that the latter is the PGF of the M/M/1 SS probabilities ???? = (1 ? ??) ? ?? ?? . Constant-batch multiple arrivals: ???? = { 1 ?? = ?? 0 ?? ? ?? In this case ??[??] = ??, ??(??) = 1 ? ?? ?? = ?? ?? , hence the stability condition is ?? = ?? ?? ? ?? < 1, which makes sense intuitively. Hence, we get (recall that 1 ? ?? ?? = (1 ? ??) ? ? ?? ???1 ?? ??=0 ): ??(??) = ?? ? (1 ? ??) ? (1 ? ??) ?? ? (1 ? ??) ? ?? ? ?? ? [1 ? ?? ??] = 1 ? ?? 1 ? ?? ?? ? ? ?? ?? ?? ??=1 Thus, we get: ??[??] = ?? ???? ??(??)|??=1 = ?? ???? [ 1 ? ?? 1 ? ?? ?? ? ? ?? ?? ?? ??=1 ] ??=1 = (1 ? ??) ? ?? ?? ? ? ?? ? ?? ?? ???1 ??=1 [1 ? ?? ?? ? ? ?? ?? ?? ??=1 ] 2 | ??=1 = ?? ? (?? + 1) 2 ? (1 ? ??) Note that, when ?? = 1, we obtain the familiar formula of of M/M/1 systems: ??[??] = ?? 1??? . Geometric arrivals: ???? = (1 ? ??) ? ?? ???1 , ?? ? 1 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 46 Thus, we get ??(??) = ? ?? ?? ? ???? +? ??=1 = ? ?? ?? ? (1 ? ??) ? ?? +? ???1 ??=1 = (1???)??? 1?????? Under the condition that ??0 = 1 ? ?? ?? ? ??[??] > 0, i. e. , ?? = ?? ?? ? 1 1 ? ?? < 1 In this case, we get: ??(??) = ?? ? (1 ? ??) ? (1 ? ??) ?? ? (1 ? ??) ? ?? ? ?? ? [1 ? (1 ? ??) ? ?? 1 ? ?? ? ?? ] = ?? ? (1 ? ??) ? (1 ? ??) ? (1 ? ?? ? ??) ?? ? (1 ? ??) ? (1 ? ?? ? ??) ? ?? ? ?? ? (1 ? ??) = (1 ? ??) ? 1 ? ?? ? ?? (1 ? ?? ? ??) ? (1 ? ??) ? ?? ? ?? = (1 ? ??) ? 1 ? ?? ? ?? 1 ? (?? + ?? ? ?? ? ??) ? ?? This is hard to anti-transform. However, we can still find some interesting data: ??0 = lim???0 ??(??) = 1 ? ?? ??1 = ?? ??????(??)| ??=0 = (1 ? ??) ? [ ??? ? [1 ? (?? + ?? ? ?? ? ??) ? ??] + (1 ? ?? ? ??) ? (?? + ?? ? ?? ? ??) [1 ? (?? + ?? ? ?? ? ??) ? ??] 2 ] ??=0 = (1 ? ??) ? ?? ? (1 ? ??) [1 ? (?? + ?? ? ?? ? ??) ? ??] 2 | ??=0 = (1 ? ??) ? ?? ? (1 ? ??) ??[??] = ?? ???? ??(??)|??=1 = (1 ? ??) ? ?? ? (1 ? ??) [1 ? (?? + ?? ? ?? ? ??) ? ??] 2 | ??=1 = (1 ? ??) ? ?? ? (1 ? ??) [(1 ? ??) ? (1 ? ??)] 2 = ?? (1 ? ??) ? (1 ? ??) The same procedure can be used with systems having bulk services, i.e. where arcs going to the right may imply more than a single state jump. Computations tend to be nastier for these systems. 3.9 Systems with non-exponential service time distributions So far, we have assumed that: - Interarrivals are exponential; - Service times are exponential. And we have described a theory that allows one to find not only mean values of the steady-state performance indexes, but also – in most cases – their distributions. There are cases when interarrival and (more frequently) service times cannot be fitted to an exponential distribution. In these l m exponential general Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 47 cases, the analysis is made complex by the fact that the number of jobs in the system is not a sufficient characterization of its state anymore. Despite this, some results can be found, for instance for the M/G/1 system, i.e. the one with exponential interarrivals, general service times and one server. By “general” we mean that any distribution can be used (including the exponential, which would make this system an M/M/1, for which we have a direct method). Let ???? be the RV that models the service times, and let us assume that ??[???? ] = 1??? and ??????(????) are known. If ?? = ?? ?? < 1, then the system is stable and Pollaczek and Khinchin’s formula states that: ??[??] = ?? + ?? 2 + ?? 2 ? ??????(????) 2 ? (1 ? ??) = ?? + ?? 2 ? [1 + ??????(???? ) 2 ] 2 ? (1 ? ??) Note the following: - given ??[??], one can always compute the other three mean performance indexes (waiting time, response time and number of jobs in the queue), using Little’s law and few other obvious tricks; - when ???? is exponential, PK’s formula yields Kleinrock’s formula for M/M/1 systems. The version of PK’s formula that mentions explicitly the CoV is quite insightful, since we know that the exponential’s CoV is equal to 1. This means that the mean number of jobs in the system will also depend on “how variable” service times are. If the service is deterministic (which we call an M/D/1 system), then it will be ??????(????) = ??????(????) = 0, and we will have the smallest possible average number of jobs in a system. PK’s formula shows that the variability of the service time increases the queue occupancy. If that variability is very high (e.g., the service time distribution is fat- or heavy-tailed), then a system may become congested even when ?? ? 1. This confirms that it is very important to pick the right model for the service times, otherwise you will end up thinking that your system has negligible queueing when in fact it does not. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 48 PK’s formula tells us something which has a strong physical significance: queueing arises from variability (or randomness). In a system where both interarrival times and service times are constant (i.e., a D/D/1 system), there is no queueing as long as ?? ? ?? (yes, we can also afford equality here). If either or both the interarrival times and the service times are variable, then there will be queueing. Queueing arises from jobs “bunching up”. If interarrival times are stochastic, there will be jobs that arrive close to each other, and this generates queueing. If service times are stochastic, there will occasionally be a long service time, during which many jobs will queue up. The higher the variability, the longer the queue will be on average. Because of Little’s law, the same can be said of the response and waiting times. PK formula computes ??[??] exactly, but it does not allow you to compute steady-state probabilities in a closed form. For instance, you cannot compute ??{?? ? 3}. If results like this are required, you have two choices: the first one is to analyze your M/G/1 system using the method of the imbedded Markov chain. This method yields exact results (for the PGF), but it requires an entirely different mathematics, related to discrete-time processes (ours are continuous-time). If you are interested, just check any QT book. An alternative method is that of Phase-Type distributions to obtain approximate numerical results, with a tunable trade-off between accuracy and complexity. With that method, you model the general service-time distribution using compositions of exponential distributions. This way, you can still write down a (more complex) CTMC, and you can solve it using numerical techniques (the so-called Neuts’ matrix-analytic method). This method is well described in QT books too. In a few moments, we will present an interesting case of the application of this method, for which the maths we introduced so far is enough. First, we give another result. 0 1 2 3 4 5 6 7 8 9 10 0 0.2 0.4 0.6 0.8 1 E[N] CoV=1 (D)(D) CoV=0 (D)(D) CoV=10 (D)(D) Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 49 3.9.1 M/G/? systems and insensitivity Another interesting result is the one for the M/G/? system. This is one where there are infinitely many identical servers, but the distribution of the service time is general. For this system, the steadystate probabilities are exactly the same as the M/M/?’s. In other words, the SS probabilities for an M/G/? system depend only on the mean value of the service time, and not on its particular distribution. Any distribution with the same mean will yield the same results. This is called insensitivity property, and such a property is a rare gem in queueing theory. Systems with insensitivity properties are usually found when there is no queueing. This is in fact one such case. In fact, if there are infinite servers, the variability of the service time does not really matter, since a long service time will not create queueing. 3.9.2 Exercise: M/En/1 system Consider now a system where the service time distribution is an ??-stage Erlang distribution, for which the service time is the sum of ?? IID exponentials, each with a rate ?? ? ??. The Erlang distribution is a subclass of Phase-Type distributions. The mean service time will of course be ?? ? 1?(?? ? ??) = 1???. This system can be modeled by a server that is constituted of ?? serving stages, such that only one job may be in service at any time. The next job will enter the first service stage after the current job leaves the last service stage, so that no two jobs are being served concurrently. Assume that we count the number of residual stages to be traversed in order to clear the backlog, as a state characterization. In a possible trajectory, a job leaving a service stage would count as a unitary downward step. On the other hand, an arrival will count as an upward step of ?? stages, increasing by ?? the total number of service stages that need to be traversed. Therefore, we would obtain a CTMC which is, by all accounts, the same as the one of a constant-batch bulk-arrival system, ?? being in fact the batch length, where left-bound arcs have a rate ?? ? ??. Once more, the number in the circles is not the number of jobs in the system, it is the total number of stages that must be traversed in order to clear the backlog. 0 1 2 …. nm n nm nm nm nm n+1 nm l l n+2 l For the latter, we already have formulas: l nm nm ... nm n Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 50 ??(??) = ?? ? ?? ? (1 ? ??) ? (1 ? ??) ?? ? ?? ? (1 ? ??) ? ?? ? ?? ? [1 ? ?? ??] = 1 ? ?? 1 ? ?? ?? ? ? ?? ?? ?? ??=1 , where ?? = ?? ????? ? ?? = ?? ?? < 1. Calling ?? the number of stages, we get ??[??] = ???(??+1) 2?(1???) . If one need to compute SS probabilities for the number of stages in the system (call it ???? ), she can try either to antitransform the PGF, or to compute the first ?? probabilities by differentiating the PGF. For each number of stages ??, the corresponding number of jobs is ?? = ???????, so one can obtain SS probabilities for the number of jobs as well. From the latter, it would not be too difficult to compute the distribution of the response times (the procedure would be similar to the one we used for the M/M/1). Also note that the mean number of jobs in the system can always be computed via PK’s formula. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 51 4 Queueing Networks So far, we have examined queueing systems in isolation. Queueing Theory allows you to deal with systems composed by several queue+server subsystems, which are called queueing networks. Queueing networks can be either: - Open: these do interact with the external environment, which injects jobs (external arrivals) and absorbs jobs leaving the QN. In these, the number of jobs in the system is a variable. Discovering that number (or, more correctly, its steady-state distribution) is in fact the main purpose of the analysis. - Closed: there is no interaction with the external world. The number of jobs in the system is constant and it is an input datum. In these, we normally want to measure the throughput. A typical example of a queueing network is the following (transactional server): CPU g p0 p1 m1 I/O device 1 m2 I/O device 2 m3 p2 The server has one CPU and two I/O devices (e.g., disks). Jobs arrive from the outside, hence the QN is an open one. When they arrive, they first spend some random time on the CPU. That service time is exponentially distributed with a mean 1???1 . After that, they can: - Leave, with a probability ??0 - Queue at device 1, with probability ??1 - Queue at device 2, with probability ??2 And it is obviously ??0 + ??1 + ??2 = 1. After being processed at an I/O device, a job comes back to the CPU, and starts over again. Therefore, a job may pay several visits to the same service center before leaving the network. In the above model, all SCs have been assumed to be M/M/1, but it does not have to be so. If you have – for instance – a multicore CPU, modeling it as an M/M/C would be more appropriate. We may want to add a delay center on the link coming back from the I/O devices to the CPU, to model some interaction with users (e.g., the need to press a key), etc. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 52 Closed QNs are a bit more difficult to envisage. One way to picture a closed QN is to figure out an open QN, and then connect its output to its input, so that a job “leaving” the network is immediately fed back to the input. This models a situation when a system admits a finite number of jobs simultaneously, and as soon as one job is completed and leaves the network, another one replaces it. A typical case of a system modeled using a closed QN is a multiprogrammed system, where the number of processes is constant. Another case is modeling network paths, e.g. to solve flow-control problems. For instance, a network path can be modeled by a chain of servers. The fact that flow control is in place is modeled by fixing the number of packets to the flow-control window size. In a closed QN like this, we want to know the throughput, i.e. how fast packets circulate. m1 m2 SC 1 SC 2 SRC m3 SC 3 m6 m5 m4 DST SC 6 SC 5 SC 4 How do we describe a QN? We need to know: - The network topology, which can be represented by a directed graph. Let ?? be the number of SCs in the network. - The rates of the external arrivals at each SC, at least those that do admit external arrivals, call them ???? . - The service rates at each SC ???? , and the number of servers ???? . - The routing matrix ??, whose entries ????,?? are the probabilities that a job leaving SC ?? reaches SC j. If ? ????,?? ?? ??=1 < 1, then ????,0 = 1 ? ? ????,?? ?? ??=1 is the probability that a job will leave the QN after visiting SC ??. The state of the network at a given time ?? will be a vector6 ??(??) = [??1 (??), ??2 (??), . . . ????(??)] ?? , where each ???? (??) represents the number of jobs at SC ?? at time ??. If the network admits a steady state, then we will have SS probabilities associated to each vector ?? = [??1, ??2, . . . ????] ?? . In other words, we will define ???? = ??(??1, ??2, . . . , ????) = ??{??1 = ??1, ??2 = ??2, … , ???? = ????} , the JPMF of RVs ??1, ??2, . . . , ????, each one representing the number of jobs on SC ??. 6 It should be a column vector. However, writing column vectors takes up too much space, therefore we will often write them as row vectors instead and add a “transpose” symbol. This is not very elegant, but it makes for concise reading. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 53 4.1 Characterizing the output of a service center In a QN, the output of a SC constitutes part of the input for another SC. We have not discussed yet how to characterize the output of a SC. Consider an M/M/1 SC at the steady state (but the result is more general, and holds for an M/M/C, even with ?? ? ?), whose interarrival times are distributed as ????(??) = 1 ? ?? ?????? , and whose service times are distributed as ????(??) = 1 ? ?? ?????? . We want to compute the distribution of the inter-departure times ????(??) = ??{?? ? ??}. We leverage the Total Probability law, and get: ????(??) = ??{?? ? ??} = ??{?? ? ??|?? > 0} ? ??{?? > 0} + ??{?? ? ??|?? = 0} ? ??{?? = 0}. Let us discuss the two terms separately: - ??{?? ? ??|?? > 0}: when ?? > 0 , the next job starts service as soon as the previous one leaves. Therefore, the inter-departure times are distributed as the service times: ??{?? ? ??|?? > 0} = ????(??). - ??{?? ? ??|?? = 0}: when ?? = 0, a job departing at time ??0 leaves the system empty. Therefore, the inter-departure time, i.e. the time until the next job departs, consists of two contributions: one (residual) interarrival time, and one service time. However, residual interarrival times are distributed the same as interarrival times, because the exponential is memoryless. Thus, ??{?? ? ??|?? = 0} = ??{?? + ?? ? ??}. Furthermore, note that ??{?? > 0} = ?? and ??{?? = 0} = 1 ? ??. Therefore, we have: ????(??) = ??{?? ? ??} = ????(??) ? ?? + ??{?? + ?? ? ??} ? (1 ? ??). In order to write ??{?? + ?? ? ??} simply, we can switch to the LST domain. In fact, ????+?? = ???? ? ????, because of the convolution property and since ?? and ?? are independent. Now, ???? = ?? ??+?? , and ???? = ?? ??+?? , hence: ???? = ?? ?? + ?? ? ?? + ?? ?? + ?? ? ?? ?? + ?? ? (1 ? ??) = ?? ?? + ?? + ?? ?? + ?? ? ?? ?? + ?? ? ?? ? ?? ?? = ?? ?? + ?? ? (1 + ?? ? ?? ?? + ?? ) = ?? ?? + ?? ? ?? + ?? ?? + ?? = ???? Since LSTs are univocal, this can only mean that ????(??) = ????(??) = 1 ? ?? ?????? . In other words, the inter-departure times have the same distribution as the interarrival ones. This is somewhat t0 t1 t2 Interarr. time Serv. time Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 54 surprising, and should not be misconstrued. The above result does not mean that interarrival times between two jobs are preserved at their departure, which would be false. Only, that the interdeparture time of those two jobs will be drawn from the same distribution as the interarrival one. This result is general, and holds for M/M/C systems, for any value of ??. Let us enounce it more formally: Burke’s Theorem (a.k.a. “?? ? ??” property) Given an M/M/C system in a steady state, whose average arrival rate is ??, then: a) The departure process is a Poisson one, with a rate ?? b) ???, the number of jobs in the system ??(??) is independent of the inter-departure times in [0,??). ? Burke’s theorem has a straightforward consequence. Take a tandem (or “linear”) QN like the one in the figure, consisting of two M/M/1 SCs. In the latter, the arrivals at SC 2 are a Poisson process with a rate ??, and ??1 (??) is independent of what happens downstream – and, in particular, it is independent of ??2 (??). This means that ???? = ??(??1, ??2 ) = ??1 (??1 ) ? ??2 (??2 ) = [(1 ? ??1 ) ? ??1 ??1] ? [(1 ? ??2 ) ? ??2 ??2], where from now on ???? (???? ) will denote “the probability that ???? jobs are at SC ??”, i.e. the PMF for node ??, with a slight but necessary deviation from the usual notation. Of course, we still need to check a posteriori that ???? < 1 ???, otherwise no SS probabilities exist. We say that such a network has a product form, i.e.: we can write joint, network-wide SS probabilities as the product of per-SC SS probabilities. 4.2 From Burke’s theorem to queueing networks Burke’s theorem has many important consequences. Take any acyclic network with probabilistic routing, where each SC is an M/M/C. Acyclic means that there is no feedback loop (for instance, part of the output of SC 5 being fed back to SC 2 would constitute a feedback loop). l m1 m2 SC 1 SC 2 m3 SC 3 m4 SC 4 m5 SC 5 p1 1?p1 p2 1?p2 m2 We know that the output of SC 1 is a Poisson process with a rate ?? (by Burke’s Theorem). Can we characterize the input to SC 2 and SC 3? l m1 m2 SC 1 SC 2 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 55 This is relevant, since in a QN it may happen that two or more Poisson processes are merged into one to generate the input to a node. It may also happen that the output of a node is split probabilistically into two or more flows (through routing), which then form the input of two different SCs. l1 m l2 SC 1 SC 2 p 1-p l m1 m2 We can observe straightforwardly that the superimposition of independent Poisson processes is a Poisson process, with a rate equal to the sum of the rates. In fact, a Poisson process has exponential interarrival times. The next arrival will occur when the shortest (residual) interarrival time expires, but we know that, with independent exponentials: a) the adjective “residual” is immaterial (exponentials are memoryless); b) the minimum is still an exponential with a rate equal to the sum of the rates. Therefore, the superimposition of two independent Poisson processes is itself a Poisson process, with a rate equal to the sum of the rates. If, instead, a Poisson process is split probabilistically: arrivals are Poissonian with a rate ??, and they are routed to SC 1, with a probability ??, or to SC 2, with a probability 1 ? ??. Then the arrivals at either SC are themselves independent Poisson processes, with rates ??1 = ?? ? ??, ??2 = ??(1 ? ??). This can be obviously generalized to a probabilistic splitting of a process into ?? processes, with probabilities ???? ??.??. ? ???? = 1 ?? ??=1 . Thus, coming back to the above example, we now know the following: - by Burke’s theorem, the output process at SC 1 is Poisson with a rate ??; - the probabilistic splitting of a Poisson process is still a Poisson process, hence arrivals at SC 2 are Poisson with a rate ??1 ? ?? and those to SC 3 are Poisson with a rate (1 ? ??1 ) ? ??; - still by Burke’s theorem, the number of jobs at each SC is independent; - the superimposition of independent Poisson processes is still a Poisson process, hence arrivals at SC 4 are Poisson with a rate ??1 ? ??2 ? ?? and those at SC 5 are Poisson with a rate [??1 ? (1 ? ??2 ) + (1 ? ??1 )] ? ?? = (1 ? ??1 ? ??2 ) ? ??; All the above SCs are M/M/C where the arrival and service rates are known, hence: we can compute stability conditions for each of them, in isolation; Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 56 - we can compute SS probabilities for each of them in isolation, call them ???? (???? ), under the respective stability conditions7 . Burke’s theorem guarantees that, if all the stability conditions are verified simultaneously, then: ???? = ??(??1, ??2, ??3, ??4, ??5 ) = ????? (???? ) 5 ??=1 . Therefore, all acyclic networks with probabilistic routing have a product form, and their inputs and outputs are Poisson processes. Furthermore, we can easily compute ??[???? ], ??[???? ] (by applying Little’s Law to each SC), ??[??] = ? ??[???? ] 5 ??=1 , and ??[??] = ??[??]???. If required, we can also compute distributions of response times at the single service centers, etc. Note that this holds if queues are infinite. Infinite queues are a requirement of Burke’s Theorem. 4.2.1 Queueing networks with feedback loops l m SC 1 p 1?p g Ext. arrivals, avg.=1/l Feedback arrivals Feedback arrivals Let us consider instead an open queueing network with a feedback loop such as the one in the figure: jobs leave the network with a probability 1 ? ?? and are sent back to SC 1 with a probability ??. This is, of course, not a tandem network. We know that the superimposition of independent Poisson processes is a Poisson process. However, the external arrivals and the arrivals on the feedback loop are by no means independent. This can be shown through a simple example: if ?? ? ?? and ?? is close to 1, then one external arrival will trigger a burst of arrivals at the feedback loop (on average 1?(1 ? ??)), whose average spacing is a service time 1???. The burst eventually dies out, and another one occurs after the next external arrival. Thus, arrivals on the feedback loop are triggered by an external arrival, hence the two processes are not independent. Moreover, the arrival process at SC 1 is not a Poisson one. What is surprising is that, despite the above, the departure process is still a Poisson one, with a rate ?? ? (1 ? ??). In fact, as long as the external arrivals are Poisson, then even QNs with feedback arcs, like the one above, still admit a product form. 7 Thus far, we have denoted with ???? (??) the probability of finding ?? jobs in a queueing system at time ??. Since we now discuss queueing networks at the steady state, we need to alter the notation a bit: from now on we will write ???? (??) to denote the SS probability of finding ?? jobs at SC ??. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 57 4.3 General results for open queueing networks It is now time to lay down the hypotheses under which an open network admits a product form. We define an open Jackson’s network as a directed graph whose nodes are M/M/C SCs, and whose arcs represent routing among SCs. Each arc has a weight equal to the routing probability: ????,?? is the probability that a job leaving SC ?? will reach SC ??. We call ????,0 the probability that a job leaves after visiting SC ??. It is, of course, ? ????,?? ?? ??=0 = 1, ???. Moreover, ????,?? must be independent of the network’s state. In other words, the routing probability must not change based on how jobs are distributed in the network (which, for instance, excludes dynamic load balancing from this kind of modeling8 ). Finally, at each SC external arrivals are Poissonian with a rate ???? . Vector ?? = [??1 , . . . , ???? ] ?? must not be identically null (otherwise the QN is not an open one). Summing up: 1) ?? M/M/???? SCs. At each SC ??, the ???? severs have a service rate ???? ; 2) Poisson external arrivals ?? = [??1, . . . , ????] ?? ; 3) Markovian routing, i.e., the routing probabilities are state-independent; 4) arcs are traversed in zero time (the only delay is at the nodes). The above four hypotheses define an open Jackson’s network. OJNs do admit a product form, as per the following theorem. Jackson’s Theorem In an OJN, under hypotheses 1-4 above, if ???? = ???? ???? ????? < 1 ??? , then it is ???? = ??(??1, . . . , ????) = ? ???? (???? ) ?? ??=1 , where: ???? (???? ) = { ???? (0) ? (???? ? ???? ) ???? ???? ! ???? ? ???? ???? (0) ? ???? ???? ? ???? ???? ???? ! ???? ? ???? are the SS probabilities of an M/M/???? system whose severs have a rate ???? . If ???? = 1 (i.e., an M/M/1 system), the SS probabilities collapse to (1 ? ???? ) ? ???? ???? . ? 8 By dynamic load balancing, we mean, for instance, the policy of routing a job to the downstream SC with the smallest queue. This would make routing probabilities dependent on the state of the downstream SCs. SC1 SC2 SC3 g1 p1,2 p2,0 g3 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 58 The only missing tile in the above picture are the arrival rates ???? , which are assumed to be known quantities in the above theorem. Obtaining the arrival rates is rather straightforward. A job arrives at SC ?? because: a) it arrives from the outside, at a rate ???? , or b) it leaves SC ?? and is routed to SC ??, according to routing probability ????,?? . This yields the following relationship: ???? = ???? + ? ????,?? ? ???? ?? ??=1 , which holds for every SC ??. The above equality can be written in a matrix form, i.e.: ?? = ?? + ?? ?? ? ??, where ?? = {????,?? } is the routing matrix. This means that the arrival rates at each SC can be computed by solving the above matrix equation, i.e. ?? = (?? ? ?? ?? ) ?1 ? ??. The latter can be solved at least numerically using a spreadsheet software. In most cases, ?? can be obtained in a closed form. Note that, if you sum up all the ???? = ???? + ? ????,?? ? ???? ?? ??=1 on index ??, you get the following: ????? ?? ??=1 = ????? ?? ??=1 +??????,?? ? ???? ?? ??=1 ?? ??=1 ????? ?? ??=1 = ????? ?? ??=1 +????? ? ?????,?? ?? ??=1 ?? ??=1 ????? ?? ??=1 (1 ??????,?? ?? ??=1 ) = ????? ?? ??=1 ????? ?? ??=1 ? ????,0 = ????? ?? ??=1 Which confirms that, at the steady state, the aggregate input and output rates for the QN must be the same. We instantiate the above procedure in a simple example. Writing I/O balance equations at each SC is in fact the quickest way to compute the arrival rate vector ?? . Example Consider the following system, which consists of ?? + 1 M/M/1 SCs. SC m+1 g p0 p1 mm+1 SC1 m1 SC m-1 mm-1 pm-1 SC m mm …. pm Changing the symbol for this index to avoid confusion Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 59 The routing matrix and the external arrivals are the following: ?? = [ 0 0 . . . 0 1 0 0 . . . 0 1 . . . . . . . . . . . . . . . 0 0 . . . 0 1 ??1 ??2 . . . ???? 0 ] , ?? = [ 0 0 . . . 0 ?? ] . Rather than by inverting matrix (?? ? ?? ?? ), the above system can be solved faster by considering I/O balance: ?? = ????+1 ? ??0, hence ????+1 = ?? ??0 . Moreover, from the graph it is clear that: ???? = ????+1 ? ???? = ?? ??0 ? ???? , 1 ? ?? ? ?? Thus, the stability conditions are: { ???? = ?? ???? ? ???? ??0 < 1 1 ? ?? ? ?? ????+1 = ?? ????+1 ? ??0 < 1 And, if the above conditions hold, then it is: ???? = ??(??1, ??2, . . . , n??+1 ) = ????? (???? ) ??+1 ??=1 = ?(1 ? ???? ) ? ???? ???? ??+1 ??=1 Given the above, we can easily compute some performance metrics: ??[??] = ? ??[???? ] ??+1 ??=1 = ? ???? 1 ? ???? ??+1 ??=1 ??[????] = ? ?? [?????? ] ??+1 ??=1 = ? ???? 2 1 ? ???? ??+1 ??=1 ? If one wants to know which SC contributes to the overall response time how, some care must be observed. It stands to reason that the overall response time ??[??] depends on the SC’s response times ??[???? ]. By Little’s law, we can also write ??[??] = ??[??]?????????, where ???????? = ? ???? ?? ??=1 , i.e. ??[??] = ??[??] ???????? = ? ??[???? ] ???????? ?? ??=1 = ? ??[???? ] ???? ?? ??=1 ? ???? ???????? = ???[???? ] ?? ??=1 ? ???? ???????? Why is there a multiplying coefficient ????????????? in the last sum? Because a SC can be visited never, once or more than once while a job traverses the QN. Each SC’s response time ???? must therefore be multiplied by the mean number of visits to that SC. Define ???? as the RV that counts the number of visits to SC ??. Then, we define the mean residence time at SC ?? as ??[???? ] = ??[???? ] ? ??[???? ]. The OJN’s response time is the sum of the residence times, ??[??] = ? ??[???? ] ?? ??=1 , which implies that: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 60 ??[???? ] = ???? ???????? The mean number of visits to a SC is equal to its arrival rate divided by the total external arrival rate. We can now continue the above example and compute the response times and the mean number of visits: Example (continued) We compute the OJN’s response time and the individual residence times. We already know that ???? = { ?? ? ???? ??0 1 ? ?? ? ?? ?? ??0 ?? = ?? + 1 , ???? = { ?? ???? ? ???? ??0 < 1 1 ? ?? ? ?? ?? ???? ???0 < 1 ?? = ?? + 1 . Thus, we can compute straightforwardly: ??[???? ] = ???? 1????? = { ??????? ???? ???0???????? 1 ? ?? ? ?? ?? ???? ???0??? ?? = ?? + 1 , ??[??] = ? ??[???? ] ??+1 ??=1 = (? ??????? ???? ???0???????? ?? ??=1 ) + ?? ????+1???0??? . Through Little’s Law, we can compute the OJN’s response time: ??[??] = ??[??] ???????? = (? ???? ???? ? ??0 ? ?? ? ???? ?? ??=1 ) + 1 ????+1 ? ??0 ? ?? We can obtain the same result by computing the mean number of visits to each SC and their mean residence time: ??[???? ] = ???? ???????? = { ???? ??0 1 ? ?? ? ?? 1 ??0 ?? = ?? + 1 , ??[???? ] = 1 ???? ? ???? 1????? = { ??0 ???? ???0???????? 1 ? ?? ? ?? ??0 ???? ???0??? ?? = ?? + 1 , hence ??[???? ] = ??[???? ] ? ??[???? ] = { ???? ???? ???0???????? 1 ? ?? ? ?? 1 ???? ???0??? ?? = ?? + 1 . One can readily check that ??[??] = ? ??[???? ] ??+1 ??=1 . ? 4.4 Closed Queueing Networks We now move to analyzing closed Jackson’s networks. The hypotheses we posit are the same as for OJNs, with a major difference: we assume that no external arrivals/departures occur, and that the number of jobs is a constant ??, which is given as an input datum. Everything else stays the same (M/M/C SCs, Markovian routing, etc.). Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 61 Note that, if the number of jobs is fixed, the state space ?? has a finite cardinality, since there will be a finite number of ways to distribute ?? jobs among ?? SCs. The fact that it is finite does not imply that it is small. In fact, one could check that the following property holds: |?| = ( ?? + ?? ? 1 ?? ? 1 ) In fact, the above expression is the number of ways to insert ?? ? 1 “division marks” in a line of ?? + ?? ? 1 elements, i.e. all the possible ways to separate ?? items into ?? (possibly empty) subsets. The above property implies that |?| = ??(?? ???1 ). In practical cases (few tens SCs and jobs) the state space is really huge. Since CJNs are a variation of OJNs, we may attempt to use the same solution procedure as for OJNs, keeping in mind that we will have ???? = 0 and ????,0 = 0 ???. However, we soon face a major problem. If we attempt to compute the arrival rates at each SC, we get the following equation: ?? = 0 + ?? ?? ? ??. This is a homogeneous system; hence it admits: - no solution (except the null one, which is however unhelpful), if the routing matrix ?? ? ?? ?? has full rank; - infinite solutions otherwise. Luckily, our routing matrix does not have full rank, since ? ????,?? ?? ??=1 = 1 ??? (recall that ????,0 = 0), which leaves us with infinite solutions. In particular, if ?? = [??1,??2, . . . ,????] ?? is one solution to ?? = 0 + ?? ?? ? ??, then ?? ? ??, ?? ? ?, will be a solution as well. This means that we can only obtain solutions which depend on a multiplying constant, and we must find some way to get rid of that constant. Our problem is solved by the following theorem: Gordon and Newell’s Theorem In a CJN, take any solution to system ?? = 0 + ?? ?? ? ??, and call it ?? = [??1,??2, . . . ,????] ?? . Call ???? = ???? ???? ? . Then, ???? = ??(??1, . . . , ????) = 1 ??(??,??) ? ? ???? (???? ) ?? ??=1 , where: ???? (???? ) = { (???? ? ???? ) ???? ???? ! ???? ? ???? ???? ???? ? ???? ???? ???? ! ???? ? ???? And ??(??,??) is a normalizing constant such that ? ?? ????? ?? = 1, i.e., ??(??,??) = ? (? ???? (???? ) ?? ??=1 ) ???? . ? Note that expressions ???? (???? ) are almost the SS probabilities of an M/M/???? SC, the only thing missing being a multiplying factor ???? (0). Of course, if a SC is an M/M/1, then ???? (???? ) = ???? ???? (this is a special Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 62 case that we will develop further later on). Moreover, note that we have a normalizing constant ??(??, ??), which is only fair given that we have chosen our initial solution to the routing equation arbitrarily. The fact that we can write ??(??, ??) = ? ? ???? (???? ) ?? ???? ??=1 does not imply that this is the most efficient way to compute it. In fact, the above computation is prohibitive in most cases. Even if we give up computing ??(??,??) in a closed form and settle for a numerical solution, we incur the risk of numerical instability, since large powers and sums are involved. Luckily for us, there is an efficient algorithm to compute ??(??,??). This will be discussed in a minute, after giving an example of application of GN’s theorem. Example Consider a CJN with two M/M/1 SCs. Its routing matrix is trivially ?? = [ 0 1 1 0 ]. Hence the solution to the routing equation is ??1 = ??2. Thus, the arrival rates are the same, and they can be defined but for a multiplying constant. This implies that we can set ???? to any value, and the solution will not be affected by it (the normalizing constant ??(??,??) will, but the SS probabilities will not). This means that the smart thing to do is to choose ???? so as to simplify computations. In this case, a good choice would be ??1 = ??1 (??1 = ??2 would do just as well). By doing so, we get ??1 = 1, ??2 = ??1 ??2 ? . By GN’s theorem, we get ??(??1, ??2 ) = 1 ??(2,??) ? 1 ??1 ? ( ??1 ??2 ) ??2 . Having in mind that ??1 + ??2 = ??, this can be rewritten as ??(?? ? ??, ??) = 1 ??(2,??) ? ( ??1 ??2 ) ?? , ?? being the number of jobs at SC 2. In this case it is quite easy to compute ??(??,??) directly from the normalization formula. In fact, it is: ??(2,??) = ? (? ???? (???? ) 2 ??=1 ) ???? = ? ( ??1 ??2 ) ?? ?? ??=0 . Assuming ??1 ? ??2 , it is ??(2,??) = 1?(??1???2 )??+1 1???1???2 , thus: ??(?? ? ??, ??) = 1 ? ??1???2 1 ? (??1???2 ) ??+1 ? ( ??1 ??2 ) ?? This is intuitively clear: if ??1 > ??2 , then SC 1 is faster than SC 2, which means that one is more likely to find many jobs at SC 2 (i.e., ??(?? ? ??, ??) should increase with ??). Otherwise, if ??1 < ??2 then SC 1 is slower than SC 2, which means that ??(?? ? ??, ??) should decrease with ??. Finally, if ??1 = ??2 , it is ??(2,??) = ?? + 1, and each state is equally likely. ? We are now left with two problems: first, we need a computationally efficient (and, possibly, numerically stable) way to compute ??(??,??). Second, we need to compute the performance indexes. SC1 m2 SC2 m1 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 63 4.4.1 Buzen’s convolution algorithm This algorithm allows one to compute ??(??,??) efficiently. If all SCs are M/M/1, the algorithm completes in ??(?? ? ??) steps and only requires filling up a table. More involved computations are required if some SCs are load-dependent (i.e., they have more than one server). The general version of the algorithm can be found on QT textbooks – hereafter we will stick to the simplified one. For a CJN of M/M/1 SCs, Buzen’s algorithm is strikingly simple. Consider the definition ??(??,??) = ? ? ???? (???? ) ?? ???? ??=1 , and set apart all the vectors in ?? where ???? = 0. We can write the above equality as: ??(??,??) = ? ????? (???? ) ?? ???? ??=1 ????=0 + ? ????? (???? ) ?? ???? ??=1 ????>0 = ? ????? ???? ?? ???? ??=1 ????=0 + ? ????? ???? ?? ???? ??=1 ????>0 Now, in the first addendum, we can stop the product at ?? ? 1 (since the last factor will be ???? ???? = ???? 0 = 1). On the other hand, in the second addendum the last term in the product can be written as ???? ???? = ???? ? ???? ?????, with ????? ? 0, since ???? > 0. This leads to: ??(??,??) = ? ????? ???? ???1 ???? ??=1 ????=0 + ???? ? ? (????? ???? ?? ??=1 ) ???? ??????0 One may observe that: - the first addendum is the normalizing constant of a CJN with ?? jobs circulating among ?? ? ?? SCs (the ????? one is in fact empty). In fact, the state space for that CJN is ? ? {(??1, ??2, . . . , ?????1, 0): ???? ? 0, ? ???? ???1 ??=1 = ??}. Thus, the first addendum is ??(?? ? 1,??). - In the second addendum, we have “set apart” one factor ???? , i.e. one of the circulating jobs, “pinning” it at SC ??. The sum is therefore the normalizing constant of a CJN with ?? ? ?? jobs circulating among ?? SCs (the ?? ??? job is in fact the one “pinned” on SC ??). The state space for this CJN is ? ? {(??1, ??2, . . . , ?????1, ?????): ???? ? 0, ????? ? 0, (? ???? ???1 ??=1 ) + ????? = ?? ? 1}. Thus, we can replace that sum with ??(??,?? ? 1). This yields the following recursive formula: ??(??,??) = ??(?? ? 1,??) + ???? ? ??(??,?? ? 1) If we know the initial conditions for the above formula, we can compute ??(??,??) for arbitrary values of ?? and ??. However, these initial conditions are quite straightforward. We need to compute: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 64 - ??(1, ??), i.e., the normalizing constant of a CJN with one SC and ?? jobs. But the state space ? of that CJN includes only one state, i.e. ?? jobs at the one and only SC. Thus, it is ??(1, ??) = ? ? ???? ?? ???? ???? ??=1 = ??1 ?? , ??? ? 0. - ??(??, 0), i.e., the normalizing constant of a CJN with ?? SCs and 0 circulating jobs. Again, for a CJN like this, the state space ? includes only one state, i.e. the one where all the ?? SCs are empty. Thus, ??(??, 0) = ? ? ???? ???? ?? ???? ??=1 = ? ???? ?? 0 ??=1 = 1, ??? ? 0. Given the above initializations, we can run the algorithm with the help of a simple table (this is even quicker if you use a spreadsheet software). The table has ?? + ?? rows (from 0 to ?? included) and ?? columns, and it is written as follows: SC ?? ?? … ?? ? ?? ?? ?? Jobs ???? ???? … ??????? ???? ?? 1 1 … 1 1 ?? ???? {???????? ??????????} + {?????????? ??????????} × {??????. ??????? ??????????} … ?? (???? ) ?? … ?? (???? ) ?? … … … … … … … ?? ??? (???? ) ????? … ??(??,?? ? 1) ?? (???? ) ?? … ??(?? ? 1,??) ??(??, ??) Once the first row and column have been initialized, we start filling the table from the top left corner, going down first, and then right. In each cell, the only operation required is to multiply the value above by the one at the heading of the column, and add to this result the value in the cell to the left. At the end the required constant ??(??,??) will appear at the bottom-right corner. We will see later on that other values in the table will be useful as well. If the values in the above table get numerically unstable, then you may want to scale up/down the solution that you chose when you first solved the routing equation. A good choice is to select an initial solution such that the ???? are around one as much as possible. If the algorithm is run on a spreadsheet, that initial value can be written in a cell and modified at will to improve numerical stability, without having to redo all the computations. 4.4.2 Performance indexes in Closed Queueing Networks Given ??(??,??), you can compute ???? for every vector ?? ? ?. Thus, you can compute all the performance indexes. These are amazingly simple, and they involve ratios of ??(??,??) for some indexes ??,??. ??(??,0) ??(1, ??) ?? ?? Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 65 CDF, PMF and mean number of jobs at a single SC We want to compute ???? (??) = ??{???? ? ??} and ???? (??) = ??{???? = ??}. Let us first compute ??{???? ? ??}. In fact, this can be computed by “setting apart” ?? jobs at SC ??, and repeating the same reasoning of Buzen’s algorithm. It is: ??{???? ? ??} = ? ???? ???? ??????? = 1 ??(??, ??) ? ? ???? ??? ?? ???? ?=1 ??????? = = 1 ??(??,??) ? ? ( ???? ??? ?? ?=1 ???? ? ???? ?????+?? ) = ???? ??????0 ??(??,?? ? ??) ??(??,??) ? ???? ?? Both ??(??,?? ? ??) and ??(??,??) can be read in the last column of the table. From the above we get: ???? (??) = ??{???? ? ??} = 1 ? ??{???? ? ?? + 1} = 1 ? ??(??,?? ? (?? + 1)) ??(??,??) ? ???? ??+1 ???? (??) = ??{???? ? ??} ? ??{???? ? ?? + 1} = ???? ?? ??(??,??) ? [??(??,?? ? ??) ? ???? ? ??(??,?? ? (?? + 1))] Note that, if we define ??(??, ??) = 0 when ?? < 0, we can also compute both the CDF and the PMF with ?? = ??. From ???? (??) we can compute ??[???? ]: ??[???? ] = ??? ? ???? ?? ??(??,??) ? [??(??,?? ? ??) ? ???? ? ??(??,?? ? (?? + 1))] ?? ??=1 = 1 ??(??,??) ? [??? ? ???? ?? ? ??(??,?? ? ??) ?? ??=1 ? ? ?? ? ???? ??+1 ? ??(??,?? ? (?? + 1)) ???1 ??=1 ] = 1 ??(??,??) ? [??? ? ???? ?? ? ??(??,?? ? ??) ?? ??=1 ? ?(?? + 1) ? ???? ??+1 ? ??(??,?? ? (?? + 1)) ???1 ??=1 + ? 1 ? ???? ??+1 ? ??(??,?? ? (?? + 1)) ???1 ??=1 ] = 1 ??(??,??) ? [??? ? ???? ?? ? ??(??,?? ? ??) ?? ??=1 ? ? ? ? ???? ? ? ??(??,?? ? ?) ?? ?=2 + ? ???? ? ? ??(??,?? ? ?) ?? ?=2 ] = 1 ??(??,??) ? [???? ? ??(??,?? ? 1) + ? ???? ? ? ??(??,?? ? ?) ?? ?=2 ] = 1 ??(??,??) ? [? ???? ? ? ??(??,?? ? ?) ?? ?=1 ] = ???{???? ? ??} ?? ??=1 Joint probabilities at two or more SCs Similarly, we can compute joint probabilities for two or more SCs, e.g. ??{???? ? ??, ???? ? ??}. The trick is always the same, i.e. to set apart ?? jobs at SC ?? and ?? jobs at SC ??. The result is: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 66 ??{???? ? ??, ???? ? ??} = ??(??,?? ? (?? + ??)) ??(??,??) ? ???? ?? ? ???? ?? Utilization For a single SC, this can easily be computed as ???? = ??{???? ? 1} = ???? ? ??(??,???1) ??(??,??) . If we need the probability that two or more SCs are simultaneously busy, we easily get: ????,?? = ??{???? ? 1,???? ? 1} = ??(??,?? ? 2) ??(??,??) ? ???? ? ???? , and so on. Throughput of a SC The throughput of a SC ?? is equal to ???? when the latter is busy, hence: ???? = ???? ? ???? = ??(??,?? ? 1) ??(??,??) ? ???? ? ???? . Response time of a SC The response time can be computed through Little’s law, as: ??[???? ] = ??[???? ]????? = ? ???? ? ? ??(??,?? ? ?) ?? ?=1 ???? ? ??(??,?? ? 1) . Example Consider a CJN of ?? = 5 identical SCs in a tandem, having ?? = 8 circulating jobs. Compute: 1) the mean number of jobs at a SC; 2) the mean response time of a SC, and the mean circuit time. Explain the result; 3) the probability that all SCs are simultaneously busy. 1 2 ... 5 The routing matrix is: ?? = [ 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0] Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 67 Trying to solve ?? = ?? ?? ? ?? obviously yields ???? = ??. Thus, one may conveniently set ???? = ??, which leads to ???? = 1. This means that the SS probabilities will be uniform (which is intuitively clear, given the symmetry of the CJN). In fact, it is: ???? = 1 ??(??,??) ??1 ???? ?? ??=1 = 1 ??(??,??) Moreover, it is: ??(??, ??) = ??1 ???? ?? ??=1 = ???? |?| = ( ?? + ?? ? 1 ?? ? 1 ) = ( 12 4 ) = 495 since all states are equally likely. However, we will still run Buzen’s convolution algorithm, both as a cross check and because we need intermediate values in the table to compute performance indexes: SC 1 2 3 4 5 ?? jobs 1 1 1 1 1 0 1 1 1 1 1 1 1 2 3 4 5 2 1 3 6 10 15 3 1 4 10 20 35 4 1 5 15 35 70 5 1 6 21 56 126 6 1 7 28 84 210 7 1 8 36 120 330 8 1 9 45 165 495 1) The mean number of jobs per SC is: ??[???? ] = 1 ??(??,??) ? [? ???? ? ? ??(??,?? ? ?) ?? ?=1 ] = 1 ??(??,??) ? [???(??,?? ? ?) ?? ?=1 ] = [. . .] = 8 5 The latter could have been obtained reasoning by symmetry. 2) The utilization of each of the SC is: ???? = ??{???? ? 1} = ???? ? ??(??,?? ? 1) ??(??,??) = 330 495 = 2 3 Thus, the throughput is ???? = 2 3 ? ??, and the mean response time at a SC is: ??[???? ] = ??[???? ] ???? = 8 5 ? 3 2 ? ?? = 12 5 ? ??[???? ] Thus, the mean circuit time is ?? ? ??[???? ] = 5 ? 12 5 ? ??[???? ] = 12 ? ??[???? ]. This result has an intuitive explanation: each job has to be served ?? times in a full circuit. While traveling along Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 68 the circuit, it will find ahead of itself other ?? ? ?? jobs. Therefore, the average cycle time should be ?? + ?? ? 1 times the average service time, which is in fact the above result. 3) The probability that all SCs are busy at the same time is: ??(??, ?? ? ??) ??(??,??) ? 1 ? 1 … ? 1 = 35 495 = 7 99 ? 4.5 Classed queueing networks The fact that OJNs and CJNs have probabilistic routing is somewhat unpleasant. Quite often, systems that we would like to model as QNs offer service to several classes of jobs, and routes are different depending on the class. For instance, you may have a computer network where several flows (each having its source and destination) traverse a number of routers. In that case, the routes for the flows will be different, but they will be fixed, and not probabilistic. The same model can be used to represent a manufacturing plant, where each product line has a different line of assembly, which involves visiting several assembly points in a fixed order. One assembly point may provide service for different products simultaneously. We would model product lines as classes of jobs, assembly points as service centers, and the sequence of assembly points to be visited as a fixed per-class route. f1 1 2 3 4 5 f2 For instance, we might have a QN where: - Flow 1 traverses SCs 1, 2, 3 (call it route R1). - Flow 2 traverses SCs 3, 2, 4, 5 (call it route R2). In this case, there is no probabilistic routing, meaning that all jobs belonging to flow 1 will follow route R1, and all packets from flow 2 will traverse route R2. Jackson’s hypothesis of Markovian routing does not hold anymore. If, instead, we assume that routing probabilities depend on the class of a job, we can just assign different classes to flow 1 and flow 2, and write down two routing matrices (one per flow/class) that describe the routing: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 69 ???? = [ 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] ???? = [ 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0] Nothing prevents adding to this model (static) load balancing per class, e.g., f1’s packets that leave node 2 going to either node 4 or node 3, with given probabilities. 4.5.1 Classed queueing systems in isolation Let us take a look at classed systems in isolation first. Defining the state of a SC in a classed network is not so easy. In fact, the behavior of the SC is not determined anymore by the number of jobs in the system, but also by the class of each and every job. In fact, the state of a SC having ?? jobs is an ??-tuple of class indicators: ?? = (?? (1) , ?? (2) , … ?? (??) ), meaning that job 1 (the one at the head of the queue) is of class ?? (1) , job 2 is of class ?? (2) , etc. This implies that analyzing classed QNs is somewhat notationally heavy, although conceptually simple. We give the following results (without proof – please refer to any QT book if you need one). Theorem 1 (classed M/M/1) Take an M/M/1 SC with ?? classes 1 … ??. Assume that the arrival processes of each class ?? are independent. Call ?? (??) their arrival rate, and let ?? = ? ?? ?? (??) ??=1 . Call ?? = ??/??. If ?? < 1, then we have: ???? = ?? (?? (1) ) ? ?? (?? (2) ) ? … ?? (?? (??) ) ?? ?? (1 ? ??) ? In other words, to obtain the SS probability of a state ??, you multiply the arrival rates of the class that each job belongs to, and everything else is unchanged with respect to the formula for an unclassed M/M/1. Note that: - if you have only one class, the above formula collapses to the classical M/M/1’s, and it only depends on the overall number of jobs; - in a classed system, the probability is the same for any two states with the same number of jobs per class, arranged in a different order (the product at the numerator is in fact commutative). Therefore, it depends only on the number of jobs of each class, not on their position in the queue. This last property allows us to find something useful: ... m l (1) l (2) l (c) Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 70 Corollary 1 (classed M/M/1) The probability that a classed M/M/1 SC has ?? jobs overall (whichever their class) is: ??{?? ???????? ???? ????} = ?? ?? ? (1 ? ??) ? Proving the above is easy. In fact, it is: ??{?? ???????? ???? ????} = ??…????? ?? (??) ?? (2) ?? (1) = (1 ? ??) ?? ?? ??? (?? (1) )??? (?? (2) ) …??? (?? (??) ) ?? (??) ?? (2) ?? (1) = (1 ? ??) ?? ?? ? ?? ?? = ?? ?? ? (1 ? ??) But then, we do not even need a proof. If the arrival processes for each class are independent, all we need is to acknowledge that – for the sole purpose of counting the jobs inside the system – the result must be indistinguishable from an unclassed M/M/1 whose arrival rate is ?? = ? ?? ?? (??) ??=1 . 4.5.2 Open classed queueing networks It turns out that classed Open QNs still admit a product form, i.e. the probability of a certain network state is the product of the probabilities of the states at the single SCs. Theorem 2 (product form for classed OJNs) In a classed OJN of ?? M/M/1 SCs, as long as ???? < 1, 1 ? ?? ? ??, steady-state probabilities admit a product form: ??{??1,??2,…????} = ? ?????? ?? ??=1 Where ?????? are those of Theorem 1. In order to compute ???? = ? ???? ?? (??) ??=1 , the arrival rate ???? (??) of class- ?? jobs at SC ?? must be determined by solving ?? times the per-class versions of arrival-rate equations, i.e., ?? (??) = ?? (??) + ?? (??) ?? ? ?? (??) Moreover, the probability of finding ?? = (??1, ??2, … ????) jobs at the M SCs (again, whichever their class) has a product form too: ???? = ???{???? ???????? ???? ???? ??} ?? ??=1 = ????? ???? ? (1 ? ????) ?? ??=1 ? This means that the only added complication when dealing with classed OJNs is that you have to compute the arrival rates for each class individually, and then aggregate them into per-SC arrival Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 71 rates. All things considered, the analysis of classed QNs is not conceptually more difficult – it just requires a few more computations. 4.5.3 Exercise – response times in a routed network f1 1 2 3 4 5 f2 - Flow 1 traverses SCs 1, 2, 3 (call it route R1). - Flow 2 traverses SCs 3, 2, 4, 5 (call it route R2). Compute the average end-to-end delay for packets of flow 1 and flow 2. Call ?? (1) the arrival rate of flow/class 1, and ?? (2) that of flow/class 2. We straightforwardly obtain the arrival rates for each class at each SC through visual inspection: - Flow 1: ??1 (1) = ??2 (1) = ??3 (1) = ?? (1) , ??4 (1) = ??5 (1) = 0 - Flow 2: ??3 (2) = ??2 (2) = ??4 (2) = ??5 (2) = ?? (2) , ??1 (2) = 0 Thus, we can compute per-SC arrival rate values: ??1 = ??1 (1) + ??1 (2) = ?? (1) ??2 = ??2 (1) + ??2 (2) = ?? (1) + ?? (2) ??3 = ??3 (1) + ??3 (2) = ?? (1) + ?? (2) ??4 = ??4 (1) + ??4 (2) = ?? (2) ??5 = ??5 (1) + ??5 (2) = ?? (2) Assuming that ???? > ???? ???, the mean number of jobs at each SC is finite, hence the mean response time at each SC is (by Little’s law): ??[???? ] = ???? 1 ? ???? ? 1 ???? = 1 ???? ? ???? Therefore: - For flow 1, we get: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 72 ??[??] = 1 ??1 ? ?? (1) + 1 ??2 ? (?? (1) + ?? (2)) + 1 ??3 ? (?? (1) + ?? (2)) ; - for flow 2, we get: ??[??] = 1 ??3 ? (?? (1) + ?? (2)) + 1 ??2 ? (?? (1) + ?? (2)) + 1 ??4 ? ?? (2) + 1 ??5 ? ?? (2) The above result makes perfect sense intuitively. Note that you cannot obtain the same result modeling the above network as an unclassed OJN, since you would need to choose routing probabilities (namely, ??2,4 and ??2,3) arbitrarily. The probability that a packet leaving SC 2 is routed to SC 3 depends on its belonging to flow 1, hence on flow 1’s sending rate compared to flow 2’s. Therefore, routing would not be state-independent, and you would not be able to use Jackson’s theorem. 4.6 Closing remarks on FCFS queueing networks All the QNs we have discussed so far have service centers with FCFS queueing. In order to analyze FCFS QNs, we require that service times are exponential, otherwise we simply cannot perform the analysis (without exponential service times there is no product form). FCFS queueing is typical of: - Computer networks, where jobs are packets and they are transmitted atomically; - Human systems, where jobs are in fact human beings, and they are served atomically too. FCFS QNs (especially classed ones) are good models for the above systems. In a computer network, servers model the links between routers. If packets have constant size, the exponential service time hypothesis does not hold, yet the results we obtain through Markovian analysis (e.g., ??[??]) can be proved to be upper bounds of those you would compute in the real systems. Therefore, QT may give you interesting results even when its hypotheses are not met. Class-dependent routing is a nice modeling tool, since it allows to model per-flow network routing. The assumption that the service time depends on the server, and not on the class, is somewhat limiting. We would like to have class-dependent service times, but these models do not allow it. Note that we have dealt with open classed QNs only. The product form extends to closed classed QNs, and to mixed classed QNs (i.e., those that are open w.r.t. one class and closed w.r.t. another). These generalizations can be found on most QT books. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 73 5 Processor-sharing queueing systems When modeling computer systems as queueing systems, we would like to model the tasks that run on a processor as jobs, and the CPU as a server. In this case, however, tasks share the processor time, often equally through (e.g.) round-robin scheduling. In this case, modeling things in terms of FCFS queueing is not a good idea. For ?? tasks sharing a processor with a service rate ??, it would be more reasonable to assume that all jobs are served simultaneously at a rate ?????, where “simultaneous” service is an abstraction for a fast-paced time-sharing service, where the granularity of the time slices can be neglected. We call a system like this a processor-sharing queueing system. In Kendall’s notation, we denote it as M/M/1/PS (if both arrivals and services are memoryless), as opposed to the M/M/1/FCFS, which we had only called M/M/1 thus far, omitting to specify the queueing discipline. Luckily, there are interesting results covering PS systems, including networks of PS systems (which do admit product forms). PS systems are in fact easier to analyze than FCFS systems – because they do not have queueing. Let us model an M/M/1/PS through a CTMC. We can do this since interarrivals and service times are memoryless, hence the number of jobs in the system should be the only necessary state characterization. - When there are zero jobs, the only thing that can happen is a new job arrival, with a rate ??. Clearly, arrivals occur at a rate ??, whatever the state. The only thing that requires some discussion is thus the service rate. - When there is one job, it has the whole server to itself. There is no difference between this case and the one of a M/M/1/FCFS system holding just one job, hence the arc going to the left has a rate ??. - When there are two jobs, it is as if each was served by a dedicated server of rate ???2. Note that when the second job joins the system, the first one has already been served for a while. However, its residual service time is still exponential, due to the memoryless property. Therefore, the arc going to the left is the one of an M/M/2/FCFS system when two jobs are in, i.e. it has a rate 2 ? ???2 = ??. - When the system is in state ??, the transition to ?? ? 1 will occur when the minimum among ?? (residual) service times expires. However, all service times are exponential with a rate ?????, hence the arc going to the left has a rate ?? ? ????? = ??. l m Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 74 The conclusion is that the CTMC is the same as an M/M/1/FCFS’. Hence, the SS probabilities are the same. 0 l l 1 l l 2 …. n l m m m m m If ?? < 1, then ???? = (1 ? ??) ? ?? ?? , hence ??[??] = ?? 1??? , ??[??] = ??[??] ?? = 1??? 1??? = 1 ????? , exactly the same as an FCFS’s. Note that ??[????],??[??] do not make sense here. Recall that in a PS system there is no queueing. In fact, PS systems are (almost) insensitive to the distribution of service times. As long as service times are Coxian (see below), then the results are the same, and the only relevant parameter is the mean service time ?????. Therefore, all M/Cox/1/PS systems (which in practice means almost all M/G/1/PS systems) behave like the one above. Recall that when there is no queueing, the distribution of service times does not really matter (only its mean value does). Coxian distributions are particular cases of Phase-Type distributions, which can accommodate pretty much everything, at least in an approximate way. They can be described as follows: Imagine that the service includes at most ?? stages. Each of them takes an exponential time (possibly with different means), and all stages are independent of each other. After each stage ??, you can either go to the next stage, with probability ???? , or leave the server, with probability 1 ? ???? . A Coxian collapses to an Erlang if ???? = 1 ???, and all stages are identical. m1 m2 ... mn n p1 p2 1?p1 1?p2 Coxian distributions can approximate distributions with: - ?????? < 1: e.g., an Erlang one, or even a deterministic one (which is the limit of an Erlang for ?? ? ?, recall the CLT); - ?????? > 1, e.g., those with a large variability, even approximating heavy-tailed ones. For instance, a (possibly crude) Coxian approximation of a distribution with ??[??] = ?? and ??????[??] = ??, with ?? ? 0.25 can be obtained by matching it to a 2-stage Coxian as follows: ??1 = 2??, ??1 = 1 2?? 2 , ??2 = ??1 ? ??1 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 75 More involved computations are required to obtained better matches (e.g., matching the first three moments). If you want to know more about how to fit a generic distribution to a Coxian, check the literature. For our purpose, it is enough to say that most distributions can be approximated with a Coxian, and the approximation can be made arbitrarily close by increasing the number of stages (and, consequently, the complexity of the computations). What are the SS probabilities in an M/Cox/1/PS system? They are surprisingly easy to compute. The first question to address is what is the mean service time for a job in such a system? This is an easy question: ??[???? ] = 1 ??1 + ??1 ? 1 ??2 + ??1 ? ??2 ? 1 ??3 + ? = ? 1 ???? ?? ??=1 ?????? ???1 ??=1 Then call ?? = ?? ? ??[???? ], and the SS probabilities are simply: ???? = ?? ?? ? (1 ? ??), which is almost too good to be true. They have the same shape as an M/M/1’s, and the only difference is that you need to compute the mean service time considering the traversal of up to ?? stages. Note that this result does only hold because there is no queueing in a PS system. Queueing creates variability. An M/Cox/1/FCFS system would behave very differently (you can analyze it using matrix analytic methods and check for yourselves). The last, very important thing about QNs of PS servers is the following: Theorem9 Open/closed networks of M/Cox/1/PS systems, with or without classes, admit a product form, as long as external arrivals (if any) are Poissonian and routing (possibly per class) is Markovian. ? The above thesis implies that we can study networks of PS systems, with generic service times (with a pinch of salt) as if they were OJNs or CJNs, as long as we use the mean value of whatever service time distribution we have at the nodes in place of 1/??. Over the last decades, more and more QNs have been found to admit product forms, including: - other service disciplines (e.g., LCFS with preemption and resume); 9 This thesis is part of the famous “BCMP theorem” (named after the initials of its inventors), published in 1975, which sets very general conditions under which QNs admits product forms. Its thesis is indeed more general than this one, but such generality often baffles first-time readers. Interested students may want to check the above paper for more details. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 76 - QNs where jobs may change class from one SC to the other, with known probabilities; - load-dependent and class-dependent service times at the nodes; - special forms of state-dependent routing; - special cases of blocking and finite queues. Therefore, there is a good chance that any model you come up with can be accommodated in the above framework. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 77 6 Exercises 6.1 Single-queue systems 6.1.1 Problem A packet switching node is modeled via an M/M/1 queueing system. The link speed ?? is 1400 bits/s, and the mean packet length ??[??] is 10 bits. Under some load conditions, the mean number of packets in the system is ??[??] = 50 at the steady state. Compute: a) the packet arrival rate ??; b) the mean response time ??[??]; c) the mean number of packets in the queue ??[????]; d) the mean queue waiting time ??[??]; e) the 95th percentile of the response time ??95; f) the link speed such that the above is equal to 1ms. Solution a) We know that ??[??] = 10 and that ?? = 1400. This allows us to compute ?? = ?????[??] = 140. Furthermore, since we have ??[??] = 50, this means that the system is positive recurrent, hence it is ??[??] = ???(1 ? ??). Therefore, we obtain ?? = ??[??]?(1 + ??[??]) = 50?51. Note that it stands to reason that ??~1, since the mean number of packets is high. Now, since ?? = ?????, we obtain ?? = ?? ? ?? = ?? ??[??] ? ??[??] 1+??[??] = 137.26. b) The average response time can be obtained by applying Little’s Theorem to the system queue+server in the steady state. Therefore, it is ??[??] = ??[??]??? = 0.364??. c) The mean number of packets in the queue can be computed directly as: ??[????] = ??[??] ? (1 ? ??0 ) = ??[??] ? ?? = 49.02, since the system has one server. d) There are two ways to compute ??[??]. The first one is by applying Little’s theorem to the system “queue” in the steady state. This gets us: ??[??] = ??[????]??? = 0.357??. Equivalently, one may leverage linearity of expectations and write ??[??] = ??[??] ? ??[???? ], where ???? is the service time. It is ??[???? ] = ?? = 1???, i.e. ?? = 1??? = 1?140 = 0.00714. Then, ??[??] = ??[??] ? ?? yields the same result. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 78 e) The distribution of the response time is exponential ??(??) = ??{?? ? ??} = 1 ? ?? ??????[??] . In order to compute the 95th percentile, we need to solve ??(??95) = 1 ? ?? ???95???[??] = 0.95, hence: ?? ???95???[??] = 0.05 ? ??95???[??] = ln(0.05) ??95 = ???[??]ln(0.05) ??95 ? 3??[??] = 1.092?? Note that the 95th percentile of the exponential is actually 2.996 times its mean value. Therefore, ??95 ? 3??[??] is an accurate estimate. f) The required equation is ??95 ? 3??[??] = 10 ?3 . Now, ??[??] = ??[??] ?? = ?? ??(1 ? ??) = ????? ??(1 ? ?????) = 1 ?? ? ?? = 1 ?????[??] ? ?? Therefore, we have: 3 ?????[??] ? ?? = 10 ?3 ?? = ??[??] ? (3 ? 10 3 + ??) ?? ? 10 ? (3000 + 137.26) = 31372??/?? 6.1.2 Problem Assume that a packet switching node is modeled via an M/M/1 queueing system whose transition diagram is reported below. The state of the system is represented by the number of packets in the system, although value ???? specifies the arrival rate of messages carrying ?? packets each. 0 1 2 3 m m m l1 l2 l3 ... a) Use the CTMC to provide a physical interpretation of the behavior of this system; b) write down the global equilibrium equations and determine the stability condition. Assuming that ???? = ?? ?? 3 ? , compute: c) the steady-state probabilities; d) the throughput; e) the utilization and the mean service time. Note: it may be useful to know that ? 1 ??2 = ?? 2 6 ? 1.645 +? ??=1 . Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 79 Solution a) The physical interpretation is the following: the system has bulk arrivals. It accepts messages with possibly many packets in a burst. On receipt of a message (containing an arbitrary number of packets) the system stops accepting messages (line blocking) and starts serving the available packets, until it is empty again. b) We can write down the global equilibrium equations at the steady state by circling each state and taking into account outgoing and incoming arcs. ??0 ? (? ???? +? ??=1 ) = ?? ? ??1 ?? ? ???? = ?? ? ????+1 + ???? ? ??0 (?? > 1) From the first equation, we get ??1 = 1 ?? ? (? ???? +? ??=1 ) ? ??0 . From the second equation, we get: ?? ? ??2 = ?? ? ??1 ? ??1 ? ??0 ??2 = ??1 ? ??1 ?? ? ??0 = [ 1 ?? ? (? ???? +? ??=1 ) ? ??1 ?? ] ? ??0 = 1 ?? ? (? ???? +? ??=2 ) ? ??0 And again: ?? ? ??3 = ?? ? ??2 ? ??2 ? ??0 ??3 = ??2 ? ??2 ?? ? ??0 = [ 1 ?? ? (? ???? +? ??=2 ) ? ??2 ?? ] ? ??0 = 1 ?? ? (? ???? +? ??=3 ) ? ??0 Thus it is easy to see that ???? = 1 ?? ? (? ???? +? ??=?? ) ? ??0 . In order to compute the stability condition, we need to enforce that ? ???? +? ??=0 = 1, which means that: [1 + 1 ?? ? ? ? ???? +? ??=?? +? ??=1 ] ? ??0 = 1. This, in turn, holds if and only if ? ? ???? +? ??=?? +? ??=1 is limited. Let us see what the double summation yields. You easily see that ??1 appears once, ??2 appears twice, … ???? appears ?? times. Thus, the double summation can be rewritten as: ? ? ???? +? ??=?? +? ??=1 = ? ?? ? ???? +? ??=1 Therefore, the stability condition is that the arrival rates are such that ? ?? ? ???? +? ??=1 < +?. The physical interpretation is that the mean arrival rate of packets should be finite. k n Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 80 The condition does not depend on the server speed, since the switch only accepts packets when it is empty. c) In this case, we have ???? = ?? ?? 3 ? , which means that the stability condition is verified, since: ? ?? ? ???? +? ??=1 = ? ?? ??2 +? ??=1 = ?? ? ?? 2 6 Therefore, the steady-state probabilities are: [1 + ?? ?? ? ?? 2 6 ] ? ??0 = 1 ??0 = 1 1 + ?? ? ??2?6 Where ?? = ?????. Furthermore, it is: ???? = ?? ?? ? (? 1 ??3 +? ??=?? ) ? ??0 = ?? 1 + ?? ? ??2?6 ? (? 1 ??3 +? ??=?? ) d) The definition of throughput is the following: ?? = ? ???? ? ???? +? ??=1 , i.e. the mean value of the service rate. In our case, it is ???? = ??, hence: ?? = ?? ? ????? +? ??=1 = ?? ? (1 ? ??0 ) = ?? ? ?? ? ?? 2?6 1 + ?? ? ?? 2?6 = ?? ? ?? 2?6 1 + ?? ? ?? 2?6 e) By definition, the utilization is the probability that the server is not idle. Therefore, we have ?? = ????? +? ??=1 = 1 ? ??0 = ?? ? ?? 2?6 1 + ?? ? ?? 2?6 The mean service time could be obtained without any computations, since the service rate does not depend on the state. Therefore, it is surely ??[???? ] = 1???. In any case, the definition yields: ??[???? ] = ?? ?? = ?? ? ?? 2?6 1 + ?? ? ?? 2?6 ? 1 + ?? ? ?? 2?6 ?? ? ?? 2?6 = ?? ?? = 1 ?? 6.1.3 Problem Consider a switch of a packet network having ?? output links and ?? input links, with ?? ? ??. Assume that the output links can be modeled as exponential servers with identical rate ??, and the arrival processes on each input line are IID Poisson processes with a rate ??. When a packet arrives on the switch from an input line, the switch does the following: - if there is at least one idle server, the packet goes immediately under service, blocking the input line it arrived on while it is being served; Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 81 - otherwise (there are no idle servers), the packet is discarded. a) Model the switch as a birth-death process, compute the arrival rate and draw the CTMC; b) compute the steady-state probabilities and the stability condition of the system; c) compute the steady-state probability ???? that all the servers are busy (blocking probability); d) compute the probability that an arriving packet finds all the servers busy (???? , packet loss probability), and prove that ???? (??) = ????(?? ? 1); e) When ?? = ??, prove that ???? = ( ?? ?? ) ?? ?? ? (1 ? ??) ????? , where ?? = ?? ??+?? . Provide a physical interpretation for the result. Note: it may be helpful to observe that (?? ? ??) ( ?? ?? ) = ?? ? ( ?? ? 1 ?? ) Solution The state of the switch can be characterized by the number of busy servers ??. a) Let us start with the arrival rates. - Consider an empty system (i.e., state 0), where all the ?? input links can send packets. The overall arrival rate can be computed by taking into account that the sum of ?? IID Poisson processes is itself a Poisson process with a mean value equal to ?? ? ??. Therefore, it is ??0 = ?? ? ??. - Let us now move to state 1. Now, one of the processes is blocked, since there is one packet in the system (hence one input link is blocked). Therefore, the aggregate arrival rate is (?? ? 1) ? ??. Therefore, ??1 = (?? ? 1) ? ??. - For a generic state ?? < ??, it is ???? = (?? ? ??) ? ??. - The system has ?? + 1 states, since the switch drops packets when ?? servers are busy. This means that a non null aggregate arrival rate can still be derived, but no state transition is possible. 0 Ml (M-1)l 1 (M-n+1)l (M-n)l …. n (M-N+1)l …. N m m2 mn m) 1+n( m N As far as service rates are concerned, they are proportional to the number of busy servers, thus it is ???? = ?? ? ?? 1 ? ?? ? ??. b) Since the CTMC has only nearest-neighbor transitions, we can use the well-known formula to compute ???? as a function of ??0 : ???? = ? ???? ????+1 ???1 ??=0 ??0 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 82 By substituting ???? = (?? ? ??) ? ?? and ???? = ?? ? ?? into the above we obtain: ???? = (?? ? ?? + 1)?? ?. . . (?? ? 1)?? ? ???? ?? ? ?? ? (?? ? 1) ? ?? ?. . .? 2?? ? ?? ??0 = ??!?(?? ? ??)! ??! ? ?? ?? ?? ?? ??0 = ( ?? ?? ) ? ( ?? ?? ) ?? ? ??0 0 ? ?? ? ?? Therefore, the normalization condition is the following: ??0 ? ? [( ?? ?? ) ? ( ?? ?? ) ?? ] ?? ??=0 = 1. Since the above is a finite sum, the system is positive recurrent. Therefore, we have: { ??0 = 1 ? [( ?? ?? ) ? ( ?? ?? ) ?? ] ?? ??=0 ???? = ( ?? ?? ) ? ( ?? ?? ) ?? ? ??0 ?? ? 1 (note that the last expression also holds for ?? = 0). c) The probability that ?? servers are busy is: ???? = ???? = ( ?? ?? ) ? ( ?? ?? ) ?? ? [( ?? ?? ) ? ( ?? ?? ) ?? ] ?? ??=0 Note that this is the probability that a random observer finds the system in state ??. d) The solution to this point is not the same as the previous point’s. The former requested the probability that ?? servers are busy at any time. This one is the probability that ?? servers are busy when a packet arrives. The two things are known to be different when the arrival rates depend on the state of the system, which is in fact the case in point. The arrival-time steady-state probabilities (for a generic state ??) can be computed as follows: ???? = ???? ? ???? ? ???? ? ???? ?? ??=0 = (?? ? ??) ? ?? ? ( ?? ?? ) ? ( ?? ?? ) ?? ? ??0 ? {(?? ? ??)?? ? ( ?? ?? ) ? ( ?? ?? ) ?? ? ??0 } ?? ??=0 = (?? ? ??) ? ?? ? ( ?? ?? ) ? ( ?? ?? ) ?? ? [(?? ? ??)?? ? ( ?? ?? ) ? ( ?? ?? ) ?? ] ?? ??=0 Keeping into account that: (?? ? ??) ? ( ?? ?? ) = ?? ? ( ?? ? 1 ?? ), we obtain: ???? = ?? ? ( ?? ? 1 ?? ) ? ( ?? ?? ) ?? ? [?? ? ( ?? ? 1 ?? ) ? ( ?? ?? ) ?? ] ?? ??=0 This means that the packet loss probability ???? is equal to ????, i.e.: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 83 ???? = ( ?? ? 1 ?? ) ? ( ?? ?? ) ?? ? [( ?? ? 1 ?? ) ? ( ?? ?? ) ?? ] ?? ??=0 Note that it is ???? (??) = ???? (?? ? 1). The packet loss probability for a system with ?? input links is the blocking probability for a system with ?? ? 1 input links. e) If ?? = ??, we get the following: ???? = ( ?? ?? ) ? ( ?? ?? ) ?? ? ??0 = ( ?? ?? ) ? ( ?? ?? ) ?? ? [( ?? ?? ) ? ( ?? ?? ) ?? ] ?? ??=0 However, since ? [( ?? ?? ) ? ( ?? ?? ) ?? ] ?? ??=0 = (1 + ?? ?? ) ?? , we obtain ???? = ( ?? ?? )?( ?? ?? ) ?? (1+ ?? ?? ) ?? . If we define ?? = ?? ??+?? < 1, we obtain: ?? = ????? 1 + ????? ?? ?? = ?? 1 ? ?? We substitute the latter in the former expression and obtain: ( ?? ?? ) ?? = ( ?? 1 ? ?? ) ?? , (1 + ?? ?? ) ?? = ( 1 1 ? ?? ) ?? ???? = ( ?? ?? ) ? ( ?? ?? ) ?? (1 + ?? ?? ) ?? = ( ?? ?? ) ? ?? ?? (1 ? ??) ?? 1 (1 ? ??)?? = ( ?? ?? ) ? ?? ?? ? (1 ? ??) ????? Therefore, if the number of input links and servers is equal, the steady-state probabilities are those of a binomial RV. This makes perfect sense. Consider a server in isolation. It oscillates between a busy and an idle state. The transition from idle to busy occurs at a rate ??, and those from busy to idle occur at a rate ??. This is a two-state birth-death process, whose steady-state probabilities are: { ?????????? = ?? ?? + ?? = ?? ?????????? = ?? ?? + ?? = 1 ? ?? idle l busy m 84 Since there are ?? such servers, and they are independent of each other, the number of busy servers is distributed as a binomial RV over ?? trials having success probability ?? = ??. 6.2 Queueing networks 6.2.1 Problem (open queueing network) Consider the computer system in the figure, and let ?? + ?? = 1. Compute: 1) the PMF of the number of jobs in the two service centers. Which of the two centers is the system bottleneck? 2) The mean number of jobs in the two service centers and in the system; 3) the mean response time of the system and the mean number of visits at the service centers. p q g m1 m2 CPU I/O SC1 SC2 Solution 1) This is an open Jackson’s network, and its routing matrix is ?? = [ 0 ?? 1 0 ]. Arrivals are ?? = [ ?? 0 ]. We could compute the arrival rate by solving equation ?? = (?? ? ?? ?? ) ?1 ? ??. It is easier if we observe that, since the input and output must balance, it must be ?? = ??1 ? ??. Moreover, from the routing we get that ??2 = ?? ? ??1. Hence, we obtain ??1 = ?????, ??2 = ?? ? ?????. Now that we have the arrival rates, we can compute the utilization of the SCs as ??1 = ??1 ??1 ? = ?? (??1 ? ? ??), and ??2 = ??2 ??2 ? = ?? ? ?? (??2 ? ? ??). By Jackson’s Theorem, this network admits a product form, which is: ??(??1, ??2 ) = [(1 ? ??1 ) ? ??1 ??1] ? [(1 ? ??2 ) ? ??2 ??2], as long as ???? < 1, 1 ? ?? ? 2, i.e.: ??(??1, ??2 ) = [(1 ? ?? ??1 ? ?? ) ? ( ?? ??1 ? ?? ) ??1 ] ? [(1 ? ?? ? ?? ??2 ? ?? ) ? ( ?? ? ?? ??2 ? ?? ) ??2 ] The SC with the highest utilization is the system bottleneck. The condition by which ??1 > ??2 is ?? (??1 ? ? ??) > ?? ? ?? (??2 ? ? ??), i.e. ?? ? ??1 < ??2. Under the above inequality, the CPU is the bottleneck. Otherwise, the I/O subsystem is the bottleneck. 2) By Jackson’s theorem we know that each SC behaves like an independent M/M/1 system, hence: ??[???? ] = ???? 1 ? ???? = { ?? ?? ? ??1 ? ?? ?? = 1 ?? ? ?? ?? ? ??2 ? ?? ? ?? ?? = 2 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 85 Obviously, it is ??[??] = ??[??1] + ??[??2], since mean values are additive. 3) By Little’s law, we get: ??[??] = ??[??]???, i.e.: ??[??] = 1 ?? ? ??1 ? ?? + ?? ?? ? ??2 ? ?? ? ?? The average number of visits at each SC is ??[???? ] = ???????, i.e. ??[??1 ] = 1???, ??[??2 ] = ?????. We can easily verify that ??[??] = ??[??1 ] + ??[??2 ] = ??[??1 ] ? ??[??1 ]???1 + ??[??2 ] ? ??[??2 ]???2 . In fact, ??[???? ]????? = 1???, and the computation is straightforward. 6.2.2 Problem (open queueing network) Consider a tandem queueing network like the one in the figure. Assume that all SCs have infinite queues. Let ? = {(??1, ??2 )|???? ? 0} be the state space for the system, where (??1, ??2 ) denotes a state in which ??1 jobs are at SC 1 and ??2 are at SC 2. l m1 m2 SC 1 SC 2 1) Draw the CTMC for the above system, including at least all the states such that ??1 + ??2 ? 3. 2) Write down the global equilibrium equations. 3) Verify Jackson’s theorem in this case study, i.e. prove that the equilibrium equations have the following solution: ???? = ??(??1, ??2 ) = [(1 ? ??1 ) ? ??1 ??1] ? [(1 ? ??2 ) ? ??2 ??2], with ???? = ?? ???? ? . Solution The CTMC can be computed as follows: - starting from state (0,0) (the system is empty), one arrival – which occurs at a rate ?? – brings the system to state (1,0). - In state (1,0), two things may happen: o one arrival at SC 1 (still at a rate ??), which brings the systems to state (2,0); o one departure from SC 1, which occurs at a rate ??1 and brings the system to state (0,1). The above behavior can be easily generalized to all the states (??, 0): o one arrival at SC 1 (still at a rate ??), which brings the systems in state (?? + 1,0); o one departure from SC 1, which occurs at a rate ??1 and brings the system to state (?? ? 1,1). - In state (0,1), again, two things may happen: o one arrival at SC 1 (at a rate ??), which brings the systems to state (1,1); o one departure from SC 2, which occurs at a rate ??2 and brings the system to state (0,0). Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 86 The above behavior can be easily generalized to all the states (0,??). - In state (1,1), the following may happen: o one arrival at SC 1 (still at a rate ??), which brings the systems in state (2,1); o one departure from SC 1, which occurs at a rate ??1 and brings the system to state (1,2); o one departure from SC 2, which occurs at a rate ??2 and brings the system to state (1,0). This can be easily generalized to all states (??,??), where both ?? and ?? are non null. Therefore, a portion of the diagram is the one in the following figure. On the right, the figure displays the portion of the state diagram related to generic state (??,??), where both ?? and ?? are non null. 0,0 1,0 2,0 3,0 0,1 1,1 2,1 1,2 0,3 0,2 l l l l l m1 l m1 m1 m1 m1 m1 m2 m2 m2 m2 m2 m2 i, j-1 i+1 j-1 i-1, j i,j i+1 ,j i, j+1 i-1, j+1 l l m1 m1 m2 m2 2) The global equilibrium equations can be easily inferred from the diagram on the right, with reference to generic state (??,??), assuming both ?? and ?? are non null. ????,?? ? [?? + ??1 + ??2 ] = ?????1,?? ? ?? + ????+1,???1 ? ??1 + ????,??+1 ? ??2 If either or both ?? and ?? are null, then the above equation still holds, provided that we remove the missing states. To that aim, we can use the step function ??(??), which is 1 if ?? > 0 and 0 if ?? = 0, and write down a general expression, which holds for any state (??,??): ????,?? ? [?? + ??1 ? ??(??) + ??2 ? ??(??)] = ?????1,?? ? ??(??) ? ?? + ????+1,???1 ? ??(??) ? ??1 + ????,??+1 ? ??2 . 3) We just need to substitute the given expression for ????,?? in the above equation, and check that equality holds: [(1 ? ??1 ) ? ??1 ?? ] ? [(1 ? ??2 ) ? ??2 ?? ] ? [?? + ??1 ? ??(??) + ??2 ? ??(??)] = [(1 ? ??1 ) ? ??1 ???1 ] ? [(1 ? ??2 ) ? ??2 ?? ] ? ??(??) ? ?? + [(1 ? ??1 ) ? ??1 ??+1 ] ? [(1 ? ??2 ) ? ??2 ???1 ] ? ??(??) ? ??1 + [(1 ? ??1 ) ? ??1 ?? ] ? [(1 ? ??2 ) ? ??2 ??+1 ]??2 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 87 By multiplying and/or dividing each addendum by ???? as required, the above expression can be quickly rewritten as: [(1 ? ??1 ) ? ??1 ?? ] ? [(1 ? ??2 ) ? ??2 ?? ] ? [?? + ??1 ? ??(??) + ??2 ? ??(??)] = [(1 ? ??1 ) ? ??1 ?? ] ? [(1 ? ??2 ) ? ??2 ?? ] ? ??(??) ? ?? ??1 ? + [(1 ? ??1 ) ? ??1 ?? ] ? [(1 ? ??2 ) ? ??2 ?? ] ? ??(??) ? ??1 ? ??1 ??2 ? + [(1 ? ??1 ) ? ??1 ?? ] ? [(1 ? ??2 ) ? ??2 ?? ]??2 ? ??2 From the above, we obtain: ?? + ??1 ? ??(??) + ??2 ? ??(??) = ??(??) ? ?????1 + ??(??) ? ??1 ? ??1???2 + ??2 ? ??2 By substituting ???? = ?? ???? ? into the above, we get: ?? + ??1 ? ??(??) + ??2 ? ??(??) = ??(??) ? ?? ? ??1 ?? + ??(??) ? ??1 ? ?? ??1 ? ??2 ?? + ??2 ? ?? ??2 ?? + ??1 ? ??(??) + ??2 ? ??(??) = ??1 ? ??(??) + ??2 ? ??(??) + ?? Hence equality holds. 6.2.3 Problem (closed queueing network) m1 m2 SC 1 SC 2 m3 SC3 mM SC M p1 p2 p3 pM ... Consider the central-server closed queueing network in the figure. Let ?? be the number of jobs in the system, and let ???? be the service rate at each SC. Assume that all SCs are M/M/1. 1) Compute the steady-state probabilities in their general form. 2) Specialize the computation for ???? = 1???, ???? = ??. Explain the result. 3) Run Buzen’s algorithm with ?? = 5,?? = 10 and compute the normalizing constant and the steady-state probabilities. 4) Compute the utilization and the throughput of each server in the above case. Solution The routing matrix is the following: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 88 ?? = [ ??1 ??2 . . . ?????1 ???? 1 0 . . . 0 0 1 0 . . . 0 0 . . . . . . . . . . . . . . . 1 0 . . . 0 0 ] Hence the linear system to be solved is the following: { ??1 = ??1 ? ??1 + ??2+. . .+???? ??2 = ??2 ? ??1 ??3 = ??3 ? ??1 . . . ???? = ???? ? ??1 We can easily observe that the equations of this linear system are not independent, since the first one boils down to ??1 = ??1 ? ??1 + ??2 ? ??1+. . . +???? ? ??1 = ??1 ? ? ???? ?? ??=1 = ??1. One solution is thus ??1 = ??1 , ???? = ???? ? ??1 for 2 ? ?? ? ??. Thus, ?? = [??1, ??2 ? ??1, . . . , ???? ? ??1 ] ?? . From this we can compute the values for ???? : ?? = [1, ??2 ? ??1 ??2 ? , . . . , ???? ? ??1 ???? ? ] ?? . Therefore, by Gordon and Newell’s Theorem, we have: ???? = ??(??1, ??2, . . . , ????) = 1 ??(??,??) ??( ???? ? ??1 ???? ) ?? ???? ??=2 2) With ???? = 1???, ???? = ??, the above computation becomes: ???? = ??(??1, ??2, . . . , ????) = 1 ??(??,??) ? ? ( 1 ?? ???? ) ?? ??=2 = 1 ??(??,??) ? 1 ?? ?????1 . The result should not surprise us. In fact, it tells us that every state having ??1 jobs at SC 1 has the same probability. In fact, from the above data we infer that all the other SCs are equivalent, since they have the same service rate and the same routing probability. Therefore, ??(??1, ??2, . . . , ????)|??1 should be uniform, which it is. 3) We run Buzen’s algorithm with the help of a spreadsheet, with the following initialization: - row 0: ??(??, 0) = 1, 1 ? ?? ? ?? - column 1: ??(1,??) = ??1 ?? = 1, 1 ? ?? ? ?? The final result is in the table, and it is equal to 2.44. Note that, had we chosen ??1 = 10??1 , the required constant would have been around ??(??,??) ? 2.44 ? 10 10. This is to remind us that, depending on the initial choice, numerical instability may arise. Since powers are involved, it is preferable that the value of the ??s be kept as close as possible to 1. Thus, the steady-state probabilities are: ???? = ??(??1, ??2, . . . , ??5 ) = 1 2.44 ? 1 5 10???1 . One may wonder why the constant ??(??,??) exhibits a negligible dependence on the number of jobs ??. This is again a consequence of our initial choice: since ???? = 1??? < 1, then it makes sense that numbers do not grow that much while moving down in a column. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 89 SC 1 2 3 4 5 ?? jobs 1 1/5 1/5 1/5 1/5 0 1 1 1 1 1 1 1 1.20 1.40 1.60 1.80 2 1 1.24 1.52 1.84 2.20 3 1 1.25 1.55 1.92 2.36 4 1 1.25 1.56 1.94 2.42 5 1 1.25 1.56 1.95 2.43 6 1 1.25 1.56 1.95 2.44 7 1 1.25 1.56 1.95 2.44 8 1 1.25 1.56 1.95 2.44 9 1 1.25 1.56 1.95 2.44 10 1 1.25 1.56 1.95 2.44 The mean number of jobs at each SC can be computed through a spreadsheet software again: ??[???? ] = 1 ??(??,??) ?????? ?? ? ??(??,?? ? ??) ?? ??=1 For ?? = 1 it is ??[??1 ] = ? ??(??,?????) ?? ??=1 ??(??,??) ? 9 = ?? ? 1 , whereas for ?? > 1 we have ??[???? ] = ? ??(??,?????) 5 ?? ?? ??=1 ??(??,??) ? 0.25 = 1 ???1 . Of course, ? ??[???? ] ?? ??=1 = ??. 4) The utilization is ???? ? ??(??,???1) ??(??,??) ? ???? . This makes sense: as the number of jobs increases, the probability that SC 1 is idle should go to zero (every job passes through SC 1 in a round). Moreover, the utilization of SCs 2 to ?? tends to ???? ? ??1 ???? ? = 1???, and this makes sense as well. The throughput is: ???? ? ???? ? ???? = { ?? ?? = 1 ???? ? ?? = ?? ?? 2 ? ?? ? ?? , which again makes sense, given that the routing probabilities are uniform. This said, we can compute ??[???? ] as: ??[??1 ] = ??[??1 ] ?? = 9 1 ?? ??[???? ] = ??[???? ] ?? = 1 ?? ? 1 ? ?? ?? = 5 4?? , 2 ? ?? ? ?? 6.2.4 Problem (classed open queueing network) Consider a system serving two clients, ?? and ??. Client ?? (??) issues service requests independently, with exponential interarrival times, at a rate ???? (???? ). Service requests are queued FCFS, and the queue is infinite. Each service request may require more than one passage through the system: on average, requests by client ?? (??) require ???? (????) such passages. This is achieved by sending requests Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 90 that leave the server back to the queue with a certain probability (to be computed). The server is exponential with a rate ??. 1) Model this system as a queueing network and compute the routing probabilities and the arrival rates; 2) Compute the stability condition as a function of the system parameters; 3) Compute the mean number of service requests in the system; 4) Compute the joint probability to have ???? requests of client ?? and ???? requests of client ?? in the system. Explain your findings; Solution m pa 1?pa ga pb 1?pb gb 1) The system can be modeled as a classed OJN, where the two clients are two classes. There is only one SC, that has a rate ??, and the routing matrixes are ???? = [????], ???? = [????]. The number of visits to the SC is a geometric RV, where ??{???? = ??} = ???? ???1 ? (1 ? ????), hence ???? = ??[???? ] = 1 1????? and ???? = 1 ? 1 ???? . Using input-output balance, one finds that ???? = (1 ? ???? ) ? ???? , hence ???? = ???? ? ???? . 2) The total ingress rate to the system is therefore ???? + ???? = ???? ? ???? + ???? ? ????, hence stability reads ???? ? ???? + ???? ? ???? < ??. 3) Under the above conditions, define ?? = ?????????+????????? ?? , and it is ??{???? + ???? = ??} = ?? ?? ? (1 ? ??) 4) In a classed system, the probability to be in any state ?? having ???? + ???? service requests is equal to: ???? = ???? ???? ? ???? ???? ?? ????+???? ? (1 ? ??) There are ( ????+???? ???? ) such states ??, their number being the number of possible subsets of ???? items in a set of ???? + ????. Call ?? = {??|???? ???????? ???? ?????????? ?? ?????? ???? ???????? ???? ?????????? ??}. We obtain: ???? = ( ???? + ???? ???? ) ???? ???? ? ???? ???? ?? ????+???? ? (1 ? ??) Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 91 = ( ???? + ???? ???? ) ???? ???? ? ???? ???? (???? + ????) ????+???? ? ?? ????+????(1 ? ??) = [( ???? + ???? ???? ) ( ???? ???? + ???? ) ???? ? ( ???? ???? + ???? ) ???? ] ? ?? ????+????(1 ? ??) The first term in the above expression is the probability of having ???? successes in a repeated trial of ???? + ???? trials, whereas the second term is the SS probability to have ???? + ???? jobs in the system at all. The alert reader can check that ? ? ???? +? ????=0 +? ????=0 = 1. This is obtained by rewriting the above double sum as ? ? ???? ?? ????=0 +? ??=0 , where ?? = ???? + ????. 6.2.5 Problem (classed open QN of PS systems) A processing system has two CPUs (CPU1 and CPU2), which are shared by a number of flows. Tasks are scheduled round-robin on both CPUs. CPU 1 serves ?? (1) + 1 flows. One flow (pictured in red in the figure below) has an external arrival rate ?? (3) , whereas the other ?? (1) flows have an arrival rate ?? (1) . Similarly, CPU 2 serves ?? (2) + 1 flows, ?? (2) of which have an external arrival rate ?? (2) . We are interested in the performance of tasks belonging to the red flow. The latter is served at least once at CPU 1, and then is routed to CPU 2 (or back to CPU 1) with a probability ?? (1 ? ??). The distribution of service times at CPU 2 is an Erlang with 5 equal stages, each one with a rate ??2. The distribution of service times at CPU 1 is a 2-stage Coxian as in the figure below. CPU 1 CPU 2 g (3) n (1), g(1) n (2), g(2) p 1?p m1,1 m1,2 p1,1 1?p1,1 CPU 1 1) Compute the mean service time at CPU 2, and the parameters of CPU 1’s server that allow one to experience a service time with a mean ?? and a CoV ?? (? 0.25). 2) Compute the routing matrix for the red flow and the overall arrival rates at each CPU. 3) Find the stability condition for the above system 4) Compute the mean number of jobs at CPU 1 and CPU 2 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 92 Solution 1) The service time at CPU 2 is the sum of 5 IID exponentials with a rate ??2. Therefore, it is ??[????2 ] = 5/??2. As far as CPU 1 is concerned, it is ??[????1 ] = ?? (obviously), and: ??1,1 = 2??, ??1,1 = 1/2?? 2 , ??1,2 = ??/?? 2 . 2) The routing matrix for the red flow is ?? (??) = [ 1 ? ? ? 0 0 ] As far as I/O balance is concerned, we observe that: - ?? (3) = ??2 (3) and ?? (3) = ??1 (3) ? ??, hence ??1 (3) = ?? (3) ?? . - At CPU 1, we have a further ??1 (1) = ?? (1) ? ?? (1) of input - At CPU 2, we have a further ??2 (2) = ?? (2) ? ?? (2) of input Thus, we have: - ??1 = ??1 (1) + ??1 (3) = ?? (1) ? ?? (1) + ?? (3) ?? - ??2 = ??2 (2) + ??2 (3) = ?? (2) ? ?? (2) + ?? (3) 3) The stability conditions are the following: - At CPU 1, we have ??1 ? ??[????1 ] < 1, i.e. (?? (1) ? ?? (1) + ?? (3) ?? ) ? ?? < 1 - At CPU 2, we have ??2 ? ??[????2 ] < 1, i.e. 5 ? ?? (2) ??? (2)+?? (3) ??2 < 1 4) Under the above conditions, the mean number of jobs at each CPU is the following: ??[??1 ] = (?? (1) ? ?? (1) + ?? (3) ?? ) ? ?? 1 ? (?? (1) ? ?? (1) + ?? (3) ?? ) ? ?? ??[??2 ] = 5 ? ?? (2) ? ?? (2) + ?? (3) ??2 1 ? 5 ? ?? (2) ? ?? (2) + ?? (3) ??2 = 5 ? (?? (2) ? ?? (2) + ?? (3) ) ??2 ? 5 ? (?? (2) ? ?? (2) + ?? (3)) Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 93 7 Appendix 7.1 Stochastic processes Take a system consisting of a FCFS queue and a server. We need to characterize the state of this system at a given time ??. The way we characterize its state depends on what we want to observe. For instance, we may be interested in: 1) The number of jobs in the system at time ?? (also called the backlog at that time) Job 1 arrives Job 2 arrives Job 3 arrives Job 4 arrives Job 1 leaves Job 2 leaves j1 response time j2 response time j1 service time j2 q-ing time j2 service time N(t) t ??(??) is a discrete quantity (it is an integer), which is a function of a continuous parameter (time). The above is a trajectory (or realization, or sample path), which depends on the interarrival times of the customers at the queue, as well as on the service times (or service demands). Given different interarrival and service times, the trajectory is going to be different. 2) The number of jobs that a departing job leaves behind. This is a discrete variable ????, which is a function of a discrete parameter (the job number). Again, the one in the figure is a trajectory, and different trajectories are possible. For instance, if interarrival times were generally shorter, then the trajectory would be higher. The same would occur if the service times were longer, all else being equal. Nk 1 2 3 Since interarrival and service times are normally random variables, we should be a little more precise when we use terms such as “higher”. We mean “higher” in a stochastic sense: if the interarrival times are shorter (in a stochastic sense: shorter interarrivals times have a higher probability), then Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 94 the trajectory will be higher (in a stochastic sense: higher trajectories will have a higher probability). Of course, lower, flatter trajectories will still be possible, but they will occur less frequently. Note that you can always compute this trajectory ???? given the first state characterization ??(??). In fact, it is ???? = ??(???? ?? + ). The vice versa, instead, does not hold - since you cannot create information that you do not possess. We say that the process ???? is embedded into ??(??). 3) The time it takes for job k to leave the system The above time is called response time of job k. This is a continuous-space variable ????, whose parameter is discrete. Rk 1 2 3 k 4) The time it takes to clear the backlog at time ?? The backlog at time t is the amount of work it takes to serve all the jobs which are in the system at time ??. This is a continuous-space variable ??(??), whose parameter is a continuous time. A trajectory is going to look like this: W(t) t Slope = service rate Job 2 arrival Job 1 arrival To summarize, we are talking about random trajectories, which can be any combination of - Discrete/continuous in the state space (i.e., in the ordinates) - Discrete/continuous in the parameter (i.e., in the abscissas) The parameter is often (albeit confunsingly) called time, even when it is not (e.g., case 2 and 3). Thus, we talk about discrete-space/continuous-time trajectories, etc. We need a mathematical framework for these entities. We extend the definition of random variable, which we provided time ago, to functions of time. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 95 A random variable is a function from a sample space to real numbers. We extend this definition, and define a random process (or stochastic process), as a function from a sample space to a space of real-valued (discrete or continuous) functions of (discrete or continuous) time. . . . . S f : ??1 ?2 ?Xt (?1 )??Xt (?2 )?For instance, given an outcome of a random experiment ??1, a process is the mapping from that outcome to a function of time (e.g., a real-valued function of continuous time). The outcome of the experiment can be, in this case, a suitably large number of interarrival times and service times for the jobs in the system. Given that outcome, the trajectory ???? is perfectly deterministic. The fact that makes these trajectories aleatory is the fact that the outcomes are aleatory. Other common names for trajectories are sample paths, or realizations of the process. Notation ???? is used with continuous times as well. Consider now several trajectories of the same process (cont. space/cont. time as an example): Fix a value for the parameter, e.g. ??1. Now ????1 is a random variable, with some distribution. So is ???? for any other value t of the parameter. The same obviously happens if the parameter is discrete, and if the state-space is discrete. t1 t2 t3 ?1 ?2 ?3 Suppose that you want to characterize the above process from a stochastic point of view. It stands to reason that you should need the joint CDF for all the values of the parameter. More specifically, ??? ? ?, ?{??1,??2, . . . ,???? } ? ??? |0 < ??1 < ??2 1, does not yield any further information. Quoting a famous phrase, “the future of a process is conditionally independent of the past, once the present is known”. The above property implies that the JPMF can be written as follows: ??{????1 = ??1, . . . , ?????? = ????} = ??? {?????? = ???? |???????1 = ?????1} ?? ??=2 ? ??{????1 = ??1} We call a Markov process one that possesses the Markov property. For a MP, the current state is enough to determine (in a stochastic sense) the future state, and knowledge of the past does not yield more information. Note – incidentally – that IID processes are a special case of Markov processes, since ??{?????? = ????|????1 = ??1, . . . , ???????1 = ?????1} = ??{?????? = ????|???????1 = ?????1} = ??{?????? = ????} Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 97 7.1.2 Example: Bernoulli process This is a discrete-space/discrete-time process, which is obtained as follows: suppose you have a slotted-time system, where a customer may or may not arrive at any timeslot ??, ?? > 0. At any timeslot, a new customer arrives with probability ??. The sequence of IID Bernoullian RVs {????,?? > 0} is one way to describe the process. A second way to characterize the above process is to consider the number of arrived customers by time ??, call it ????. If ???? are IID Bernoullian, then ???? is their sum, hence is a binomial with parameters ?? and ??: ??{???? = ??} = ???? (??) = ( ?? ?? ) ?? ?? ? (1 ? ??) ????? . It is ??0 = 0. We can see ???? as a process (discrete-space/discrete-time), whose trajectories can only be increasing. We call processes like these counting processes, or arrival processes. Now, let us consider a given trajectory at time ??, and let us predict its future state at time ?? + 1. ??{????+1 = ??} can be obtained using Total Probability as follows: ??{????+1 = ??} = ???{????+1 = ??|???? = ??} ? ??{???? = ??} +? ??=0 = ?? ? ??{???? = ?? ? 1} + (1 ? ??) ? ??{???? = ??} Since all the other conditional terms in the sum are null. . . . p 1-p k-1 k n n+1 You will have noticed that there is no further information to be gained by knowing ??{?????1 = ??} (or of any less recent time instant), if you already know ??{???? = ??}. Therefore, {????, ?? > 0} is a Markov process. All the information you need in order to predict a future state is summarized in the present state, and knowing the past does not bring any further insight. Note also that, for this process, the conditional probabilities are independent of the particular time ?? at which they are computed: ??{????+1 = ??|???? = ??} = ??{????+1 = ??|???? = ??}. A third way of describing the same phenomenon is to measure its interarrival times. Call ??1 the time at which the first customer arrives. ??1 is a geometric RV: ??{??1 = ??} = ?? ? (1 ? ??) ???1 . Now, call ??2 the inter-arrival time between customers 1 and 2 (we can see ??1 as the interarrival time between the start of the system, at time ?? = 0, and the arrival time of the first customer). In this case as well it is ??{??2 = ??} = ?? ? (1 ? ??) ???1 , and this holds for every interarrival time ???? . Therefore, the sequence of interarrival time is a sequence of IID Geometric RVs. Y1 Y2 Y3 Nn n 98 We have discussed three equivalent ways to characterize the above process. 1) A sequence of IID Bernoulli RVs {????, ?? > 0}, denoting the probability that a new customer arrives at time ??; 2) A counting process {????, ?? > 0}, denoting the number of customers arrived by time ??. This is a Markov process. 3) A sequence of IID geometric RVs, modeling the interarrival times. 7.1.3 Example: Poisson process Let us discuss how to model an arrival process in continuous time. This is made slightly trickier by the fact that, strictly speaking, the probability that something happens (e.g., a customer arrives) at time ?? is zero. Therefore, we need to exert some care when we define the counting process and interarrival times. We define a Poisson process with a parameter ?? as follows: Consider the counting process {??(??),?? ? 0} of customer arrivals by time ?? in a system. This is a Poisson process if, in a small interval [??,?? + ???), the following happens: 1) The probability of one arrival in [??,?? + ???), i.e., ??{??(?? + ???) ? ??(??) = 1}, is equal to ?? ? ??? + ??(???). The term ??(???) groups terms that go to zero faster than ???, i.e., lim ????0 ??(???)???? = 0. 2) The probability of zero arrivals in [??,?? + ???), i.e., ??{??(?? + ???) ? ??(??) = 0}, is equal to 1 ? ?? ? ??? + ??(???) 3) The probability of two or more arrivals in [??,?? + ???), i.e., ??{??(?? + ???) ? ??(??) > 1}, is ??(???). 4) The process has independent increments: ?{??1,??2, . . . ,???? } ? ??? |??1 < ??2 1 it starts peaking and then goes down. When n gets large, due to the CLT, it looks like a Normal. We can compute ??[???? ] and ??????(???? ) leveraging additivity of mean values and independence (recall that the Erlang is the sum of n independent exponentials). Therefore, we get ??[???? ] = ?? ?? , ??????(???? ) = ?? ?? 2 . From these we obtain ??????(???? ) = ???????(????) ??[????] = 1 ??? . In other words, the CoV of an n-stage Erlang is smaller than one (and, specifically, it is smaller than an exponential’s), and it gets smaller with n (which is again a consequence of the CLT). 7.2 Formal derivation of Chapman-Kolmogorov equations In this appendix we use the insight of Poisson processes to derive formally Chapman-Kolmogorov’s equations. 7.2.1 M/M/1 system We report here the full derivation of CK equations for an M/M/1 system We will now compute the PMF of the number of jobs in the system at time ??. Call ???? (??) the probability that there are ?? jobs at time ??, i.e. ???? (??) = ??{??(??) = ??}. The procedure is as follows: we write down ???? (?? + ????) using Total Probability, and then we let ??? ? 0. The expression is: ???? (?? + ???) = ? ??{??(?? + ???) = ??|??(??) = ??} ? ???? (??) +? ??=0 , which is an infinite sum. Luckily, we can neglect all but three terms in that sum. Let us assume first that ?? ? 1 (the case ?? = 0 needs special care and will be dealt with separately later on), and let us figure out what the possible trajectories are that lead to point (?? + ???, ??) in the Cartesian plane. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 102 1 dep., 0 arr. 0 dep., 1 arr. 0 dep., 0 arr. n n+1 n-1 t t+Dt a) The most obvious trajectory is one where ??(??) = ??, and there are zero arrivals/departures in [??,?? + ???]. The probability that zero arrivals/departures occur in a small interval [??,?? + ???] (recall that we let ??? ? 0) is: [1 ? ?? ? ??? + ??(???)] ? [1 ? ?? ? ??? + ??(???)] = 1 ? (?? + ??) ? ??? + ??(???) Of course, there are infinite possible trajectories such that ??(??) = ?? and ??(?? + ???) = ??: for instance, one where there is one arrival and one departure in [??,?? + ???]. However, the probability that there is one arrival and one departure is [?? ? ??? + ??(???)] ? [?? ? ??? + ??(???)] = ??(???), hence it is negligible. We quickly see that the only possible trajectory such that ??(??) = ?? and ??(?? + ???) = ?? whose probability is non-negligible is the one where zero arrivals and zero departures occur. All trajectories where two or more events are required have a negligible ??(???) probability. b) Another possibility is that ??(??) = ?? + 1, and one departure occurs in [??,?? + ???]. The probability of zero arrivals/one departure in [??,?? + ???] is: [1 ? ?? ? ??? + ??(???)] ? [?? ? ??? + ??(???)] = ?? ? ??? + ??(???). Again, all other trajectories such that ??(??) = ?? + 1 and ??(?? + ???) = ?? require at least two events in [??,?? + ???], hence their probability is ??(???). c) Another possibility is that ??(??) = ?? ? 1, and one arrival occurs in [??,?? + ???]. The probability of zero departures/one arrival in [??,?? + ???] is: [?? ? ??? + ??(???)] ? [1 ? ?? ? ??? + ??(???)] = ?? ? ??? + ??(???). Again, all other trajectories such that ??(??) = ?? ? 1 and ??(?? + ???) = ?? require at least two events in [??,?? + ???], hence their probability is ??(???). Any other trajectory, such as those with ??(??) = ?? ± ??, ?? ? 2, requires at least two events to occur, hence has ??(???) probability. The only non-negligible terms in the infinite sum are those listed at points a-c above. Therefore, we can write: Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 103 ???? (?? + ???) = ???{??(?? + ???) = ??|??(??) = ??} ? ???? (??) +? ??=0 = [1 ? (?? + ??) ? ??? + ??(???)] ? ???? (??) + [?? ? ??? + ??(???)] ? ????+1 (??) + [?? ? ??? + ??(???)] ? ?????1 (??) The latter quickly becomes: ???? (?? + ???) ? ???? (??) ??? = [?(?? + ??) + ??(???) ??? ] ? ???? (??) + [?? + ??(???) ??? ] ? ????+1 (??) + [?? + ??(???) ??? ] ? ?????1 (??) And, if we let ??? ? 0, we obtain (recall that ??(???) terms go to zero faster than ????): ?? ???? ???? (??) = ?(?? + ??) ? ???? (??) + ?? ? ????+1 (??) + ?? ? ?????1 (??) The above is called Chapman-Kolmogorov equation. We still have to deal with the case ?? = 0, which we had set apart. In this case, in fact, only two trajectories are possible: a) The one where ??(??) = ?? = 0, and there are zero arrivals/zero departures in [??,?? + ???]. The probability that this occurs is [1 ? ?? ? ??? + ??(???)] ? 1 = 1 ? ?? ? ??? + ??(???). This is because one cannot have departures when there are no jobs, so “zero departures” is the certain event in this case. b) The one where ??(??) = ?? + 1 = 1, and there are zero arrivals/one departure in [??,?? + ???], with a a probability: ?? ? ??? + ??(???). 1 dep., 0 arr. 0 dep., 0 arr. 0 1 t t+Dt The third trajectory, in fact (the one that involves one arrival and zero departures) cannot occur. Therefore, we can repeat the same computations and obtain: ??0 (?? + ???) = ???{??(?? + ???) = 0|??(??) = ??} ? ???? (??) +? ??=0 = [1 ? ?? ? ??? + ??(???)] ? ??0 (??) + [?? ? ??? + ??(???)] ? ??1 (??) Which leads to: ?? ???? ??0 (??) = ??? ? ??0 (??) + ?? ? ??1 (??) This way, we obtain a system of differential equations that describes ???? (??) for each time ??. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 104 { ?? ???? ???? (??) = ?(?? + ??) ? ???? (??) + ?? ? ????+1 (??) + ?? ? ?????1 (??) ?? > 0 ?? ???? ??0 (??) = ??? ? ??0 (??) + ?? ? ??1 (??) ?? = 0 7.2.2 M/M/2 system Like we did for the M/M/1 system, we write down Chapman-Kolmogorov’s equations and compute ???? (??). This time we need to distinguish three cases: ?? ? 2, ?? = 1, ?? = 0. Case ?? ? ??: Let us figure out what the possible trajectories are that lead to point (?? + ???, ??) in the Cartesian plane. As usual, there are three such trajectories: 1 dep., 0 arr. 0 dep., 1 arr. 0 dep., 0 arr. n n+1 n-1 t t+Dt a) one where ??(??) = ??, and there are zero arrivals/departures in [??,?? + ???], whose probability is: [(1 ? ?? ? ??? + ??(???)) ? (1 ? ?? ? ??? + ??(???)) 2 ] = 1 ? (?? + 2??) ? ??? + ??(???) The square is due to the fact that there are two independent busy servers, hence the probability that neither of them outputs a job is the product of two identical terms. b) one where ??(??) = ?? + 1, and one departure occurs in [??,?? + ???], whose probability is: [1 ? ?? ? ??? + ??(???)] ? {[?? ? ??? + ??(???)] ? [1 ? ?? ? ??? + ??(???)] + [1 ? ?? ? ??? + ??(???)] ? [?? ? ??? + ??(???)]} = 2?? ? ??? + ??(???) In this case, in fact, one server has a departure, and the other hasn’t. However, both events (departure, no departure) and (no departure, departure), which are disjoint and with the same probability, must be considered, hence the resulting term has a multiplying factor 2. c) Another one ??(??) = ?? ? 1, and one arrival occurs in [??,?? + ???], whose probability is: [?? ? ??? + ??(???)] ? [1 ? ?? ? ??? + ??(???)] 2 = ?? ? ??? + ??(???). Again, mind the square, since there are two busy servers. Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 105 Any other trajectory, such as those with ??(??) = ?? ± ??, ?? ? 2, requires at least two events to occur, hence has ??(???) probability. The only non-negligible terms in the infinite sum are those listed at points a-c above. Therefore, we can write: ???? (?? + ???) = ???{??(?? + ???) = ??|??(??) = ??} ? ???? (??) +? ??=0 = [1 ? (?? + 2??) ? ??? + ??(???)] ? ???? (??) + [2?? ? ??? + ??(???)] ? ????+1 (??) + [?? ? ??? + ??(???)] ? ?????1 (??) And, if we let ??? ? 0, we obtain: ?? ???? ???? (??) = ?(?? + 2??) ? ???? (??) + 2?? ? ????+1 (??) + ?? ? ?????1 (??) Case ?? = ?? In this case, all three trajectories are possible, but probabilities are different. In fact, only one server is busy, whereas the other is idle. a) one where ??(??) = ?? = 1, and there are zero arrivals/departures in [??,?? + ???], whose probability is: [(1 ? ?? ? ??? + ??(???)) ? (1 ? ?? ? ??? + ??(???))] ? 1 = 1 ? (?? + ??) ? ??? + ??(???) There is no square this time, since one of the servers is idle, so the fact that it will have no departures is the certain event. b) one where ??(??) = ?? + 1 = 2, and one departure occurs in [??,?? + ???], whose probability is: [1 ? ?? ? ??? + ??(???)] ? {2 ? [?? ? ??? + ??(???)] ? [1 ? ?? ? ??? + ??(???)]} = 2?? ? ??? + ??(???) c) Another one ??(??) = ?? ? 1 = 0, and one arrival occurs in [??,?? + ???], whose probability is ?? ? ??? + ??(???). Note that there are no busy servers in this case. From the above, we get ?? ???? ??1 (??) = ?(?? + ??) ? ??1 (??) + 2?? ? ??2 (??) + ?? ? ??0 (??) Case ?? = ?? In this case, only two trajectories are possible: a) The one where ??(??) = ?? = 0, and there are zero arrivals/zero departures in [??,?? + ???]. The probability that this occurs is [1 ? ?? ? ??? + ??(???)] ? 1 = 1 ? ?? ? ??? + ??(???). This is because Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 106 one cannot have departures when there are no jobs, so “zero departures” is the certain event in this case. b) The one where ??(??) = ?? + 1 = 1, and there are zero arrivals/one departure in [??,?? + ???], with a a probability: ?? ? ??? + ??(???) (note that in this case there is one busy server and one idle server). Thus, we have: ?? ???? ??0 (??) = ??? ? ??0 (??) + ?? ? ??1 (??) We thus obtain the usual system of differential equations that describes ???? (??) for each time ??. { ?? ???? ???? (??) = ?(?? + 2??) ? ???? (??) + 2?? ? ????+1 (??) + ?? ? ?????1 (??) ?? > 1 ?? ???? ??1 (??) = ?(?? + ??) ? ??1 (??) + 2?? ? ??2 (??) + ?? ? ??0 (??) ?? = 1 ?? ???? ??0 (??) = ??? ? ??0 (??) + ?? ? ??1 (??) ?? = 0 Notes on queueing theory (student version) – Giovanni Stea – last saved: 04/08/22 107 7.3 Useful mathematical series Source: Wikipedia 7.3.1 Sums of powers 7.3.2 Power series 7.3.3 Exponential functions 7.3.4 Binomial coefficients
