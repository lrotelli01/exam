===============================================================================
                          PRESENTAZIONE PROGETTO
                   Simulazione Accesso Concorrente a Database
                               (10 Slide)
===============================================================================

SLIDE 1: TITOLO E INTRODUZIONE
===============================================================================
Titolo Principale:
  Simulazione di Accesso Concorrente a Database
  Modello Readers/Writers con OMNeT++

Sottotitolo:
  Progetto di Simulazione - Corso di Teoria delle Code e OMNeT++

Informazioni:
  • Autori: [Nome Studente/Gruppo]
  • Data: [Data Completamento]
  • Istituzione: [Università]
  • Framewok: OMNeT++ Discrete Event Simulator

Bullet Points:
  • Simulazione di sistema database con accesso multiplo
  • Analisi di performance e bottleneck
  • Algoritmo mutual exclusion readers/writers


SLIDE 2: PROBLEMA E MOTIVAZIONE
===============================================================================
Titolo: Problema e Contesto

Problema Centrale:
  "Come prevedere e ottimizzare le performance di un database
   con accesso concorrente da molteplici clienti?"

Scenario Reale:
  • N utenti accedono simultaneamente a M tabelle
  • Mix di operazioni: letture (frequenti) e scritture (critiche)
  • Contention: Conflitti tra accessi concorrenti
  • Trade-off: Parallelismo vs Consistency

Sfide:
  • Bottleneck: Tabelle hot-spot sature
  • Queueing: Code lunghe riducono responsiveness
  • Contention: Letture bloccate da scritture
  • Scalabilità: Come aumentare throughput?

Motivazione Simulazione:
  • Esperimenti non fattibili su sistema reale
  • Parametrizzazione rapida di scenari
  • Analisi statistica rigorosa


SLIDE 3: OBIETTIVI E METRICHE
===============================================================================
Titolo: Obiettivi di Simulazione

Obiettivi Principali:

  1. Valutare Performance:
     • Throughput del sistema (operazioni/secondo)
     • Latenza (tempo di attesa medio)
     • Lunghezza code (congestione)

  2. Analizzare Fattori:
     • Impact di read/write ratio (p)
     • Impact di numero utenti (N)
     • Impact di distribuzione accessi (uniforme vs hotspot)

  3. Identificare Bottleneck:
     • Quale tabella satura per prima?
     • Quando il sistema saturo (throughput plateaus)?
     • Come scale con numero tabelle?

KPI (Key Performance Indicators):

  Throughput:
    • Totale: Accessi completati/secondo sistema
    • Per tabella: Operazioni processate/secondo

  Latency (Wait Time):
    • Media: Tempo medio dalla richiesta al completamento
    • 95-percentile: Per caratterizzare coda

  Queueing:
    • Lunghezza media: Stress sulla coda
    • Lunghezza massima: Caso pessimo

  Contention:
    • Rapporto read/write completati
    • Tasso di blocco per tipo operazione


SLIDE 4: MODELLO SISTEMA - ARCHITETTURA
===============================================================================
Titolo: Architettura del Sistema

Componenti:

  User Module (N copie):
    • Genera richieste Poisson (rate λ)
    • Seleziona tabella (uniforme o lognormale)
    • Decide lettura (prob. p) vs scrittura (prob. 1-p)
    • Misura tempo di attesa
    • Parametri: userId, lambda, readProbability, numTables

  Table Module (M copie):
    • Riceve richieste dagli utenti
    • Implementa mutual exclusion (readers/writers)
    • Gestisce coda FCFS
    • Fornisce servizio temporale
    • Parametri: tableId

  Network:
    • Fully-connected mesh topology
    • N users × M tables
    • Comunicazione message-passing

Topologia:
  
  user[0] ─┐
  user[1] ─┼─ table[0]
  ... ─┼─ table[1]
  user[N-1]─┤ ...
           └─ table[M-1]

Comunicazione:
  • Asincrona message-passing
  • Delay = 0 (rete ideale)
  • No packet loss


SLIDE 5: MODELLO SISTEMA - LOGICA CONCORRENZA
===============================================================================
Titolo: Algoritmo Mutual Exclusion (Readers/Writers)

Invarianti:
  • Nessun lettore durante scrittura
  • Nessun scrittore durante lettura
  • Nessun scrittore durante altro scrittore
  • Lettori multipli simultanei OK

Stato Interno (per tabella):

  activeReaders (int):    # di lettori attualmente serviti
  writeActive (bool):     1 se uno scrittore in servizio
  requestQueue (FIFO):    Coda di richieste in attesa

Algoritmo processQueue():

  Precondizione: writeActive == false (altrimenti tabella bloccata)
  
  While requestQueue not empty:
  
    1. Peek primo elemento dalla coda
    
    2. If lettura:
       - Pop dalla coda
       - Incrementa activeReaders
       - Avvia servizio
       - Continua loop (altre letture OK)
    
    3. If scrittura:
       - If activeReaders == 0:
         • Pop, imposta writeActive=true, avvia, break
       - Else:
         • Attendi (blocca coda dietro scrittura per FCFS)
         • Break

Proprietà:
  • FCFS: Ordine di arrivo rispettato
  • Deadlock-free: Sempre progresso se servizio finito
  • Starvation-free: FCFS evita starvazione scrittori


SLIDE 6: IMPLEMENTAZIONE - STRUTTURA OMNeT++
===============================================================================
Titolo: Implementazione con OMNeT++

Linguaggi Usati:

  • NED:    Descrizione struttura moduli (file .ned)
  • C++:    Logica simulazione e algoritmo (file .cc/.h)
  • INI:    Parametri scenari e configurazione

Principi Course-Standard:

  Signal Mechanism:
    • registerSignal("metricName") → simsignal_t
    • emit(signal, value) → registrazione dati
    • @signal[name](type=...) in NED
    • @statistic[name](source=...; record=...) in NED

  Message Passing:
    • cMessage per comunicazione inter-moduli
    • setKind(0 lettura, 1 scrittura) per distinguere
    • addPar() per parametri payload

  Event Scheduling:
    • scheduleAt(simTime()+delay, msg)
    • handleMessage(cMessage*) per routing

File Struttura:

  DatabaseNetwork.ned    → Network topology + param
  User.ned              → User module definition + signals
  User.h/cc             → User implementation
  Table.ned             → Table module definition + signals
  Table.h/cc            → Table implementation
  Makefile              → Build configuration
  omnetpp.ini           → Simulation parameters

Output:
  • *.vec                → Vettori temporali (signal recordings)
  • *.sca                → Scalari (medie, max, min)
  • *.txt                → Log output (EV_INFO/EV_DEBUG)


SLIDE 7: DESIGN SPERIMENTALE
===============================================================================
Titolo: Design Sperimentale e Scenari

Scenario Base:

  Network:
    numUsers = 60 users
    numTables = 20 tables

  User Behavior:
    lambda = 1.0 accessi/secondo (rate Poisson)
    readProbability = 0.8 (80% read, 20% write)
    tableDistribution = "uniform" (accesso equiprobabile)
    serviceTime = 0.1 secondi

  Simulation:
    simTime = 500 secondi
    warm-up = 50 secondi (ignored for stats)
    replication = 10 runs

Variazioni Sperimentali:

  Fattore 1: Read/Write Ratio
    • p = 0.5 (50:50, scrivere-intensivo)
    • p = 0.8 (80:20, realista)
    • p = 0.95 (95:5, leggere-intensivo)

  Fattore 2: Carico Utenti
    • N = 10 (basso)
    • N = 60 (baseline)
    • N = 200 (alto)

  Fattore 3: Distribuzione Tabelle
    • "uniform" (equiprobabile a tutte le M tabelle)
    • "lognormal" (hotspot: alcune tabelle più frequenti)

  Fattore 4: Rate Accessi
    • λ = 0.5 (basso carico)
    • λ = 1.0 (carico normale)
    • λ = 2.0 (alto carico)

Combinazioni Testate:
  • Totale scenarios: 3 (p) × 3 (N) × 2 (dist) × 3 (λ) = 54 configurazioni
  • Per scenario: 10-30 replicazioni indipendenti
  • Output: Medie + intervalli di confidenza 95%


SLIDE 8: RISULTATI ATTESI - ANALYSIS 1
===============================================================================
Titolo: Analisi Throughput e Latency

Throughput vs Carico Utenti:

  Atteso:
    • Crescita quasi-lineare con N fino a saturation
    • Saturation quando tabelle non riescono servire
    • Plateau superiore = throughput massimo

  Formula Approssimata:
    Throughput ≈ min(λ·N, M·(1/S))
    (limitato da rate Poisson oppure service capacity)

Latency (Wait Time) vs Carico:

  Atteso:
    • Aumenta sub-linearmente inizialmente
    • Poi esponenziale quando saturation
    • Knee point = carico ottimale

  Effetto p:
    • p alto (letture): latency bassa, throughput alta
    • p basso (scritture): latency alta, throughput bassa
    • Motivo: Letture parallelizzabili

Queueing Behavior:

  M/M/1 Approximation (single table):
    E[Wait] = (ρ/(1-ρ)) · S
    where ρ = λ·(1/S)
    
  Reality:
    • M table in parallel → carico distribuito
    • Readers/writers → effective capacity higher
    • FCFS + random table → complex analysis

Graph Examples:
  
  [Throughput] (accessi/sec)
  ^
  | /-- plateau (saturation)
  |/
  +----> numUsers
  
  [Wait Time] (secondi)
  ^
  | \
  |  \___
  |      \___
  +-------+---> numUsers
       (knee point)


SLIDE 9: RISULTATI ATTESI - ANALYSIS 2
===============================================================================
Titolo: Effetti Concorrenza e Distribuzione

Read/Write Impact:

  Throughput Totale vs p:
    • p=0.95: Throughput alto (parallelismo letture)
    • p=0.50: Throughput basso (scritture serializzano)
    • p=0.05: Throughput bassissimo (tutto in mutua esclusione)

  Wait Time vs p:
    • Inversamente correlato: più letture = meno wait
    • Cambio slope attorno p=0.8 (transizione regime)

Distribuzione Tabella (Uniforme vs Lognormale):

  Uniforme:
    • Carico equilibrato su M tabelle
    • Queue length media più bassa
    • Scalabilità migliore con M

  Lognormale (hotspot):
    • Concentrazione su poche tabelle "calde"
    • Alcune tabelle sotto-utilizzate
    • Queue length massima più alta (hotspot satura)
    • In pratica: limita throughput system

Scalabilità con numTables:

  Atteso:
    Throughput ∝ numTables (se carico distribuito)
    Queue_length ∝ 1/numTables

  Limite pratico:
    • Oltre certo point, diminishing returns
    • Network bandwidth (se non asincrono)
    • Memory per tabella


SLIDE 10: CONCLUSIONI E FUTURE WORK
===============================================================================
Titolo: Conclusioni e Prospettive

Key Findings (Attesi):

  ✓ Algoritmo readers/writers implementato correttamente
  ✓ Mutual exclusion evita race conditions
  ✓ FCFS ensures fairness
  ✓ Throughput scale con carico fino a saturation
  ✓ Latency increase esponenziale in saturation regime

Applicazioni Pratiche:

  • Dimensionamento database cluster
  • Tuning di carico read/write ratio
  • Allocazione risorse (# tabelle vs # utenti)
  • Identificazione bottleneck e hot-spot

Limitazioni Attuali:

  ⚠ Tempo di servizio fisso (non realistico)
  ⚠ No cache model (accesso sempre database)
  ⚠ No network delay (asincrono ideale)
  ⚠ No node failures
  ⚠ Single table instances (no replication)

Future Extensions:

  1. Variable service times:
     Distributions: lognormal, Pareto tail

  2. Caching model:
     P(cache hit), locality of reference

  3. Hot-spot migration:
     Tables "calde" cambiano nel tempo

  4. Transactions:
     Multi-statement batches, ACID properties

  5. Load balancing:
     Routing users to replica tables

  6. Advanced congestion control:
     Adaptive λ, backpressure mechanisms

  7. Larger-scale experiments:
     N=1000+, M=100+, distributed OMNeT++

Riferimenti Corso:

  ✓ Teoria delle Code (Poisson, M/M/1, queueing)
  ✓ Statistica (confidence intervals, variance reduction)
  ✓ OMNeT++ (signal mechanism, message passing)
  ✓ Algoritmi (mutual exclusion, FCFS, deadlock-free)

Conclusione Generale:

  Simulazione valida e strutturata per analizzare
  trade-off concorrenza vs performance.
  Risultati forniscono insight pratico per sistemi reali.


===============================================================================
Fine Presentazione
===============================================================================
